{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc986002",
   "metadata": {
    "id": "cc986002"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, Input, Activation, Dropout, Add, LSTM, GRU, RNN, LayerNormalization, BatchNormalization, Conv1D, MaxPooling1D, Flatten, Layer\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam,SGD\n",
    "import tensorflow as tf\n",
    "from keras import Model, regularizers, activations\n",
    "from keras.constraints import Constraint\n",
    "import pickle\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8LlThIlQoUAl",
   "metadata": {
    "id": "8LlThIlQoUAl"
   },
   "outputs": [],
   "source": [
    "DEFAULT_BETA_BJORCK = 0.5\n",
    "DEFAULT_EPS_SPECTRAL = 1e-3\n",
    "DEFAULT_EPS_BJORCK = 1e-3\n",
    "DEFAULT_MAXITER_BJORCK = 15\n",
    "DEFAULT_MAXITER_SPECTRAL = 10\n",
    "SWAP_MEMORY = True\n",
    "STOP_GRAD_SPECTRAL = True\n",
    "\n",
    "def reshaped_kernel_orthogonalization(\n",
    "    kernel,\n",
    "    u,\n",
    "    adjustment_coef,\n",
    "    eps_spectral=DEFAULT_EPS_SPECTRAL,\n",
    "    eps_bjorck=DEFAULT_EPS_BJORCK,\n",
    "    beta=DEFAULT_BETA_BJORCK,\n",
    "    maxiter_spectral=DEFAULT_MAXITER_SPECTRAL,\n",
    "    maxiter_bjorck=DEFAULT_MAXITER_BJORCK,\n",
    "):\n",
    "    \n",
    "    \"\"\"\n",
    "    Perform reshaped kernel orthogonalization (RKO) to the kernel given as input. It\n",
    "    apply the power method to find the largest singular value and apply the Bjorck\n",
    "    algorithm to the rescaled kernel. This greatly improve the stability and and\n",
    "    speed convergence of the bjorck algorithm.\n",
    "\n",
    "    Args:\n",
    "        kernel (tf.Tensor): the kernel to orthogonalize\n",
    "        u (tf.Tensor): the vector used to do the power iteration method\n",
    "        adjustment_coef (float): the adjustment coefficient as used in convolution\n",
    "        eps_spectral (float): stopping criterion in spectral algorithm\n",
    "        eps_bjorck (float): stopping criterion in bjorck algorithm\n",
    "        beta (float): the beta used in the bjorck algorithm\n",
    "        maxiter_spectral (int): maximum number of iterations for the power iteration\n",
    "        maxiter_bjorck (int): maximum number of iterations for bjorck algorithm\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: the orthogonalized kernel, the new u, and sigma which is the largest\n",
    "            singular value\n",
    "    \n",
    "    Reference:\n",
    "        Serrurier, M., Mamalet, F., González-Sanz, A., Boissin, T., Loubes, J. M., & Del Barrio, E. (2021). \n",
    "        Achieving robustness in classification using optimal transport with hinge regularization. \n",
    "        In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 505-514).\n",
    "\n",
    "    \"\"\"\n",
    "    W_shape = kernel.shape\n",
    "    # Flatten the Tensor\n",
    "    W_reshaped = tf.reshape(kernel, [-1, W_shape[-1]])\n",
    "    W_bar, u, sigma = spectral_normalization(\n",
    "        W_reshaped, u, eps=eps_spectral, maxiter=maxiter_spectral\n",
    "    )\n",
    "    if (eps_bjorck is not None) and (beta is not None):\n",
    "        W_bar = bjorck_normalization(\n",
    "            W_bar, eps=eps_bjorck, beta=beta, maxiter=maxiter_bjorck\n",
    "        )\n",
    "    W_bar = W_bar * adjustment_coef\n",
    "    W_bar = K.reshape(W_bar, kernel.shape)\n",
    "    return W_bar, u, sigma\n",
    "\n",
    "\n",
    "def _wwtw(w):\n",
    "    if w.shape[0] > w.shape[1]:\n",
    "        return w @ (tf.transpose(w) @ w)\n",
    "    else:\n",
    "        return (w @ tf.transpose(w)) @ w\n",
    "\n",
    "\n",
    "def bjorck_normalization(\n",
    "    w, eps=DEFAULT_EPS_BJORCK, beta=DEFAULT_BETA_BJORCK, maxiter=DEFAULT_MAXITER_BJORCK\n",
    "):\n",
    "    \"\"\"\n",
    "    apply Bjorck normalization on w.\n",
    "\n",
    "    Args:\n",
    "        w (tf.Tensor): weight to normalize, in order to work properly, we must have\n",
    "            max_eigenval(w) ~= 1\n",
    "        eps (float): epsilon stopping criterion: norm(wt - wt-1) must be less than eps\n",
    "        beta (float): beta used in each iteration, must be in the interval ]0, 0.5]\n",
    "        maxiter (int): maximum number of iterations for the algorithm\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: the orthonormal weights\n",
    "    \n",
    "    Reference:\n",
    "        Serrurier, M., Mamalet, F., González-Sanz, A., Boissin, T., Loubes, J. M., & Del Barrio, E. (2021). \n",
    "        Achieving robustness in classification using optimal transport with hinge regularization. \n",
    "        In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 505-514).\n",
    "\n",
    "    \"\"\"\n",
    "    # create a fake old_w that does'nt pass the loop condition\n",
    "    # it won't affect computation as the first action done in the loop overwrite it.\n",
    "    old_w = 10 * w\n",
    "    # define the loop condition\n",
    "\n",
    "    def cond(w, old_w):\n",
    "        return tf.linalg.norm(w - old_w) >= eps\n",
    "\n",
    "    # define the loop body\n",
    "    def body(w, old_w):\n",
    "        old_w = w\n",
    "        w = (1 + beta) * w - beta * _wwtw(w)\n",
    "        return w, old_w\n",
    "\n",
    "    # apply the loop\n",
    "    w, old_w = tf.while_loop(\n",
    "        cond,\n",
    "        body,\n",
    "        (w, old_w),\n",
    "        parallel_iterations=30,\n",
    "        maximum_iterations=maxiter,\n",
    "        swap_memory=SWAP_MEMORY,\n",
    "    )\n",
    "    return w\n",
    "\n",
    "\n",
    "def _power_iteration(\n",
    "    linear_operator,\n",
    "    adjoint_operator,\n",
    "    u,\n",
    "    eps=DEFAULT_EPS_SPECTRAL,\n",
    "    maxiter=DEFAULT_MAXITER_SPECTRAL,\n",
    "    axis=None,\n",
    "):\n",
    "    \"\"\"Internal function that performs the power iteration algorithm to estimate the\n",
    "    largest singular vector of a linear operator.\n",
    "\n",
    "    Args:\n",
    "        linear_operator (Callable): a callable object that maps a linear operation.\n",
    "        adjoint_operator (Callable): a callable object that maps the adjoint of the\n",
    "            linear operator.\n",
    "        u (tf.Tensor): initialization of the singular vector.\n",
    "        eps (float, optional): stopping criterion of the algorithm, when\n",
    "            norm(u[t] - u[t-1]) is less than eps. Defaults to DEFAULT_EPS_SPECTRAL.\n",
    "        maxiter (int, optional): maximum number of iterations for the algorithm.\n",
    "            Defaults to DEFAULT_MAXITER_SPECTRAL.\n",
    "        axis (int/list, optional): dimension along which to normalize. Can be set for\n",
    "            depthwise convolution for example. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: the maximum singular vector.\n",
    "        \n",
    "    Reference:\n",
    "        Serrurier, M., Mamalet, F., González-Sanz, A., Boissin, T., Loubes, J. M., & Del Barrio, E. (2021). \n",
    "        Achieving robustness in classification using optimal transport with hinge regularization. \n",
    "        In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 505-514).\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare while loop variables\n",
    "    u = tf.math.l2_normalize(u, axis=axis)\n",
    "    # create a fake old_w that doesn't pass the loop condition, it will be overwritten\n",
    "    old_u = u + 2 * eps\n",
    "\n",
    "    # Loop body\n",
    "    def body(u, old_u):\n",
    "        old_u = u\n",
    "        v = linear_operator(u)\n",
    "        u = adjoint_operator(v)\n",
    "\n",
    "        u = tf.math.l2_normalize(u, axis=axis)\n",
    "\n",
    "        return u, old_u\n",
    "\n",
    "    # Loop stopping condition\n",
    "    def cond(u, old_u):\n",
    "        return tf.linalg.norm(u - old_u) >= eps\n",
    "\n",
    "    # Run the while loop\n",
    "    u, _ = tf.while_loop(\n",
    "        cond,\n",
    "        body,\n",
    "        (u, old_u),\n",
    "        maximum_iterations=maxiter,\n",
    "        swap_memory=SWAP_MEMORY,\n",
    "    )\n",
    "\n",
    "    # Prevent gradient to back-propagate into the while loop\n",
    "    if STOP_GRAD_SPECTRAL:\n",
    "        u = tf.stop_gradient(u)\n",
    "\n",
    "    return u\n",
    "\n",
    "\n",
    "def spectral_normalization(\n",
    "    kernel, u, eps=DEFAULT_EPS_SPECTRAL, maxiter=DEFAULT_MAXITER_SPECTRAL\n",
    "):\n",
    "    \"\"\"\n",
    "    Normalize the kernel to have its maximum singular value equal to 1.\n",
    "\n",
    "    Args:\n",
    "        kernel (tf.Tensor): the kernel to normalize, assuming a 2D kernel.\n",
    "        u (tf.Tensor): initialization of the maximum singular vector.\n",
    "        eps (float, optional): stopping criterion of the algorithm, when\n",
    "            norm(u[t] - u[t-1]) is less than eps. Defaults to DEFAULT_EPS_SPECTRAL.\n",
    "        maxiter (int, optional): maximum number of iterations for the algorithm.\n",
    "            Defaults to DEFAULT_MAXITER_SPECTRAL.\n",
    "\n",
    "    Returns:\n",
    "        the normalized kernel, the maximum singular vector, and the maximum singular\n",
    "            value.\n",
    "\n",
    "    Reference:\n",
    "        Serrurier, M., Mamalet, F., González-Sanz, A., Boissin, T., Loubes, J. M., & Del Barrio, E. (2021). \n",
    "        Achieving robustness in classification using optimal transport with hinge regularization. \n",
    "        In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 505-514).\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    if u is None:\n",
    "        u = tf.random.uniform(\n",
    "            shape=(1, kernel.shape[-1]), minval=0.0, maxval=1.0, dtype=kernel.dtype\n",
    "        )\n",
    "\n",
    "    def linear_op(u):\n",
    "        return u @ tf.transpose(kernel)\n",
    "\n",
    "    def adjoint_op(v):\n",
    "        return v @ kernel\n",
    "\n",
    "    u = _power_iteration(linear_op, adjoint_op, u, eps, maxiter)\n",
    "\n",
    "    # Compute the largest singular value and the normalized kernel.\n",
    "    # We assume that in the worst case we converged to sigma + eps (as u and v are\n",
    "    # normalized after each iteration)\n",
    "    # In order to be sure that operator norm of normalized kernel is strictly less than\n",
    "    # one we use sigma + eps, which ensures stability of Björck algorithm even when\n",
    "    # beta=0.5\n",
    "    sigma = tf.reshape(tf.norm(linear_op(u)), (1, 1))\n",
    "    normalized_kernel = kernel / (sigma + eps)\n",
    "    return normalized_kernel, u, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "H2CpJ-MGo65c",
   "metadata": {
    "id": "H2CpJ-MGo65c"
   },
   "outputs": [],
   "source": [
    "class SpectralConstraint(Constraint):\n",
    "    def __init__(\n",
    "        self,\n",
    "        k_coef_lip=1.0,\n",
    "        eps_spectral=DEFAULT_EPS_SPECTRAL,\n",
    "        eps_bjorck=DEFAULT_EPS_BJORCK,\n",
    "        beta_bjorck=DEFAULT_BETA_BJORCK,\n",
    "        u=None,\n",
    "    ) -> None:\n",
    "        \n",
    "        \"\"\"\n",
    "        Ensure that *all* singular values of the weight matrix equals to 1. Computation\n",
    "        based on Bjorck algorithm. The computation is done in two steps:\n",
    "\n",
    "        1. reduce the larget singular value to k_coef_lip, using iterate power method.\n",
    "        2. increase other singular values to k_coef_lip, using bjorck algorithm.\n",
    "\n",
    "        Args:\n",
    "            k_coef_lip (float): lipschitz coefficient of the weight matrix\n",
    "            eps_spectral (float): stopping criterion for the iterative power algorithm.\n",
    "            eps_bjorck (float): stopping criterion Bjorck algorithm.\n",
    "            beta_bjorck (float): beta parameter in bjorck algorithm.\n",
    "            u (tf.Tensor): vector used for iterated power method, can be set to None\n",
    "                (used for serialization/deserialization purposes).\n",
    "                \n",
    "        Reference:\n",
    "            Serrurier, M., Mamalet, F., González-Sanz, A., Boissin, T., Loubes, J. M., & Del Barrio, E. (2021). \n",
    "            Achieving robustness in classification using optimal transport with hinge regularization. \n",
    "            In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 505-514).\n",
    "            \n",
    "        \"\"\"\n",
    "        self.eps_spectral = eps_spectral\n",
    "        self.eps_bjorck = eps_bjorck\n",
    "        self.beta_bjorck = beta_bjorck\n",
    "        self.k_coef_lip = k_coef_lip\n",
    "        if not (isinstance(u, tf.Tensor) or (u is None)):\n",
    "            u = tf.convert_to_tensor(u)\n",
    "        self.u = u\n",
    "        super(SpectralConstraint, self).__init__()\n",
    "\n",
    "    def __call__(self, w):\n",
    "        # make the largest singular value of W to be 1\n",
    "        wbar, _, _ = reshaped_kernel_orthogonalization(\n",
    "            w,\n",
    "            self.u,\n",
    "            self.k_coef_lip,\n",
    "            self.eps_spectral,\n",
    "            self.eps_bjorck,\n",
    "            self.beta_bjorck,\n",
    "        )\n",
    "\n",
    "        # clip to ensure non-negative weight\n",
    "        wbar = K.clip(wbar, 0, wbar)\n",
    "        return wbar\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            \"k_coef_lip\": self.k_coef_lip,\n",
    "            \"eps_spectral\": self.eps_spectral,\n",
    "            \"eps_bjorck\": self.eps_bjorck,\n",
    "            \"beta_bjorck\": self.beta_bjorck,\n",
    "            \"u\": None if self.u is None else self.u.numpy(),\n",
    "        }\n",
    "        base_config = super(SpectralConstraint, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "287426c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_salt_and_pepper_noise(images, amount):\n",
    "    noisy_images = images.copy()\n",
    "    num_images = images.shape[0]\n",
    "    num_pixels = images.shape[1] * images.shape[2]\n",
    "    num_salt = np.ceil(amount * num_pixels)\n",
    "    for i in range(num_images):\n",
    "        # Add salt noise\n",
    "        salt_indices = np.random.choice(num_pixels, size=int(num_salt), replace=False)\n",
    "        noisy_images[i].flat[salt_indices] = 1\n",
    "        \n",
    "        # Add pepper noise\n",
    "        pepper_indices = np.random.choice(num_pixels, size=int(num_salt), replace=False)\n",
    "        noisy_images[i].flat[pepper_indices] = 0\n",
    "    return noisy_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c200e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "352/352 - 163s - loss: 0.8552 - accuracy: 0.7124 - val_loss: 0.3708 - val_accuracy: 0.8922 - 163s/epoch - 462ms/step\n",
      "Epoch 2/100\n",
      "352/352 - 119s - loss: 0.2688 - accuracy: 0.9191 - val_loss: 0.1892 - val_accuracy: 0.9419 - 119s/epoch - 339ms/step\n",
      "Epoch 3/100\n",
      "352/352 - 121s - loss: 0.1825 - accuracy: 0.9469 - val_loss: 0.2189 - val_accuracy: 0.9353 - 121s/epoch - 343ms/step\n",
      "Epoch 4/100\n",
      "352/352 - 121s - loss: 0.1420 - accuracy: 0.9576 - val_loss: 0.1356 - val_accuracy: 0.9622 - 121s/epoch - 343ms/step\n",
      "Epoch 5/100\n",
      "352/352 - 121s - loss: 0.1116 - accuracy: 0.9680 - val_loss: 0.1709 - val_accuracy: 0.9513 - 121s/epoch - 344ms/step\n",
      "Epoch 6/100\n",
      "352/352 - 120s - loss: 0.1094 - accuracy: 0.9684 - val_loss: 0.1315 - val_accuracy: 0.9624 - 120s/epoch - 340ms/step\n",
      "Epoch 7/100\n",
      "352/352 - 121s - loss: 0.1031 - accuracy: 0.9704 - val_loss: 0.1212 - val_accuracy: 0.9630 - 121s/epoch - 344ms/step\n",
      "Epoch 8/100\n",
      "352/352 - 122s - loss: 0.0843 - accuracy: 0.9758 - val_loss: 0.1286 - val_accuracy: 0.9620 - 122s/epoch - 345ms/step\n",
      "Epoch 9/100\n",
      "352/352 - 120s - loss: 0.0809 - accuracy: 0.9766 - val_loss: 0.1187 - val_accuracy: 0.9697 - 120s/epoch - 340ms/step\n",
      "Epoch 10/100\n",
      "352/352 - 121s - loss: 0.0767 - accuracy: 0.9779 - val_loss: 0.0824 - val_accuracy: 0.9767 - 121s/epoch - 343ms/step\n",
      "Epoch 11/100\n",
      "352/352 - 120s - loss: 0.0650 - accuracy: 0.9821 - val_loss: 0.0977 - val_accuracy: 0.9736 - 120s/epoch - 340ms/step\n",
      "Epoch 12/100\n",
      "352/352 - 126s - loss: 0.0637 - accuracy: 0.9818 - val_loss: 0.0895 - val_accuracy: 0.9759 - 126s/epoch - 359ms/step\n",
      "Epoch 13/100\n",
      "352/352 - 124s - loss: 0.0582 - accuracy: 0.9837 - val_loss: 0.0861 - val_accuracy: 0.9771 - 124s/epoch - 351ms/step\n",
      "Epoch 14/100\n",
      "352/352 - 123s - loss: 0.0583 - accuracy: 0.9834 - val_loss: 0.1935 - val_accuracy: 0.9605 - 123s/epoch - 350ms/step\n",
      "Epoch 15/100\n",
      "352/352 - 125s - loss: 0.0594 - accuracy: 0.9837 - val_loss: 0.0980 - val_accuracy: 0.9737 - 125s/epoch - 354ms/step\n",
      "Epoch 16/100\n",
      "352/352 - 122s - loss: 0.0530 - accuracy: 0.9853 - val_loss: 0.1163 - val_accuracy: 0.9704 - 122s/epoch - 348ms/step\n",
      "Epoch 17/100\n",
      "352/352 - 126s - loss: 0.0528 - accuracy: 0.9851 - val_loss: 0.0801 - val_accuracy: 0.9773 - 126s/epoch - 357ms/step\n",
      "Epoch 18/100\n",
      "352/352 - 131s - loss: 0.0530 - accuracy: 0.9855 - val_loss: 0.1191 - val_accuracy: 0.9701 - 131s/epoch - 373ms/step\n",
      "Epoch 19/100\n",
      "352/352 - 126s - loss: 0.0595 - accuracy: 0.9837 - val_loss: 0.0871 - val_accuracy: 0.9782 - 126s/epoch - 359ms/step\n",
      "Epoch 20/100\n",
      "352/352 - 127s - loss: 0.0450 - accuracy: 0.9878 - val_loss: 0.0990 - val_accuracy: 0.9781 - 127s/epoch - 360ms/step\n",
      "Epoch 21/100\n",
      "352/352 - 122s - loss: 0.0411 - accuracy: 0.9887 - val_loss: 0.1253 - val_accuracy: 0.9725 - 122s/epoch - 346ms/step\n",
      "Epoch 22/100\n",
      "352/352 - 121s - loss: 0.0462 - accuracy: 0.9872 - val_loss: 0.0867 - val_accuracy: 0.9799 - 121s/epoch - 345ms/step\n",
      "Epoch 23/100\n",
      "352/352 - 125s - loss: 0.0454 - accuracy: 0.9878 - val_loss: 0.0842 - val_accuracy: 0.9805 - 125s/epoch - 356ms/step\n",
      "Epoch 24/100\n",
      "352/352 - 122s - loss: 0.0398 - accuracy: 0.9887 - val_loss: 0.0824 - val_accuracy: 0.9801 - 122s/epoch - 346ms/step\n",
      "Epoch 25/100\n",
      "352/352 - 123s - loss: 0.0425 - accuracy: 0.9884 - val_loss: 0.1092 - val_accuracy: 0.9715 - 123s/epoch - 349ms/step\n",
      "Epoch 26/100\n",
      "352/352 - 121s - loss: 0.0406 - accuracy: 0.9891 - val_loss: 0.1004 - val_accuracy: 0.9771 - 121s/epoch - 344ms/step\n",
      "Epoch 27/100\n",
      "352/352 - 121s - loss: 0.0365 - accuracy: 0.9896 - val_loss: 0.0972 - val_accuracy: 0.9783 - 121s/epoch - 343ms/step\n",
      "Epoch 28/100\n",
      "352/352 - 125s - loss: 0.0423 - accuracy: 0.9886 - val_loss: 0.1073 - val_accuracy: 0.9763 - 125s/epoch - 354ms/step\n",
      "Epoch 29/100\n",
      "352/352 - 122s - loss: 0.0328 - accuracy: 0.9903 - val_loss: 0.1142 - val_accuracy: 0.9778 - 122s/epoch - 347ms/step\n",
      "Epoch 30/100\n",
      "352/352 - 121s - loss: 0.0352 - accuracy: 0.9904 - val_loss: 0.0986 - val_accuracy: 0.9810 - 121s/epoch - 344ms/step\n",
      "Epoch 31/100\n",
      "352/352 - 122s - loss: 0.0384 - accuracy: 0.9896 - val_loss: 0.0723 - val_accuracy: 0.9806 - 122s/epoch - 347ms/step\n",
      "Epoch 32/100\n",
      "352/352 - 106s - loss: 0.0302 - accuracy: 0.9919 - val_loss: 0.0716 - val_accuracy: 0.9828 - 106s/epoch - 301ms/step\n",
      "Epoch 33/100\n",
      "352/352 - 106s - loss: 0.0339 - accuracy: 0.9904 - val_loss: 0.0972 - val_accuracy: 0.9778 - 106s/epoch - 302ms/step\n",
      "Epoch 34/100\n",
      "352/352 - 109s - loss: 0.0394 - accuracy: 0.9890 - val_loss: 0.0688 - val_accuracy: 0.9825 - 109s/epoch - 311ms/step\n",
      "Epoch 35/100\n",
      "352/352 - 120s - loss: 0.0296 - accuracy: 0.9917 - val_loss: 0.0914 - val_accuracy: 0.9768 - 120s/epoch - 340ms/step\n",
      "Epoch 36/100\n",
      "352/352 - 112s - loss: 0.0308 - accuracy: 0.9915 - val_loss: 0.0769 - val_accuracy: 0.9823 - 112s/epoch - 318ms/step\n",
      "Epoch 37/100\n",
      "352/352 - 103s - loss: 0.0227 - accuracy: 0.9934 - val_loss: 0.0785 - val_accuracy: 0.9824 - 103s/epoch - 293ms/step\n",
      "Epoch 38/100\n",
      "352/352 - 103s - loss: 0.0368 - accuracy: 0.9901 - val_loss: 0.0992 - val_accuracy: 0.9791 - 103s/epoch - 293ms/step\n",
      "Epoch 39/100\n",
      "352/352 - 105s - loss: 0.0257 - accuracy: 0.9933 - val_loss: 0.0959 - val_accuracy: 0.9770 - 105s/epoch - 299ms/step\n",
      "Epoch 40/100\n",
      "352/352 - 118s - loss: 0.0248 - accuracy: 0.9931 - val_loss: 0.1543 - val_accuracy: 0.9748 - 118s/epoch - 336ms/step\n",
      "Epoch 41/100\n",
      "352/352 - 119s - loss: 0.0273 - accuracy: 0.9927 - val_loss: 0.0965 - val_accuracy: 0.9789 - 119s/epoch - 337ms/step\n",
      "Epoch 42/100\n",
      "352/352 - 126s - loss: 0.0274 - accuracy: 0.9930 - val_loss: 0.0991 - val_accuracy: 0.9780 - 126s/epoch - 357ms/step\n",
      "Epoch 43/100\n",
      "352/352 - 118s - loss: 0.0340 - accuracy: 0.9906 - val_loss: 0.1232 - val_accuracy: 0.9747 - 118s/epoch - 335ms/step\n",
      "Epoch 44/100\n",
      "352/352 - 112s - loss: 0.0449 - accuracy: 0.9883 - val_loss: 0.0805 - val_accuracy: 0.9795 - 112s/epoch - 320ms/step\n",
      "Epoch 45/100\n",
      "352/352 - 114s - loss: 0.0255 - accuracy: 0.9926 - val_loss: 0.0798 - val_accuracy: 0.9792 - 114s/epoch - 325ms/step\n",
      "Epoch 46/100\n",
      "352/352 - 114s - loss: 0.0263 - accuracy: 0.9930 - val_loss: 0.0691 - val_accuracy: 0.9837 - 114s/epoch - 325ms/step\n",
      "Epoch 47/100\n",
      "352/352 - 112s - loss: 0.0321 - accuracy: 0.9906 - val_loss: 0.0996 - val_accuracy: 0.9807 - 112s/epoch - 320ms/step\n",
      "Epoch 48/100\n",
      "352/352 - 117s - loss: 0.0244 - accuracy: 0.9928 - val_loss: 0.0983 - val_accuracy: 0.9807 - 117s/epoch - 334ms/step\n",
      "Epoch 49/100\n",
      "352/352 - 116s - loss: 0.0259 - accuracy: 0.9927 - val_loss: 0.0758 - val_accuracy: 0.9843 - 116s/epoch - 330ms/step\n",
      "Epoch 50/100\n",
      "352/352 - 112s - loss: 0.0246 - accuracy: 0.9931 - val_loss: 0.0910 - val_accuracy: 0.9793 - 112s/epoch - 319ms/step\n",
      "Epoch 51/100\n",
      "352/352 - 113s - loss: 0.0216 - accuracy: 0.9938 - val_loss: 0.0929 - val_accuracy: 0.9814 - 113s/epoch - 322ms/step\n",
      "Epoch 52/100\n",
      "352/352 - 114s - loss: 0.0215 - accuracy: 0.9941 - val_loss: 0.0889 - val_accuracy: 0.9832 - 114s/epoch - 322ms/step\n",
      "Epoch 53/100\n",
      "352/352 - 113s - loss: 0.0257 - accuracy: 0.9928 - val_loss: 0.0867 - val_accuracy: 0.9797 - 113s/epoch - 320ms/step\n",
      "Epoch 54/100\n",
      "352/352 - 113s - loss: 0.0255 - accuracy: 0.9931 - val_loss: 0.0801 - val_accuracy: 0.9811 - 113s/epoch - 321ms/step\n",
      "Epoch 55/100\n",
      "352/352 - 114s - loss: 0.0219 - accuracy: 0.9939 - val_loss: 0.1051 - val_accuracy: 0.9788 - 114s/epoch - 323ms/step\n",
      "Epoch 56/100\n",
      "352/352 - 115s - loss: 0.0235 - accuracy: 0.9937 - val_loss: 0.0975 - val_accuracy: 0.9823 - 115s/epoch - 327ms/step\n",
      "Epoch 57/100\n",
      "352/352 - 113s - loss: 0.0245 - accuracy: 0.9938 - val_loss: 0.0821 - val_accuracy: 0.9818 - 113s/epoch - 322ms/step\n",
      "Epoch 58/100\n",
      "352/352 - 114s - loss: 0.0164 - accuracy: 0.9957 - val_loss: 0.0914 - val_accuracy: 0.9825 - 114s/epoch - 325ms/step\n",
      "Epoch 59/100\n",
      "352/352 - 114s - loss: 0.0259 - accuracy: 0.9929 - val_loss: 0.0755 - val_accuracy: 0.9838 - 114s/epoch - 324ms/step\n",
      "Epoch 60/100\n",
      "352/352 - 112s - loss: 0.0288 - accuracy: 0.9919 - val_loss: 0.0969 - val_accuracy: 0.9788 - 112s/epoch - 318ms/step\n",
      "Epoch 61/100\n",
      "352/352 - 113s - loss: 0.0226 - accuracy: 0.9934 - val_loss: 0.0670 - val_accuracy: 0.9838 - 113s/epoch - 320ms/step\n",
      "Epoch 62/100\n",
      "352/352 - 114s - loss: 0.0216 - accuracy: 0.9943 - val_loss: 0.0952 - val_accuracy: 0.9796 - 114s/epoch - 323ms/step\n",
      "Epoch 63/100\n",
      "352/352 - 113s - loss: 0.0387 - accuracy: 0.9895 - val_loss: 0.0974 - val_accuracy: 0.9779 - 113s/epoch - 322ms/step\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 - 112s - loss: 0.0292 - accuracy: 0.9922 - val_loss: 0.0891 - val_accuracy: 0.9788 - 112s/epoch - 317ms/step\n",
      "Epoch 65/100\n",
      "352/352 - 112s - loss: 0.0247 - accuracy: 0.9928 - val_loss: 0.1004 - val_accuracy: 0.9793 - 112s/epoch - 317ms/step\n",
      "Epoch 66/100\n",
      "352/352 - 103s - loss: 0.0245 - accuracy: 0.9934 - val_loss: 0.0896 - val_accuracy: 0.9785 - 103s/epoch - 293ms/step\n",
      "Epoch 67/100\n",
      "352/352 - 99s - loss: 0.0207 - accuracy: 0.9937 - val_loss: 0.0687 - val_accuracy: 0.9841 - 99s/epoch - 281ms/step\n",
      "Epoch 68/100\n",
      "352/352 - 113s - loss: 0.0180 - accuracy: 0.9952 - val_loss: 0.0734 - val_accuracy: 0.9818 - 113s/epoch - 320ms/step\n",
      "Epoch 69/100\n",
      "352/352 - 116s - loss: 0.0250 - accuracy: 0.9936 - val_loss: 0.0746 - val_accuracy: 0.9842 - 116s/epoch - 329ms/step\n",
      "Epoch 70/100\n",
      "352/352 - 117s - loss: 0.0190 - accuracy: 0.9947 - val_loss: 0.0908 - val_accuracy: 0.9811 - 117s/epoch - 332ms/step\n",
      "Epoch 71/100\n",
      "352/352 - 114s - loss: 0.0207 - accuracy: 0.9941 - val_loss: 0.1467 - val_accuracy: 0.9684 - 114s/epoch - 324ms/step\n",
      "Epoch 72/100\n",
      "352/352 - 114s - loss: 0.0319 - accuracy: 0.9913 - val_loss: 0.0791 - val_accuracy: 0.9807 - 114s/epoch - 325ms/step\n",
      "Epoch 73/100\n",
      "352/352 - 115s - loss: 0.0260 - accuracy: 0.9928 - val_loss: 0.0795 - val_accuracy: 0.9823 - 115s/epoch - 326ms/step\n",
      "Epoch 74/100\n",
      "352/352 - 114s - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.0725 - val_accuracy: 0.9823 - 114s/epoch - 323ms/step\n",
      "Epoch 75/100\n",
      "352/352 - 114s - loss: 0.0170 - accuracy: 0.9954 - val_loss: 0.0890 - val_accuracy: 0.9809 - 114s/epoch - 324ms/step\n",
      "Epoch 76/100\n",
      "352/352 - 114s - loss: 0.0270 - accuracy: 0.9923 - val_loss: 0.0887 - val_accuracy: 0.9795 - 114s/epoch - 324ms/step\n",
      "Epoch 77/100\n",
      "352/352 - 116s - loss: 0.0233 - accuracy: 0.9942 - val_loss: 0.0732 - val_accuracy: 0.9828 - 116s/epoch - 329ms/step\n",
      "Epoch 78/100\n",
      "352/352 - 115s - loss: 0.0177 - accuracy: 0.9950 - val_loss: 0.0680 - val_accuracy: 0.9843 - 115s/epoch - 327ms/step\n",
      "Epoch 79/100\n",
      "352/352 - 115s - loss: 0.0198 - accuracy: 0.9944 - val_loss: 0.0966 - val_accuracy: 0.9805 - 115s/epoch - 326ms/step\n",
      "Epoch 80/100\n",
      "352/352 - 119s - loss: 0.0199 - accuracy: 0.9948 - val_loss: 0.0824 - val_accuracy: 0.9792 - 119s/epoch - 339ms/step\n",
      "Epoch 81/100\n",
      "352/352 - 116s - loss: 0.0145 - accuracy: 0.9958 - val_loss: 0.0877 - val_accuracy: 0.9797 - 116s/epoch - 329ms/step\n",
      "Epoch 82/100\n",
      "352/352 - 114s - loss: 0.0259 - accuracy: 0.9931 - val_loss: 0.0742 - val_accuracy: 0.9818 - 114s/epoch - 324ms/step\n",
      "Epoch 83/100\n",
      "352/352 - 114s - loss: 0.0183 - accuracy: 0.9945 - val_loss: 0.0918 - val_accuracy: 0.9808 - 114s/epoch - 324ms/step\n",
      "Epoch 84/100\n",
      "352/352 - 115s - loss: 0.0238 - accuracy: 0.9936 - val_loss: 0.0951 - val_accuracy: 0.9809 - 115s/epoch - 327ms/step\n",
      "Epoch 85/100\n",
      "352/352 - 113s - loss: 0.0228 - accuracy: 0.9940 - val_loss: 0.0747 - val_accuracy: 0.9828 - 113s/epoch - 321ms/step\n",
      "Epoch 86/100\n",
      "352/352 - 113s - loss: 0.0257 - accuracy: 0.9930 - val_loss: 0.0910 - val_accuracy: 0.9798 - 113s/epoch - 321ms/step\n",
      "Epoch 87/100\n",
      "352/352 - 115s - loss: 0.0231 - accuracy: 0.9941 - val_loss: 0.0807 - val_accuracy: 0.9825 - 115s/epoch - 326ms/step\n",
      "Epoch 88/100\n",
      "352/352 - 114s - loss: 0.0184 - accuracy: 0.9945 - val_loss: 0.0816 - val_accuracy: 0.9839 - 114s/epoch - 325ms/step\n",
      "Epoch 89/100\n",
      "352/352 - 114s - loss: 0.0184 - accuracy: 0.9946 - val_loss: 0.0839 - val_accuracy: 0.9815 - 114s/epoch - 323ms/step\n",
      "Epoch 90/100\n",
      "352/352 - 114s - loss: 0.0156 - accuracy: 0.9959 - val_loss: 0.1223 - val_accuracy: 0.9774 - 114s/epoch - 325ms/step\n",
      "Epoch 91/100\n",
      "352/352 - 116s - loss: 0.0246 - accuracy: 0.9936 - val_loss: 0.0863 - val_accuracy: 0.9821 - 116s/epoch - 329ms/step\n",
      "Epoch 92/100\n",
      "352/352 - 115s - loss: 0.0202 - accuracy: 0.9944 - val_loss: 0.0731 - val_accuracy: 0.9841 - 115s/epoch - 326ms/step\n",
      "Epoch 93/100\n",
      "352/352 - 100s - loss: 0.0162 - accuracy: 0.9961 - val_loss: 0.0819 - val_accuracy: 0.9816 - 100s/epoch - 284ms/step\n",
      "Epoch 94/100\n",
      "352/352 - 88s - loss: 0.0178 - accuracy: 0.9953 - val_loss: 0.0843 - val_accuracy: 0.9819 - 88s/epoch - 251ms/step\n",
      "Epoch 95/100\n",
      "352/352 - 106s - loss: 0.0217 - accuracy: 0.9944 - val_loss: 0.0804 - val_accuracy: 0.9820 - 106s/epoch - 302ms/step\n",
      "Epoch 96/100\n",
      "352/352 - 112s - loss: 0.0280 - accuracy: 0.9928 - val_loss: 0.1035 - val_accuracy: 0.9749 - 112s/epoch - 318ms/step\n",
      "Epoch 97/100\n",
      "352/352 - 99s - loss: 0.0246 - accuracy: 0.9930 - val_loss: 0.0797 - val_accuracy: 0.9830 - 99s/epoch - 282ms/step\n",
      "Epoch 98/100\n",
      "352/352 - 100s - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.0842 - val_accuracy: 0.9820 - 100s/epoch - 285ms/step\n",
      "Epoch 99/100\n",
      "352/352 - 105s - loss: 0.0153 - accuracy: 0.9957 - val_loss: 0.0736 - val_accuracy: 0.9841 - 105s/epoch - 299ms/step\n",
      "Epoch 100/100\n",
      "352/352 - 107s - loss: 0.0162 - accuracy: 0.9952 - val_loss: 0.0938 - val_accuracy: 0.9804 - 107s/epoch - 305ms/step\n",
      "[0.980400025844574, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "79/79 [==============================] - 8s 98ms/step - loss: 0.0813 - accuracy: 0.9823\n",
      "[0.9822999835014343, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zihaow19\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "352/352 - 135s - loss: 1.0357 - accuracy: 0.6516 - val_loss: 0.5469 - val_accuracy: 0.8237 - 135s/epoch - 384ms/step\n",
      "Epoch 2/100\n",
      "352/352 - 105s - loss: 0.4278 - accuracy: 0.8653 - val_loss: 0.3762 - val_accuracy: 0.8839 - 105s/epoch - 297ms/step\n",
      "Epoch 3/100\n",
      "352/352 - 105s - loss: 0.2982 - accuracy: 0.9080 - val_loss: 0.2785 - val_accuracy: 0.9238 - 105s/epoch - 298ms/step\n",
      "Epoch 4/100\n",
      "352/352 - 107s - loss: 0.2171 - accuracy: 0.9341 - val_loss: 0.2098 - val_accuracy: 0.9393 - 107s/epoch - 303ms/step\n",
      "Epoch 5/100\n",
      "352/352 - 104s - loss: 0.1858 - accuracy: 0.9454 - val_loss: 0.1745 - val_accuracy: 0.9453 - 104s/epoch - 296ms/step\n",
      "Epoch 6/100\n",
      "352/352 - 104s - loss: 0.1655 - accuracy: 0.9506 - val_loss: 0.2026 - val_accuracy: 0.9397 - 104s/epoch - 295ms/step\n",
      "Epoch 7/100\n",
      "352/352 - 106s - loss: 0.1426 - accuracy: 0.9575 - val_loss: 0.1954 - val_accuracy: 0.9428 - 106s/epoch - 300ms/step\n",
      "Epoch 8/100\n",
      "352/352 - 105s - loss: 0.1344 - accuracy: 0.9599 - val_loss: 0.2391 - val_accuracy: 0.9372 - 105s/epoch - 298ms/step\n",
      "Epoch 9/100\n",
      "352/352 - 105s - loss: 0.1209 - accuracy: 0.9636 - val_loss: 0.1894 - val_accuracy: 0.9460 - 105s/epoch - 298ms/step\n",
      "Epoch 10/100\n",
      "352/352 - 107s - loss: 0.1167 - accuracy: 0.9641 - val_loss: 0.1825 - val_accuracy: 0.9480 - 107s/epoch - 303ms/step\n",
      "Epoch 11/100\n",
      "352/352 - 107s - loss: 0.1062 - accuracy: 0.9677 - val_loss: 0.1489 - val_accuracy: 0.9583 - 107s/epoch - 303ms/step\n",
      "Epoch 12/100\n",
      "352/352 - 106s - loss: 0.0945 - accuracy: 0.9715 - val_loss: 0.1608 - val_accuracy: 0.9577 - 106s/epoch - 302ms/step\n",
      "Epoch 13/100\n",
      "352/352 - 108s - loss: 0.1040 - accuracy: 0.9694 - val_loss: 0.1878 - val_accuracy: 0.9508 - 108s/epoch - 307ms/step\n",
      "Epoch 14/100\n",
      "352/352 - 105s - loss: 0.0902 - accuracy: 0.9736 - val_loss: 0.1710 - val_accuracy: 0.9525 - 105s/epoch - 298ms/step\n",
      "Epoch 15/100\n",
      "352/352 - 105s - loss: 0.0807 - accuracy: 0.9761 - val_loss: 0.1594 - val_accuracy: 0.9576 - 105s/epoch - 299ms/step\n",
      "Epoch 16/100\n",
      "352/352 - 105s - loss: 0.0866 - accuracy: 0.9746 - val_loss: 0.1677 - val_accuracy: 0.9541 - 105s/epoch - 298ms/step\n",
      "Epoch 17/100\n",
      "352/352 - 107s - loss: 0.0813 - accuracy: 0.9755 - val_loss: 0.1466 - val_accuracy: 0.9595 - 107s/epoch - 303ms/step\n",
      "Epoch 18/100\n",
      "352/352 - 105s - loss: 0.0707 - accuracy: 0.9789 - val_loss: 0.1536 - val_accuracy: 0.9593 - 105s/epoch - 300ms/step\n",
      "Epoch 19/100\n",
      "352/352 - 103s - loss: 0.0745 - accuracy: 0.9779 - val_loss: 0.1568 - val_accuracy: 0.9565 - 103s/epoch - 293ms/step\n",
      "Epoch 20/100\n",
      "352/352 - 102s - loss: 0.0745 - accuracy: 0.9777 - val_loss: 0.1666 - val_accuracy: 0.9569 - 102s/epoch - 291ms/step\n",
      "Epoch 21/100\n",
      "352/352 - 105s - loss: 0.0635 - accuracy: 0.9815 - val_loss: 0.1602 - val_accuracy: 0.9599 - 105s/epoch - 297ms/step\n",
      "Epoch 22/100\n",
      "352/352 - 104s - loss: 0.0638 - accuracy: 0.9810 - val_loss: 0.1754 - val_accuracy: 0.9535 - 104s/epoch - 297ms/step\n",
      "Epoch 23/100\n",
      "352/352 - 104s - loss: 0.0571 - accuracy: 0.9833 - val_loss: 0.1614 - val_accuracy: 0.9594 - 104s/epoch - 295ms/step\n",
      "Epoch 24/100\n",
      "352/352 - 105s - loss: 0.0684 - accuracy: 0.9793 - val_loss: 0.1826 - val_accuracy: 0.9535 - 105s/epoch - 299ms/step\n",
      "Epoch 25/100\n",
      "352/352 - 104s - loss: 0.0618 - accuracy: 0.9826 - val_loss: 0.1660 - val_accuracy: 0.9585 - 104s/epoch - 294ms/step\n",
      "Epoch 26/100\n",
      "352/352 - 103s - loss: 0.0609 - accuracy: 0.9825 - val_loss: 0.1698 - val_accuracy: 0.9622 - 103s/epoch - 293ms/step\n",
      "Epoch 27/100\n",
      "352/352 - 103s - loss: 0.0552 - accuracy: 0.9833 - val_loss: 0.1626 - val_accuracy: 0.9585 - 103s/epoch - 294ms/step\n",
      "Epoch 28/100\n",
      "352/352 - 103s - loss: 0.0602 - accuracy: 0.9816 - val_loss: 0.1637 - val_accuracy: 0.9551 - 103s/epoch - 292ms/step\n",
      "Epoch 29/100\n",
      "352/352 - 102s - loss: 0.0526 - accuracy: 0.9840 - val_loss: 0.1771 - val_accuracy: 0.9594 - 102s/epoch - 289ms/step\n",
      "Epoch 30/100\n",
      "352/352 - 104s - loss: 0.0560 - accuracy: 0.9836 - val_loss: 0.1543 - val_accuracy: 0.9614 - 104s/epoch - 296ms/step\n",
      "Epoch 31/100\n",
      "352/352 - 104s - loss: 0.0509 - accuracy: 0.9851 - val_loss: 0.1647 - val_accuracy: 0.9583 - 104s/epoch - 296ms/step\n",
      "Epoch 32/100\n",
      "352/352 - 104s - loss: 0.0480 - accuracy: 0.9851 - val_loss: 0.1711 - val_accuracy: 0.9578 - 104s/epoch - 296ms/step\n",
      "Epoch 33/100\n",
      "352/352 - 105s - loss: 0.0487 - accuracy: 0.9862 - val_loss: 0.1725 - val_accuracy: 0.9554 - 105s/epoch - 297ms/step\n",
      "Epoch 34/100\n",
      "352/352 - 105s - loss: 0.0556 - accuracy: 0.9836 - val_loss: 0.1395 - val_accuracy: 0.9622 - 105s/epoch - 298ms/step\n",
      "Epoch 35/100\n",
      "352/352 - 104s - loss: 0.0600 - accuracy: 0.9822 - val_loss: 0.1628 - val_accuracy: 0.9607 - 104s/epoch - 295ms/step\n",
      "Epoch 36/100\n",
      "352/352 - 103s - loss: 0.0397 - accuracy: 0.9883 - val_loss: 0.1679 - val_accuracy: 0.9620 - 103s/epoch - 294ms/step\n",
      "Epoch 37/100\n",
      "352/352 - 104s - loss: 0.0412 - accuracy: 0.9882 - val_loss: 0.1570 - val_accuracy: 0.9593 - 104s/epoch - 294ms/step\n",
      "Epoch 38/100\n",
      "352/352 - 105s - loss: 0.0502 - accuracy: 0.9854 - val_loss: 0.1634 - val_accuracy: 0.9612 - 105s/epoch - 297ms/step\n",
      "Epoch 39/100\n",
      "352/352 - 106s - loss: 0.0526 - accuracy: 0.9849 - val_loss: 0.1705 - val_accuracy: 0.9626 - 106s/epoch - 301ms/step\n",
      "Epoch 40/100\n",
      "352/352 - 107s - loss: 0.0470 - accuracy: 0.9861 - val_loss: 0.1509 - val_accuracy: 0.9606 - 107s/epoch - 305ms/step\n",
      "Epoch 41/100\n",
      "352/352 - 104s - loss: 0.0457 - accuracy: 0.9867 - val_loss: 0.1458 - val_accuracy: 0.9634 - 104s/epoch - 297ms/step\n",
      "Epoch 42/100\n",
      "352/352 - 104s - loss: 0.0308 - accuracy: 0.9913 - val_loss: 0.2460 - val_accuracy: 0.9479 - 104s/epoch - 296ms/step\n",
      "Epoch 43/100\n",
      "352/352 - 104s - loss: 0.0511 - accuracy: 0.9852 - val_loss: 0.1579 - val_accuracy: 0.9630 - 104s/epoch - 295ms/step\n",
      "Epoch 44/100\n",
      "352/352 - 104s - loss: 0.0421 - accuracy: 0.9878 - val_loss: 0.1762 - val_accuracy: 0.9583 - 104s/epoch - 296ms/step\n",
      "Epoch 45/100\n",
      "352/352 - 103s - loss: 0.0489 - accuracy: 0.9855 - val_loss: 0.1871 - val_accuracy: 0.9540 - 103s/epoch - 294ms/step\n",
      "Epoch 46/100\n",
      "352/352 - 106s - loss: 0.0341 - accuracy: 0.9900 - val_loss: 0.1856 - val_accuracy: 0.9589 - 106s/epoch - 300ms/step\n",
      "Epoch 47/100\n",
      "352/352 - 107s - loss: 0.0468 - accuracy: 0.9867 - val_loss: 0.1743 - val_accuracy: 0.9617 - 107s/epoch - 305ms/step\n",
      "Epoch 48/100\n",
      "352/352 - 104s - loss: 0.0409 - accuracy: 0.9880 - val_loss: 0.1996 - val_accuracy: 0.9557 - 104s/epoch - 295ms/step\n",
      "Epoch 49/100\n",
      "352/352 - 105s - loss: 0.0406 - accuracy: 0.9881 - val_loss: 0.1640 - val_accuracy: 0.9607 - 105s/epoch - 297ms/step\n",
      "Epoch 50/100\n",
      "352/352 - 104s - loss: 0.0379 - accuracy: 0.9887 - val_loss: 0.2012 - val_accuracy: 0.9592 - 104s/epoch - 296ms/step\n",
      "Epoch 51/100\n",
      "352/352 - 103s - loss: 0.0424 - accuracy: 0.9878 - val_loss: 0.1948 - val_accuracy: 0.9565 - 103s/epoch - 294ms/step\n",
      "Epoch 52/100\n",
      "352/352 - 103s - loss: 0.0404 - accuracy: 0.9880 - val_loss: 0.2151 - val_accuracy: 0.9542 - 103s/epoch - 292ms/step\n",
      "Epoch 53/100\n",
      "352/352 - 104s - loss: 0.0424 - accuracy: 0.9883 - val_loss: 0.1613 - val_accuracy: 0.9633 - 104s/epoch - 295ms/step\n",
      "Epoch 54/100\n",
      "352/352 - 103s - loss: 0.0363 - accuracy: 0.9893 - val_loss: 0.1534 - val_accuracy: 0.9643 - 103s/epoch - 293ms/step\n",
      "Epoch 55/100\n",
      "352/352 - 103s - loss: 0.0367 - accuracy: 0.9891 - val_loss: 0.1814 - val_accuracy: 0.9568 - 103s/epoch - 292ms/step\n",
      "Epoch 56/100\n",
      "352/352 - 103s - loss: 0.0402 - accuracy: 0.9880 - val_loss: 0.1848 - val_accuracy: 0.9605 - 103s/epoch - 293ms/step\n",
      "Epoch 57/100\n",
      "352/352 - 102s - loss: 0.0430 - accuracy: 0.9874 - val_loss: 0.1539 - val_accuracy: 0.9605 - 102s/epoch - 289ms/step\n",
      "Epoch 58/100\n",
      "352/352 - 102s - loss: 0.0303 - accuracy: 0.9909 - val_loss: 0.1556 - val_accuracy: 0.9638 - 102s/epoch - 289ms/step\n",
      "Epoch 59/100\n",
      "352/352 - 104s - loss: 0.0366 - accuracy: 0.9895 - val_loss: 0.1556 - val_accuracy: 0.9607 - 104s/epoch - 295ms/step\n",
      "Epoch 60/100\n",
      "352/352 - 103s - loss: 0.0460 - accuracy: 0.9871 - val_loss: 0.1774 - val_accuracy: 0.9527 - 103s/epoch - 292ms/step\n",
      "Epoch 61/100\n",
      "352/352 - 103s - loss: 0.0482 - accuracy: 0.9859 - val_loss: 0.1596 - val_accuracy: 0.9591 - 103s/epoch - 294ms/step\n",
      "Epoch 62/100\n",
      "352/352 - 103s - loss: 0.0382 - accuracy: 0.9893 - val_loss: 0.1760 - val_accuracy: 0.9589 - 103s/epoch - 294ms/step\n",
      "Epoch 63/100\n",
      "352/352 - 103s - loss: 0.0323 - accuracy: 0.9899 - val_loss: 0.1495 - val_accuracy: 0.9650 - 103s/epoch - 291ms/step\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 - 103s - loss: 0.0310 - accuracy: 0.9906 - val_loss: 0.1576 - val_accuracy: 0.9638 - 103s/epoch - 293ms/step\n",
      "Epoch 65/100\n",
      "352/352 - 104s - loss: 0.0309 - accuracy: 0.9915 - val_loss: 0.1564 - val_accuracy: 0.9643 - 104s/epoch - 296ms/step\n",
      "Epoch 66/100\n",
      "352/352 - 103s - loss: 0.0337 - accuracy: 0.9902 - val_loss: 0.1643 - val_accuracy: 0.9569 - 103s/epoch - 291ms/step\n",
      "Epoch 67/100\n",
      "352/352 - 101s - loss: 0.0444 - accuracy: 0.9875 - val_loss: 0.1532 - val_accuracy: 0.9607 - 101s/epoch - 288ms/step\n",
      "Epoch 68/100\n",
      "352/352 - 103s - loss: 0.0385 - accuracy: 0.9887 - val_loss: 0.1447 - val_accuracy: 0.9664 - 103s/epoch - 293ms/step\n",
      "Epoch 69/100\n",
      "352/352 - 103s - loss: 0.0317 - accuracy: 0.9910 - val_loss: 0.1357 - val_accuracy: 0.9673 - 103s/epoch - 293ms/step\n",
      "Epoch 70/100\n",
      "352/352 - 103s - loss: 0.0310 - accuracy: 0.9911 - val_loss: 0.1907 - val_accuracy: 0.9551 - 103s/epoch - 293ms/step\n",
      "Epoch 71/100\n",
      "352/352 - 104s - loss: 0.0405 - accuracy: 0.9886 - val_loss: 0.1743 - val_accuracy: 0.9579 - 104s/epoch - 295ms/step\n",
      "Epoch 72/100\n",
      "352/352 - 104s - loss: 0.0525 - accuracy: 0.9844 - val_loss: 0.1665 - val_accuracy: 0.9616 - 104s/epoch - 295ms/step\n",
      "Epoch 73/100\n",
      "352/352 - 103s - loss: 0.0386 - accuracy: 0.9888 - val_loss: 0.1884 - val_accuracy: 0.9548 - 103s/epoch - 293ms/step\n",
      "Epoch 74/100\n",
      "352/352 - 102s - loss: 0.0329 - accuracy: 0.9900 - val_loss: 0.1647 - val_accuracy: 0.9638 - 102s/epoch - 290ms/step\n",
      "Epoch 75/100\n",
      "352/352 - 97s - loss: 0.0315 - accuracy: 0.9908 - val_loss: 0.1634 - val_accuracy: 0.9648 - 97s/epoch - 277ms/step\n",
      "Epoch 76/100\n",
      "352/352 - 95s - loss: 0.0390 - accuracy: 0.9891 - val_loss: 0.1901 - val_accuracy: 0.9565 - 95s/epoch - 269ms/step\n",
      "Epoch 77/100\n",
      "352/352 - 94s - loss: 0.0412 - accuracy: 0.9881 - val_loss: 0.1587 - val_accuracy: 0.9624 - 94s/epoch - 268ms/step\n",
      "Epoch 78/100\n",
      "352/352 - 94s - loss: 0.0415 - accuracy: 0.9879 - val_loss: 0.1594 - val_accuracy: 0.9577 - 94s/epoch - 268ms/step\n",
      "Epoch 79/100\n",
      "352/352 - 93s - loss: 0.0366 - accuracy: 0.9895 - val_loss: 0.1621 - val_accuracy: 0.9613 - 93s/epoch - 264ms/step\n",
      "Epoch 80/100\n",
      "352/352 - 94s - loss: 0.0397 - accuracy: 0.9887 - val_loss: 0.1674 - val_accuracy: 0.9627 - 94s/epoch - 266ms/step\n",
      "Epoch 81/100\n",
      "352/352 - 96s - loss: 0.0462 - accuracy: 0.9870 - val_loss: 0.1757 - val_accuracy: 0.9604 - 96s/epoch - 272ms/step\n",
      "Epoch 82/100\n",
      "352/352 - 83s - loss: 0.0427 - accuracy: 0.9873 - val_loss: 0.1462 - val_accuracy: 0.9628 - 83s/epoch - 236ms/step\n",
      "Epoch 83/100\n",
      "352/352 - 94s - loss: 0.0281 - accuracy: 0.9916 - val_loss: 0.1794 - val_accuracy: 0.9631 - 94s/epoch - 267ms/step\n",
      "Epoch 84/100\n",
      "352/352 - 94s - loss: 0.0322 - accuracy: 0.9904 - val_loss: 0.1582 - val_accuracy: 0.9639 - 94s/epoch - 266ms/step\n",
      "Epoch 85/100\n",
      "352/352 - 95s - loss: 0.0322 - accuracy: 0.9905 - val_loss: 0.1694 - val_accuracy: 0.9601 - 95s/epoch - 270ms/step\n",
      "Epoch 86/100\n",
      "352/352 - 95s - loss: 0.0447 - accuracy: 0.9870 - val_loss: 0.1553 - val_accuracy: 0.9584 - 95s/epoch - 271ms/step\n",
      "Epoch 87/100\n",
      "352/352 - 95s - loss: 0.0321 - accuracy: 0.9904 - val_loss: 0.1949 - val_accuracy: 0.9565 - 95s/epoch - 269ms/step\n",
      "Epoch 88/100\n",
      "352/352 - 83s - loss: 0.0330 - accuracy: 0.9900 - val_loss: 0.1663 - val_accuracy: 0.9613 - 83s/epoch - 236ms/step\n",
      "Epoch 89/100\n",
      "352/352 - 95s - loss: 0.0365 - accuracy: 0.9897 - val_loss: 0.1584 - val_accuracy: 0.9647 - 95s/epoch - 269ms/step\n",
      "Epoch 90/100\n",
      "352/352 - 97s - loss: 0.0335 - accuracy: 0.9902 - val_loss: 0.1723 - val_accuracy: 0.9622 - 97s/epoch - 276ms/step\n",
      "Epoch 91/100\n",
      "352/352 - 95s - loss: 0.0335 - accuracy: 0.9905 - val_loss: 0.1704 - val_accuracy: 0.9621 - 95s/epoch - 269ms/step\n",
      "Epoch 92/100\n",
      "352/352 - 96s - loss: 0.0432 - accuracy: 0.9881 - val_loss: 0.1547 - val_accuracy: 0.9655 - 96s/epoch - 272ms/step\n",
      "Epoch 93/100\n",
      "352/352 - 96s - loss: 0.0400 - accuracy: 0.9888 - val_loss: 0.1659 - val_accuracy: 0.9617 - 96s/epoch - 272ms/step\n",
      "Epoch 94/100\n",
      "352/352 - 98s - loss: 0.0354 - accuracy: 0.9893 - val_loss: 0.1669 - val_accuracy: 0.9621 - 98s/epoch - 279ms/step\n",
      "Epoch 95/100\n",
      "352/352 - 97s - loss: 0.0327 - accuracy: 0.9905 - val_loss: 0.1688 - val_accuracy: 0.9617 - 97s/epoch - 275ms/step\n",
      "Epoch 96/100\n",
      "352/352 - 96s - loss: 0.0315 - accuracy: 0.9909 - val_loss: 0.1542 - val_accuracy: 0.9645 - 96s/epoch - 273ms/step\n",
      "Epoch 97/100\n",
      "352/352 - 97s - loss: 0.0419 - accuracy: 0.9877 - val_loss: 0.1607 - val_accuracy: 0.9609 - 97s/epoch - 274ms/step\n",
      "Epoch 98/100\n",
      "352/352 - 97s - loss: 0.0415 - accuracy: 0.9880 - val_loss: 0.1578 - val_accuracy: 0.9621 - 97s/epoch - 276ms/step\n",
      "Epoch 99/100\n",
      "352/352 - 97s - loss: 0.0332 - accuracy: 0.9897 - val_loss: 0.1644 - val_accuracy: 0.9587 - 97s/epoch - 275ms/step\n",
      "Epoch 100/100\n",
      "352/352 - 94s - loss: 0.0394 - accuracy: 0.9878 - val_loss: 0.1821 - val_accuracy: 0.9568 - 94s/epoch - 268ms/step\n",
      "[0.980400025844574, 0.9567999839782715, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "79/79 [==============================] - 7s 86ms/step - loss: 0.1335 - accuracy: 0.9741\n",
      "[0.9822999835014343, 0.9740999937057495, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Epoch 1/100\n",
      "352/352 - 115s - loss: 1.3150 - accuracy: 0.5402 - val_loss: 0.6320 - val_accuracy: 0.7852 - 115s/epoch - 327ms/step\n",
      "Epoch 2/100\n",
      "352/352 - 98s - loss: 0.5519 - accuracy: 0.8198 - val_loss: 0.4152 - val_accuracy: 0.8664 - 98s/epoch - 279ms/step\n",
      "Epoch 3/100\n",
      "352/352 - 97s - loss: 0.4084 - accuracy: 0.8706 - val_loss: 0.3327 - val_accuracy: 0.8911 - 97s/epoch - 275ms/step\n",
      "Epoch 4/100\n",
      "352/352 - 97s - loss: 0.3338 - accuracy: 0.8952 - val_loss: 0.3713 - val_accuracy: 0.8847 - 97s/epoch - 275ms/step\n",
      "Epoch 5/100\n",
      "352/352 - 100s - loss: 0.2969 - accuracy: 0.9070 - val_loss: 0.3172 - val_accuracy: 0.9001 - 100s/epoch - 285ms/step\n",
      "Epoch 6/100\n",
      "352/352 - 106s - loss: 0.2627 - accuracy: 0.9168 - val_loss: 0.3381 - val_accuracy: 0.8949 - 106s/epoch - 300ms/step\n",
      "Epoch 7/100\n",
      "352/352 - 106s - loss: 0.2451 - accuracy: 0.9229 - val_loss: 0.3296 - val_accuracy: 0.8953 - 106s/epoch - 302ms/step\n",
      "Epoch 8/100\n",
      "352/352 - 105s - loss: 0.2152 - accuracy: 0.9324 - val_loss: 0.3731 - val_accuracy: 0.8831 - 105s/epoch - 300ms/step\n",
      "Epoch 9/100\n",
      "352/352 - 104s - loss: 0.2082 - accuracy: 0.9353 - val_loss: 0.2855 - val_accuracy: 0.9150 - 104s/epoch - 296ms/step\n",
      "Epoch 10/100\n",
      "352/352 - 105s - loss: 0.2007 - accuracy: 0.9374 - val_loss: 0.2819 - val_accuracy: 0.9135 - 105s/epoch - 298ms/step\n",
      "Epoch 11/100\n",
      "352/352 - 105s - loss: 0.1843 - accuracy: 0.9429 - val_loss: 0.2634 - val_accuracy: 0.9209 - 105s/epoch - 299ms/step\n",
      "Epoch 12/100\n",
      "352/352 - 105s - loss: 0.1798 - accuracy: 0.9437 - val_loss: 0.2962 - val_accuracy: 0.9077 - 105s/epoch - 298ms/step\n",
      "Epoch 13/100\n",
      "352/352 - 105s - loss: 0.1646 - accuracy: 0.9492 - val_loss: 0.2936 - val_accuracy: 0.9089 - 105s/epoch - 298ms/step\n",
      "Epoch 14/100\n",
      "352/352 - 104s - loss: 0.1528 - accuracy: 0.9529 - val_loss: 0.3132 - val_accuracy: 0.9078 - 104s/epoch - 296ms/step\n",
      "Epoch 15/100\n",
      "352/352 - 105s - loss: 0.1446 - accuracy: 0.9551 - val_loss: 0.2830 - val_accuracy: 0.9151 - 105s/epoch - 299ms/step\n",
      "Epoch 16/100\n",
      "352/352 - 105s - loss: 0.1393 - accuracy: 0.9567 - val_loss: 0.2737 - val_accuracy: 0.9212 - 105s/epoch - 299ms/step\n",
      "Epoch 17/100\n",
      "352/352 - 106s - loss: 0.1271 - accuracy: 0.9600 - val_loss: 0.2819 - val_accuracy: 0.9189 - 106s/epoch - 302ms/step\n",
      "Epoch 18/100\n",
      "352/352 - 108s - loss: 0.1298 - accuracy: 0.9603 - val_loss: 0.2780 - val_accuracy: 0.9169 - 108s/epoch - 307ms/step\n",
      "Epoch 19/100\n",
      "352/352 - 108s - loss: 0.1285 - accuracy: 0.9594 - val_loss: 0.2916 - val_accuracy: 0.9124 - 108s/epoch - 308ms/step\n",
      "Epoch 20/100\n",
      "352/352 - 105s - loss: 0.1104 - accuracy: 0.9665 - val_loss: 0.3080 - val_accuracy: 0.9191 - 105s/epoch - 299ms/step\n",
      "Epoch 21/100\n",
      "352/352 - 105s - loss: 0.1166 - accuracy: 0.9639 - val_loss: 0.2845 - val_accuracy: 0.9166 - 105s/epoch - 300ms/step\n",
      "Epoch 22/100\n",
      "352/352 - 105s - loss: 0.1076 - accuracy: 0.9671 - val_loss: 0.3129 - val_accuracy: 0.9190 - 105s/epoch - 297ms/step\n",
      "Epoch 23/100\n",
      "352/352 - 105s - loss: 0.1098 - accuracy: 0.9662 - val_loss: 0.3116 - val_accuracy: 0.9187 - 105s/epoch - 299ms/step\n",
      "Epoch 24/100\n",
      "352/352 - 105s - loss: 0.0979 - accuracy: 0.9695 - val_loss: 0.3018 - val_accuracy: 0.9161 - 105s/epoch - 298ms/step\n",
      "Epoch 25/100\n",
      "352/352 - 103s - loss: 0.1092 - accuracy: 0.9668 - val_loss: 0.3118 - val_accuracy: 0.9186 - 103s/epoch - 294ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "352/352 - 104s - loss: 0.0931 - accuracy: 0.9713 - val_loss: 0.2809 - val_accuracy: 0.9209 - 104s/epoch - 295ms/step\n",
      "Epoch 27/100\n",
      "352/352 - 105s - loss: 0.0878 - accuracy: 0.9726 - val_loss: 0.2810 - val_accuracy: 0.9176 - 105s/epoch - 298ms/step\n",
      "Epoch 28/100\n",
      "352/352 - 104s - loss: 0.0924 - accuracy: 0.9717 - val_loss: 0.3005 - val_accuracy: 0.9143 - 104s/epoch - 295ms/step\n",
      "Epoch 29/100\n",
      "352/352 - 103s - loss: 0.0908 - accuracy: 0.9715 - val_loss: 0.2964 - val_accuracy: 0.9210 - 103s/epoch - 293ms/step\n",
      "Epoch 30/100\n",
      "352/352 - 102s - loss: 0.0870 - accuracy: 0.9737 - val_loss: 0.2997 - val_accuracy: 0.9180 - 102s/epoch - 291ms/step\n",
      "Epoch 31/100\n",
      "352/352 - 102s - loss: 0.0925 - accuracy: 0.9710 - val_loss: 0.3180 - val_accuracy: 0.9155 - 102s/epoch - 290ms/step\n",
      "Epoch 32/100\n",
      "352/352 - 103s - loss: 0.0898 - accuracy: 0.9724 - val_loss: 0.3597 - val_accuracy: 0.9245 - 103s/epoch - 294ms/step\n",
      "Epoch 33/100\n",
      "352/352 - 103s - loss: 0.0783 - accuracy: 0.9762 - val_loss: 0.3007 - val_accuracy: 0.9214 - 103s/epoch - 291ms/step\n",
      "Epoch 34/100\n",
      "352/352 - 104s - loss: 0.0875 - accuracy: 0.9729 - val_loss: 0.3299 - val_accuracy: 0.9173 - 104s/epoch - 296ms/step\n",
      "Epoch 35/100\n",
      "352/352 - 106s - loss: 0.0872 - accuracy: 0.9726 - val_loss: 0.3122 - val_accuracy: 0.9222 - 106s/epoch - 300ms/step\n",
      "Epoch 36/100\n",
      "352/352 - 105s - loss: 0.0835 - accuracy: 0.9748 - val_loss: 0.3084 - val_accuracy: 0.9189 - 105s/epoch - 298ms/step\n",
      "Epoch 37/100\n",
      "352/352 - 104s - loss: 0.0792 - accuracy: 0.9746 - val_loss: 0.3830 - val_accuracy: 0.9161 - 104s/epoch - 296ms/step\n",
      "Epoch 38/100\n",
      "352/352 - 104s - loss: 0.0759 - accuracy: 0.9766 - val_loss: 0.3327 - val_accuracy: 0.9149 - 104s/epoch - 294ms/step\n",
      "Epoch 39/100\n",
      "352/352 - 104s - loss: 0.0765 - accuracy: 0.9760 - val_loss: 0.3175 - val_accuracy: 0.9221 - 104s/epoch - 297ms/step\n",
      "Epoch 40/100\n",
      "352/352 - 105s - loss: 0.0768 - accuracy: 0.9767 - val_loss: 0.3249 - val_accuracy: 0.9169 - 105s/epoch - 298ms/step\n",
      "Epoch 41/100\n",
      "352/352 - 105s - loss: 0.0734 - accuracy: 0.9770 - val_loss: 0.3411 - val_accuracy: 0.9149 - 105s/epoch - 297ms/step\n",
      "Epoch 42/100\n",
      "352/352 - 105s - loss: 0.0745 - accuracy: 0.9761 - val_loss: 0.3173 - val_accuracy: 0.9209 - 105s/epoch - 298ms/step\n",
      "Epoch 43/100\n",
      "352/352 - 103s - loss: 0.0766 - accuracy: 0.9766 - val_loss: 0.2864 - val_accuracy: 0.9197 - 103s/epoch - 294ms/step\n",
      "Epoch 44/100\n",
      "352/352 - 104s - loss: 0.0707 - accuracy: 0.9788 - val_loss: 0.3274 - val_accuracy: 0.9225 - 104s/epoch - 296ms/step\n",
      "Epoch 45/100\n",
      "352/352 - 104s - loss: 0.0749 - accuracy: 0.9761 - val_loss: 0.3067 - val_accuracy: 0.9224 - 104s/epoch - 296ms/step\n",
      "Epoch 46/100\n",
      "352/352 - 103s - loss: 0.0748 - accuracy: 0.9775 - val_loss: 0.3101 - val_accuracy: 0.9191 - 103s/epoch - 293ms/step\n",
      "Epoch 47/100\n",
      "352/352 - 103s - loss: 0.0686 - accuracy: 0.9790 - val_loss: 0.3535 - val_accuracy: 0.9129 - 103s/epoch - 293ms/step\n",
      "Epoch 48/100\n",
      "352/352 - 103s - loss: 0.0611 - accuracy: 0.9814 - val_loss: 0.3606 - val_accuracy: 0.9170 - 103s/epoch - 294ms/step\n",
      "Epoch 49/100\n",
      "352/352 - 104s - loss: 0.0703 - accuracy: 0.9780 - val_loss: 0.3669 - val_accuracy: 0.9184 - 104s/epoch - 296ms/step\n",
      "Epoch 50/100\n",
      "352/352 - 106s - loss: 0.0690 - accuracy: 0.9797 - val_loss: 0.3351 - val_accuracy: 0.9178 - 106s/epoch - 303ms/step\n",
      "Epoch 51/100\n",
      "352/352 - 105s - loss: 0.0682 - accuracy: 0.9785 - val_loss: 0.2982 - val_accuracy: 0.9204 - 105s/epoch - 297ms/step\n",
      "Epoch 52/100\n",
      "352/352 - 104s - loss: 0.0638 - accuracy: 0.9802 - val_loss: 0.3548 - val_accuracy: 0.9171 - 104s/epoch - 295ms/step\n",
      "Epoch 53/100\n",
      "352/352 - 108s - loss: 0.0767 - accuracy: 0.9772 - val_loss: 0.3377 - val_accuracy: 0.9209 - 108s/epoch - 306ms/step\n",
      "Epoch 54/100\n",
      "352/352 - 105s - loss: 0.0685 - accuracy: 0.9786 - val_loss: 0.3549 - val_accuracy: 0.9161 - 105s/epoch - 299ms/step\n",
      "Epoch 55/100\n",
      "352/352 - 106s - loss: 0.0634 - accuracy: 0.9806 - val_loss: 0.3231 - val_accuracy: 0.9143 - 106s/epoch - 300ms/step\n",
      "Epoch 56/100\n",
      "352/352 - 104s - loss: 0.0737 - accuracy: 0.9766 - val_loss: 0.3161 - val_accuracy: 0.9201 - 104s/epoch - 297ms/step\n",
      "Epoch 57/100\n",
      "352/352 - 103s - loss: 0.0698 - accuracy: 0.9776 - val_loss: 0.3028 - val_accuracy: 0.9218 - 103s/epoch - 293ms/step\n",
      "Epoch 58/100\n",
      "352/352 - 104s - loss: 0.0673 - accuracy: 0.9792 - val_loss: 0.3164 - val_accuracy: 0.9223 - 104s/epoch - 296ms/step\n",
      "Epoch 59/100\n",
      "352/352 - 104s - loss: 0.0601 - accuracy: 0.9819 - val_loss: 0.3571 - val_accuracy: 0.9149 - 104s/epoch - 296ms/step\n",
      "Epoch 60/100\n",
      "352/352 - 104s - loss: 0.0678 - accuracy: 0.9788 - val_loss: 0.3580 - val_accuracy: 0.9184 - 104s/epoch - 295ms/step\n",
      "Epoch 61/100\n",
      "352/352 - 103s - loss: 0.0799 - accuracy: 0.9754 - val_loss: 0.3287 - val_accuracy: 0.9247 - 103s/epoch - 292ms/step\n",
      "Epoch 62/100\n",
      "352/352 - 103s - loss: 0.0683 - accuracy: 0.9788 - val_loss: 0.2999 - val_accuracy: 0.9187 - 103s/epoch - 293ms/step\n",
      "Epoch 63/100\n",
      "352/352 - 103s - loss: 0.0717 - accuracy: 0.9778 - val_loss: 0.3531 - val_accuracy: 0.9188 - 103s/epoch - 292ms/step\n",
      "Epoch 64/100\n",
      "352/352 - 103s - loss: 0.0610 - accuracy: 0.9807 - val_loss: 0.3096 - val_accuracy: 0.9233 - 103s/epoch - 291ms/step\n",
      "Epoch 65/100\n",
      "352/352 - 103s - loss: 0.0715 - accuracy: 0.9780 - val_loss: 0.3219 - val_accuracy: 0.9245 - 103s/epoch - 293ms/step\n",
      "Epoch 66/100\n",
      "352/352 - 103s - loss: 0.0738 - accuracy: 0.9774 - val_loss: 0.2961 - val_accuracy: 0.9229 - 103s/epoch - 292ms/step\n",
      "Epoch 67/100\n",
      "352/352 - 103s - loss: 0.0641 - accuracy: 0.9801 - val_loss: 0.2938 - val_accuracy: 0.9236 - 103s/epoch - 292ms/step\n",
      "Epoch 68/100\n",
      "352/352 - 103s - loss: 0.0572 - accuracy: 0.9823 - val_loss: 0.3211 - val_accuracy: 0.9231 - 103s/epoch - 294ms/step\n",
      "Epoch 69/100\n",
      "352/352 - 101s - loss: 0.0620 - accuracy: 0.9805 - val_loss: 0.3245 - val_accuracy: 0.9210 - 101s/epoch - 286ms/step\n",
      "Epoch 70/100\n",
      "352/352 - 101s - loss: 0.0614 - accuracy: 0.9811 - val_loss: 0.3319 - val_accuracy: 0.9135 - 101s/epoch - 286ms/step\n",
      "Epoch 71/100\n",
      "352/352 - 102s - loss: 0.0751 - accuracy: 0.9763 - val_loss: 0.2840 - val_accuracy: 0.9252 - 102s/epoch - 290ms/step\n",
      "Epoch 72/100\n",
      "352/352 - 102s - loss: 0.0651 - accuracy: 0.9800 - val_loss: 0.3222 - val_accuracy: 0.9215 - 102s/epoch - 289ms/step\n",
      "Epoch 73/100\n",
      "352/352 - 102s - loss: 0.0660 - accuracy: 0.9798 - val_loss: 0.3431 - val_accuracy: 0.9189 - 102s/epoch - 290ms/step\n",
      "Epoch 74/100\n",
      "352/352 - 101s - loss: 0.0750 - accuracy: 0.9770 - val_loss: 0.3029 - val_accuracy: 0.9207 - 101s/epoch - 288ms/step\n",
      "Epoch 75/100\n",
      "352/352 - 88s - loss: 0.0674 - accuracy: 0.9794 - val_loss: 0.2922 - val_accuracy: 0.9221 - 88s/epoch - 249ms/step\n",
      "Epoch 76/100\n",
      "352/352 - 96s - loss: 0.0571 - accuracy: 0.9826 - val_loss: 0.3175 - val_accuracy: 0.9207 - 96s/epoch - 273ms/step\n",
      "Epoch 77/100\n",
      "352/352 - 98s - loss: 0.0638 - accuracy: 0.9803 - val_loss: 0.3621 - val_accuracy: 0.9107 - 98s/epoch - 278ms/step\n",
      "Epoch 78/100\n",
      "352/352 - 98s - loss: 0.0693 - accuracy: 0.9788 - val_loss: 0.3337 - val_accuracy: 0.9233 - 98s/epoch - 278ms/step\n",
      "Epoch 79/100\n",
      "352/352 - 98s - loss: 0.0764 - accuracy: 0.9759 - val_loss: 0.2927 - val_accuracy: 0.9220 - 98s/epoch - 279ms/step\n",
      "Epoch 80/100\n",
      "352/352 - 98s - loss: 0.0666 - accuracy: 0.9796 - val_loss: 0.2915 - val_accuracy: 0.9233 - 98s/epoch - 278ms/step\n",
      "Epoch 81/100\n",
      "352/352 - 97s - loss: 0.0584 - accuracy: 0.9819 - val_loss: 0.3268 - val_accuracy: 0.9192 - 97s/epoch - 277ms/step\n",
      "Epoch 82/100\n",
      "352/352 - 97s - loss: 0.0677 - accuracy: 0.9782 - val_loss: 0.3207 - val_accuracy: 0.9183 - 97s/epoch - 277ms/step\n",
      "Epoch 83/100\n",
      "352/352 - 97s - loss: 0.0631 - accuracy: 0.9803 - val_loss: 0.3210 - val_accuracy: 0.9216 - 97s/epoch - 276ms/step\n",
      "Epoch 84/100\n",
      "352/352 - 98s - loss: 0.0639 - accuracy: 0.9800 - val_loss: 0.3019 - val_accuracy: 0.9220 - 98s/epoch - 278ms/step\n",
      "Epoch 85/100\n",
      "352/352 - 98s - loss: 0.0623 - accuracy: 0.9802 - val_loss: 0.3148 - val_accuracy: 0.9199 - 98s/epoch - 279ms/step\n",
      "Epoch 86/100\n",
      "352/352 - 99s - loss: 0.0662 - accuracy: 0.9793 - val_loss: 0.3422 - val_accuracy: 0.9125 - 99s/epoch - 280ms/step\n",
      "Epoch 87/100\n",
      "352/352 - 100s - loss: 0.0725 - accuracy: 0.9778 - val_loss: 0.3195 - val_accuracy: 0.9228 - 100s/epoch - 284ms/step\n",
      "Epoch 88/100\n",
      "352/352 - 100s - loss: 0.0571 - accuracy: 0.9816 - val_loss: 0.3502 - val_accuracy: 0.9194 - 100s/epoch - 285ms/step\n",
      "Epoch 89/100\n",
      "352/352 - 101s - loss: 0.0695 - accuracy: 0.9776 - val_loss: 0.3434 - val_accuracy: 0.9206 - 101s/epoch - 286ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100\n",
      "352/352 - 98s - loss: 0.0713 - accuracy: 0.9775 - val_loss: 0.3233 - val_accuracy: 0.9232 - 98s/epoch - 279ms/step\n",
      "Epoch 91/100\n",
      "352/352 - 97s - loss: 0.0585 - accuracy: 0.9821 - val_loss: 0.3256 - val_accuracy: 0.9197 - 97s/epoch - 276ms/step\n",
      "Epoch 92/100\n",
      "352/352 - 100s - loss: 0.0622 - accuracy: 0.9799 - val_loss: 0.3385 - val_accuracy: 0.9229 - 100s/epoch - 283ms/step\n",
      "Epoch 93/100\n",
      "352/352 - 100s - loss: 0.0596 - accuracy: 0.9813 - val_loss: 0.3048 - val_accuracy: 0.9263 - 100s/epoch - 283ms/step\n",
      "Epoch 94/100\n",
      "352/352 - 98s - loss: 0.0614 - accuracy: 0.9807 - val_loss: 0.3710 - val_accuracy: 0.9196 - 98s/epoch - 280ms/step\n",
      "Epoch 95/100\n",
      "352/352 - 99s - loss: 0.0633 - accuracy: 0.9809 - val_loss: 0.3121 - val_accuracy: 0.9253 - 99s/epoch - 280ms/step\n",
      "Epoch 96/100\n",
      "352/352 - 99s - loss: 0.0712 - accuracy: 0.9785 - val_loss: 0.3113 - val_accuracy: 0.9225 - 99s/epoch - 282ms/step\n",
      "Epoch 97/100\n",
      "352/352 - 98s - loss: 0.0597 - accuracy: 0.9814 - val_loss: 0.3324 - val_accuracy: 0.9227 - 98s/epoch - 280ms/step\n",
      "Epoch 98/100\n",
      "352/352 - 98s - loss: 0.0788 - accuracy: 0.9749 - val_loss: 0.3127 - val_accuracy: 0.9155 - 98s/epoch - 279ms/step\n",
      "Epoch 99/100\n",
      "352/352 - 98s - loss: 0.0657 - accuracy: 0.9794 - val_loss: 0.3514 - val_accuracy: 0.9159 - 98s/epoch - 278ms/step\n",
      "Epoch 100/100\n",
      "352/352 - 99s - loss: 0.0606 - accuracy: 0.9810 - val_loss: 0.3373 - val_accuracy: 0.9177 - 99s/epoch - 282ms/step\n",
      "[0.980400025844574, 0.9567999839782715, 0.9177333116531372, 0, 0, 0, 0, 0, 0, 0]\n",
      "79/79 [==============================] - 7s 91ms/step - loss: 0.1261 - accuracy: 0.9749\n",
      "[0.9822999835014343, 0.9740999937057495, 0.9749000072479248, 0, 0, 0, 0, 0, 0, 0]\n",
      "Epoch 1/100\n",
      "352/352 - 108s - loss: 1.6218 - accuracy: 0.4246 - val_loss: 0.9681 - val_accuracy: 0.6737 - 108s/epoch - 308ms/step\n",
      "Epoch 2/100\n",
      "352/352 - 76s - loss: 0.8758 - accuracy: 0.7030 - val_loss: 0.8032 - val_accuracy: 0.7359 - 76s/epoch - 215ms/step\n",
      "Epoch 3/100\n",
      "352/352 - 76s - loss: 0.7087 - accuracy: 0.7638 - val_loss: 0.6621 - val_accuracy: 0.7800 - 76s/epoch - 216ms/step\n",
      "Epoch 4/100\n",
      "352/352 - 76s - loss: 0.6095 - accuracy: 0.7994 - val_loss: 0.5855 - val_accuracy: 0.8081 - 76s/epoch - 215ms/step\n",
      "Epoch 5/100\n",
      "352/352 - 76s - loss: 0.5483 - accuracy: 0.8201 - val_loss: 0.5947 - val_accuracy: 0.8073 - 76s/epoch - 217ms/step\n",
      "Epoch 6/100\n",
      "352/352 - 76s - loss: 0.5082 - accuracy: 0.8344 - val_loss: 0.5310 - val_accuracy: 0.8269 - 76s/epoch - 217ms/step\n",
      "Epoch 7/100\n",
      "352/352 - 77s - loss: 0.4641 - accuracy: 0.8489 - val_loss: 0.5649 - val_accuracy: 0.8206 - 77s/epoch - 219ms/step\n",
      "Epoch 8/100\n",
      "352/352 - 78s - loss: 0.4354 - accuracy: 0.8596 - val_loss: 0.5471 - val_accuracy: 0.8213 - 78s/epoch - 220ms/step\n",
      "Epoch 9/100\n",
      "352/352 - 77s - loss: 0.4084 - accuracy: 0.8668 - val_loss: 0.5172 - val_accuracy: 0.8327 - 77s/epoch - 219ms/step\n",
      "Epoch 10/100\n",
      "352/352 - 78s - loss: 0.3747 - accuracy: 0.8795 - val_loss: 0.5309 - val_accuracy: 0.8294 - 78s/epoch - 221ms/step\n",
      "Epoch 11/100\n",
      "352/352 - 77s - loss: 0.3585 - accuracy: 0.8851 - val_loss: 0.5433 - val_accuracy: 0.8253 - 77s/epoch - 218ms/step\n",
      "Epoch 12/100\n",
      "352/352 - 77s - loss: 0.3340 - accuracy: 0.8916 - val_loss: 0.5175 - val_accuracy: 0.8394 - 77s/epoch - 218ms/step\n",
      "Epoch 13/100\n",
      "352/352 - 78s - loss: 0.3142 - accuracy: 0.8990 - val_loss: 0.6041 - val_accuracy: 0.8273 - 78s/epoch - 220ms/step\n",
      "Epoch 14/100\n",
      "352/352 - 77s - loss: 0.2920 - accuracy: 0.9053 - val_loss: 0.5368 - val_accuracy: 0.8375 - 77s/epoch - 220ms/step\n",
      "Epoch 15/100\n",
      "352/352 - 78s - loss: 0.2687 - accuracy: 0.9124 - val_loss: 0.5270 - val_accuracy: 0.8437 - 78s/epoch - 220ms/step\n",
      "Epoch 16/100\n",
      "352/352 - 77s - loss: 0.2635 - accuracy: 0.9152 - val_loss: 0.6139 - val_accuracy: 0.8291 - 77s/epoch - 218ms/step\n",
      "Epoch 17/100\n",
      "352/352 - 76s - loss: 0.2594 - accuracy: 0.9155 - val_loss: 0.5607 - val_accuracy: 0.8316 - 76s/epoch - 215ms/step\n",
      "Epoch 18/100\n",
      "352/352 - 76s - loss: 0.2371 - accuracy: 0.9243 - val_loss: 0.5875 - val_accuracy: 0.8283 - 76s/epoch - 217ms/step\n",
      "Epoch 19/100\n",
      "352/352 - 77s - loss: 0.2328 - accuracy: 0.9259 - val_loss: 0.5939 - val_accuracy: 0.8301 - 77s/epoch - 219ms/step\n",
      "Epoch 20/100\n",
      "352/352 - 77s - loss: 0.2196 - accuracy: 0.9292 - val_loss: 0.6949 - val_accuracy: 0.8246 - 77s/epoch - 220ms/step\n",
      "Epoch 21/100\n",
      "352/352 - 78s - loss: 0.2169 - accuracy: 0.9310 - val_loss: 0.5281 - val_accuracy: 0.8421 - 78s/epoch - 220ms/step\n",
      "Epoch 22/100\n",
      "352/352 - 77s - loss: 0.2165 - accuracy: 0.9314 - val_loss: 0.5820 - val_accuracy: 0.8313 - 77s/epoch - 219ms/step\n",
      "Epoch 23/100\n",
      "352/352 - 78s - loss: 0.2038 - accuracy: 0.9352 - val_loss: 0.6523 - val_accuracy: 0.8231 - 78s/epoch - 221ms/step\n",
      "Epoch 24/100\n",
      "352/352 - 78s - loss: 0.1873 - accuracy: 0.9397 - val_loss: 0.5851 - val_accuracy: 0.8285 - 78s/epoch - 221ms/step\n",
      "Epoch 25/100\n",
      "352/352 - 78s - loss: 0.1796 - accuracy: 0.9423 - val_loss: 0.5947 - val_accuracy: 0.8354 - 78s/epoch - 221ms/step\n",
      "Epoch 26/100\n",
      "352/352 - 78s - loss: 0.1930 - accuracy: 0.9394 - val_loss: 0.6389 - val_accuracy: 0.8261 - 78s/epoch - 221ms/step\n",
      "Epoch 27/100\n",
      "352/352 - 80s - loss: 0.1762 - accuracy: 0.9441 - val_loss: 0.6128 - val_accuracy: 0.8241 - 80s/epoch - 226ms/step\n",
      "Epoch 28/100\n",
      "352/352 - 78s - loss: 0.1769 - accuracy: 0.9432 - val_loss: 0.6475 - val_accuracy: 0.8299 - 78s/epoch - 221ms/step\n",
      "Epoch 29/100\n",
      "352/352 - 77s - loss: 0.1710 - accuracy: 0.9452 - val_loss: 0.6642 - val_accuracy: 0.8209 - 77s/epoch - 217ms/step\n",
      "Epoch 30/100\n",
      "352/352 - 78s - loss: 0.1805 - accuracy: 0.9419 - val_loss: 0.6751 - val_accuracy: 0.8281 - 78s/epoch - 222ms/step\n",
      "Epoch 31/100\n",
      "352/352 - 80s - loss: 0.1686 - accuracy: 0.9460 - val_loss: 0.6403 - val_accuracy: 0.8331 - 80s/epoch - 228ms/step\n",
      "Epoch 32/100\n",
      "352/352 - 77s - loss: 0.1652 - accuracy: 0.9479 - val_loss: 0.6705 - val_accuracy: 0.8281 - 77s/epoch - 220ms/step\n",
      "Epoch 33/100\n",
      "352/352 - 77s - loss: 0.1633 - accuracy: 0.9483 - val_loss: 0.7789 - val_accuracy: 0.8292 - 77s/epoch - 219ms/step\n",
      "Epoch 34/100\n",
      "352/352 - 77s - loss: 0.1649 - accuracy: 0.9468 - val_loss: 0.7024 - val_accuracy: 0.8247 - 77s/epoch - 219ms/step\n",
      "Epoch 35/100\n",
      "352/352 - 77s - loss: 0.1508 - accuracy: 0.9526 - val_loss: 0.7150 - val_accuracy: 0.8274 - 77s/epoch - 218ms/step\n",
      "Epoch 36/100\n",
      "352/352 - 77s - loss: 0.1463 - accuracy: 0.9537 - val_loss: 0.6473 - val_accuracy: 0.8224 - 77s/epoch - 217ms/step\n",
      "Epoch 37/100\n",
      "352/352 - 76s - loss: 0.1596 - accuracy: 0.9492 - val_loss: 0.6502 - val_accuracy: 0.8216 - 76s/epoch - 217ms/step\n",
      "Epoch 38/100\n",
      "352/352 - 76s - loss: 0.1592 - accuracy: 0.9490 - val_loss: 0.7019 - val_accuracy: 0.8296 - 76s/epoch - 217ms/step\n",
      "Epoch 39/100\n",
      "352/352 - 77s - loss: 0.1619 - accuracy: 0.9478 - val_loss: 0.7829 - val_accuracy: 0.8301 - 77s/epoch - 219ms/step\n",
      "Epoch 40/100\n",
      "352/352 - 76s - loss: 0.1443 - accuracy: 0.9552 - val_loss: 0.6842 - val_accuracy: 0.8230 - 76s/epoch - 215ms/step\n",
      "Epoch 41/100\n",
      "352/352 - 76s - loss: 0.1468 - accuracy: 0.9536 - val_loss: 0.6275 - val_accuracy: 0.8326 - 76s/epoch - 215ms/step\n",
      "Epoch 42/100\n",
      "352/352 - 76s - loss: 0.1594 - accuracy: 0.9487 - val_loss: 0.6664 - val_accuracy: 0.8297 - 76s/epoch - 216ms/step\n",
      "Epoch 43/100\n",
      "352/352 - 77s - loss: 0.1487 - accuracy: 0.9526 - val_loss: 0.7012 - val_accuracy: 0.8312 - 77s/epoch - 220ms/step\n",
      "Epoch 44/100\n",
      "352/352 - 77s - loss: 0.1449 - accuracy: 0.9534 - val_loss: 0.6897 - val_accuracy: 0.8267 - 77s/epoch - 219ms/step\n",
      "Epoch 45/100\n",
      "352/352 - 77s - loss: 0.1539 - accuracy: 0.9521 - val_loss: 0.6105 - val_accuracy: 0.8347 - 77s/epoch - 218ms/step\n",
      "Epoch 46/100\n",
      "352/352 - 77s - loss: 0.1470 - accuracy: 0.9532 - val_loss: 0.6729 - val_accuracy: 0.8334 - 77s/epoch - 220ms/step\n",
      "Epoch 47/100\n",
      "352/352 - 77s - loss: 0.1447 - accuracy: 0.9535 - val_loss: 0.8250 - val_accuracy: 0.8306 - 77s/epoch - 220ms/step\n",
      "Epoch 48/100\n",
      "352/352 - 77s - loss: 0.1401 - accuracy: 0.9550 - val_loss: 0.7292 - val_accuracy: 0.8197 - 77s/epoch - 220ms/step\n",
      "Epoch 49/100\n",
      "352/352 - 78s - loss: 0.1440 - accuracy: 0.9549 - val_loss: 0.6828 - val_accuracy: 0.8233 - 78s/epoch - 220ms/step\n",
      "Epoch 50/100\n",
      "352/352 - 77s - loss: 0.1333 - accuracy: 0.9576 - val_loss: 0.6912 - val_accuracy: 0.8357 - 77s/epoch - 218ms/step\n",
      "Epoch 51/100\n",
      "352/352 - 77s - loss: 0.1443 - accuracy: 0.9527 - val_loss: 0.6723 - val_accuracy: 0.8295 - 77s/epoch - 218ms/step\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 - 77s - loss: 0.1439 - accuracy: 0.9540 - val_loss: 0.6990 - val_accuracy: 0.8283 - 77s/epoch - 218ms/step\n",
      "Epoch 53/100\n",
      "352/352 - 78s - loss: 0.1456 - accuracy: 0.9534 - val_loss: 0.7255 - val_accuracy: 0.8216 - 78s/epoch - 220ms/step\n",
      "Epoch 54/100\n",
      "352/352 - 78s - loss: 0.1356 - accuracy: 0.9575 - val_loss: 0.6934 - val_accuracy: 0.8271 - 78s/epoch - 222ms/step\n",
      "Epoch 55/100\n",
      "352/352 - 78s - loss: 0.1362 - accuracy: 0.9556 - val_loss: 0.7016 - val_accuracy: 0.8266 - 78s/epoch - 222ms/step\n",
      "Epoch 56/100\n",
      "352/352 - 78s - loss: 0.1414 - accuracy: 0.9547 - val_loss: 0.6490 - val_accuracy: 0.8293 - 78s/epoch - 222ms/step\n",
      "Epoch 57/100\n",
      "352/352 - 78s - loss: 0.1403 - accuracy: 0.9545 - val_loss: 0.6514 - val_accuracy: 0.8297 - 78s/epoch - 223ms/step\n",
      "Epoch 58/100\n",
      "352/352 - 78s - loss: 0.1317 - accuracy: 0.9574 - val_loss: 0.6631 - val_accuracy: 0.8297 - 78s/epoch - 222ms/step\n",
      "Epoch 59/100\n",
      "352/352 - 78s - loss: 0.1405 - accuracy: 0.9551 - val_loss: 0.6782 - val_accuracy: 0.8291 - 78s/epoch - 222ms/step\n",
      "Epoch 60/100\n",
      "352/352 - 78s - loss: 0.1308 - accuracy: 0.9575 - val_loss: 0.6666 - val_accuracy: 0.8251 - 78s/epoch - 222ms/step\n",
      "Epoch 61/100\n",
      "352/352 - 78s - loss: 0.1264 - accuracy: 0.9594 - val_loss: 0.6731 - val_accuracy: 0.8344 - 78s/epoch - 223ms/step\n",
      "Epoch 62/100\n",
      "352/352 - 78s - loss: 0.1321 - accuracy: 0.9574 - val_loss: 0.6738 - val_accuracy: 0.8293 - 78s/epoch - 222ms/step\n",
      "Epoch 63/100\n",
      "352/352 - 78s - loss: 0.1334 - accuracy: 0.9591 - val_loss: 0.7475 - val_accuracy: 0.8229 - 78s/epoch - 222ms/step\n",
      "Epoch 64/100\n",
      "352/352 - 78s - loss: 0.1452 - accuracy: 0.9533 - val_loss: 0.6955 - val_accuracy: 0.8255 - 78s/epoch - 221ms/step\n",
      "Epoch 65/100\n",
      "352/352 - 77s - loss: 0.1366 - accuracy: 0.9572 - val_loss: 0.7530 - val_accuracy: 0.8307 - 77s/epoch - 219ms/step\n",
      "Epoch 66/100\n",
      "352/352 - 78s - loss: 0.1293 - accuracy: 0.9573 - val_loss: 0.8279 - val_accuracy: 0.8252 - 78s/epoch - 221ms/step\n",
      "Epoch 67/100\n",
      "352/352 - 77s - loss: 0.1343 - accuracy: 0.9577 - val_loss: 0.6816 - val_accuracy: 0.8370 - 77s/epoch - 218ms/step\n",
      "Epoch 68/100\n",
      "352/352 - 76s - loss: 0.1350 - accuracy: 0.9576 - val_loss: 0.7514 - val_accuracy: 0.8247 - 76s/epoch - 217ms/step\n",
      "Epoch 69/100\n",
      "352/352 - 76s - loss: 0.1273 - accuracy: 0.9590 - val_loss: 0.6884 - val_accuracy: 0.8299 - 76s/epoch - 217ms/step\n",
      "Epoch 70/100\n",
      "352/352 - 77s - loss: 0.1290 - accuracy: 0.9590 - val_loss: 0.7132 - val_accuracy: 0.8245 - 77s/epoch - 219ms/step\n",
      "Epoch 71/100\n",
      "352/352 - 77s - loss: 0.1313 - accuracy: 0.9573 - val_loss: 0.6273 - val_accuracy: 0.8325 - 77s/epoch - 219ms/step\n",
      "Epoch 72/100\n",
      "352/352 - 76s - loss: 0.1347 - accuracy: 0.9566 - val_loss: 0.6589 - val_accuracy: 0.8284 - 76s/epoch - 216ms/step\n",
      "Epoch 73/100\n",
      "352/352 - 77s - loss: 0.1437 - accuracy: 0.9541 - val_loss: 0.6220 - val_accuracy: 0.8250 - 77s/epoch - 219ms/step\n",
      "Epoch 74/100\n",
      "352/352 - 78s - loss: 0.1293 - accuracy: 0.9590 - val_loss: 0.6127 - val_accuracy: 0.8306 - 78s/epoch - 222ms/step\n",
      "Epoch 75/100\n",
      "352/352 - 78s - loss: 0.1234 - accuracy: 0.9602 - val_loss: 0.6816 - val_accuracy: 0.8329 - 78s/epoch - 221ms/step\n",
      "Epoch 76/100\n",
      "352/352 - 76s - loss: 0.1354 - accuracy: 0.9565 - val_loss: 0.6636 - val_accuracy: 0.8243 - 76s/epoch - 217ms/step\n",
      "Epoch 77/100\n",
      "352/352 - 80s - loss: 0.1424 - accuracy: 0.9543 - val_loss: 0.6884 - val_accuracy: 0.8273 - 80s/epoch - 227ms/step\n",
      "Epoch 78/100\n",
      "352/352 - 79s - loss: 0.1395 - accuracy: 0.9550 - val_loss: 0.7478 - val_accuracy: 0.8329 - 79s/epoch - 224ms/step\n",
      "Epoch 79/100\n",
      "352/352 - 75s - loss: 0.1335 - accuracy: 0.9569 - val_loss: 0.7360 - val_accuracy: 0.8341 - 75s/epoch - 214ms/step\n",
      "Epoch 80/100\n",
      "352/352 - 79s - loss: 0.1324 - accuracy: 0.9573 - val_loss: 0.7708 - val_accuracy: 0.8280 - 79s/epoch - 224ms/step\n",
      "Epoch 81/100\n",
      "352/352 - 80s - loss: 0.1431 - accuracy: 0.9538 - val_loss: 0.7279 - val_accuracy: 0.8335 - 80s/epoch - 228ms/step\n",
      "Epoch 82/100\n",
      "352/352 - 78s - loss: 0.1450 - accuracy: 0.9528 - val_loss: 0.6843 - val_accuracy: 0.8297 - 78s/epoch - 221ms/step\n",
      "Epoch 83/100\n",
      "352/352 - 79s - loss: 0.1388 - accuracy: 0.9553 - val_loss: 0.6670 - val_accuracy: 0.8401 - 79s/epoch - 225ms/step\n",
      "Epoch 84/100\n",
      "352/352 - 78s - loss: 0.1360 - accuracy: 0.9566 - val_loss: 0.8048 - val_accuracy: 0.8353 - 78s/epoch - 222ms/step\n",
      "Epoch 85/100\n",
      "352/352 - 78s - loss: 0.1383 - accuracy: 0.9562 - val_loss: 0.6978 - val_accuracy: 0.8345 - 78s/epoch - 222ms/step\n",
      "Epoch 86/100\n",
      "352/352 - 78s - loss: 0.1381 - accuracy: 0.9560 - val_loss: 0.6669 - val_accuracy: 0.8260 - 78s/epoch - 223ms/step\n",
      "Epoch 87/100\n",
      "352/352 - 79s - loss: 0.1409 - accuracy: 0.9548 - val_loss: 0.7095 - val_accuracy: 0.8309 - 79s/epoch - 225ms/step\n",
      "Epoch 88/100\n",
      "352/352 - 79s - loss: 0.1399 - accuracy: 0.9554 - val_loss: 0.6588 - val_accuracy: 0.8363 - 79s/epoch - 226ms/step\n",
      "Epoch 89/100\n",
      "352/352 - 80s - loss: 0.1385 - accuracy: 0.9555 - val_loss: 0.6377 - val_accuracy: 0.8387 - 80s/epoch - 226ms/step\n",
      "Epoch 90/100\n",
      "352/352 - 79s - loss: 0.1285 - accuracy: 0.9591 - val_loss: 0.6723 - val_accuracy: 0.8291 - 79s/epoch - 225ms/step\n",
      "Epoch 91/100\n",
      "352/352 - 79s - loss: 0.1463 - accuracy: 0.9534 - val_loss: 0.6894 - val_accuracy: 0.8293 - 79s/epoch - 223ms/step\n",
      "Epoch 92/100\n",
      "352/352 - 79s - loss: 0.1438 - accuracy: 0.9534 - val_loss: 0.6313 - val_accuracy: 0.8329 - 79s/epoch - 224ms/step\n",
      "Epoch 93/100\n",
      "352/352 - 79s - loss: 0.1299 - accuracy: 0.9576 - val_loss: 0.6884 - val_accuracy: 0.8270 - 79s/epoch - 223ms/step\n",
      "Epoch 94/100\n",
      "352/352 - 79s - loss: 0.1332 - accuracy: 0.9576 - val_loss: 0.6708 - val_accuracy: 0.8387 - 79s/epoch - 224ms/step\n",
      "Epoch 95/100\n",
      "352/352 - 79s - loss: 0.1339 - accuracy: 0.9564 - val_loss: 0.7240 - val_accuracy: 0.8300 - 79s/epoch - 224ms/step\n",
      "Epoch 96/100\n",
      "352/352 - 78s - loss: 0.1251 - accuracy: 0.9588 - val_loss: 0.7026 - val_accuracy: 0.8348 - 78s/epoch - 223ms/step\n",
      "Epoch 97/100\n",
      "352/352 - 79s - loss: 0.1373 - accuracy: 0.9556 - val_loss: 0.7059 - val_accuracy: 0.8263 - 79s/epoch - 224ms/step\n",
      "Epoch 98/100\n",
      "352/352 - 78s - loss: 0.1367 - accuracy: 0.9562 - val_loss: 0.6982 - val_accuracy: 0.8305 - 78s/epoch - 222ms/step\n",
      "Epoch 99/100\n",
      "352/352 - 78s - loss: 0.1413 - accuracy: 0.9543 - val_loss: 0.7036 - val_accuracy: 0.8293 - 78s/epoch - 222ms/step\n",
      "Epoch 100/100\n",
      "352/352 - 79s - loss: 0.1555 - accuracy: 0.9498 - val_loss: 0.6475 - val_accuracy: 0.8320 - 79s/epoch - 224ms/step\n",
      "[0.980400025844574, 0.9567999839782715, 0.9177333116531372, 0.8320000171661377, 0, 0, 0, 0, 0, 0]\n",
      "79/79 [==============================] - 6s 72ms/step - loss: 0.1962 - accuracy: 0.9620\n",
      "[0.9822999835014343, 0.9740999937057495, 0.9749000072479248, 0.9620000123977661, 0, 0, 0, 0, 0, 0]\n",
      "Epoch 1/100\n",
      "352/352 - 82s - loss: 1.8752 - accuracy: 0.3239 - val_loss: 1.3538 - val_accuracy: 0.5220 - 82s/epoch - 232ms/step\n",
      "Epoch 2/100\n",
      "352/352 - 76s - loss: 1.2809 - accuracy: 0.5541 - val_loss: 1.2116 - val_accuracy: 0.5777 - 76s/epoch - 217ms/step\n",
      "Epoch 3/100\n",
      "352/352 - 76s - loss: 1.1272 - accuracy: 0.6114 - val_loss: 1.1232 - val_accuracy: 0.6114 - 76s/epoch - 217ms/step\n",
      "Epoch 4/100\n",
      "352/352 - 76s - loss: 1.0384 - accuracy: 0.6472 - val_loss: 1.0433 - val_accuracy: 0.6437 - 76s/epoch - 216ms/step\n",
      "Epoch 5/100\n",
      "352/352 - 75s - loss: 0.9682 - accuracy: 0.6717 - val_loss: 0.9784 - val_accuracy: 0.6655 - 75s/epoch - 214ms/step\n",
      "Epoch 6/100\n",
      "352/352 - 75s - loss: 0.9055 - accuracy: 0.6944 - val_loss: 0.9471 - val_accuracy: 0.6825 - 75s/epoch - 214ms/step\n",
      "Epoch 7/100\n",
      "352/352 - 77s - loss: 0.8457 - accuracy: 0.7155 - val_loss: 0.9923 - val_accuracy: 0.6654 - 77s/epoch - 218ms/step\n",
      "Epoch 8/100\n",
      "352/352 - 76s - loss: 0.8028 - accuracy: 0.7283 - val_loss: 0.9543 - val_accuracy: 0.6909 - 76s/epoch - 217ms/step\n",
      "Epoch 9/100\n",
      "352/352 - 75s - loss: 0.7710 - accuracy: 0.7416 - val_loss: 0.8972 - val_accuracy: 0.6983 - 75s/epoch - 214ms/step\n",
      "Epoch 10/100\n",
      "352/352 - 75s - loss: 0.7292 - accuracy: 0.7568 - val_loss: 0.8594 - val_accuracy: 0.7095 - 75s/epoch - 212ms/step\n",
      "Epoch 11/100\n",
      "352/352 - 75s - loss: 0.6914 - accuracy: 0.7703 - val_loss: 0.8864 - val_accuracy: 0.7033 - 75s/epoch - 213ms/step\n",
      "Epoch 12/100\n",
      "352/352 - 75s - loss: 0.6450 - accuracy: 0.7839 - val_loss: 0.9222 - val_accuracy: 0.7043 - 75s/epoch - 214ms/step\n",
      "Epoch 13/100\n",
      "352/352 - 75s - loss: 0.6206 - accuracy: 0.7923 - val_loss: 0.9672 - val_accuracy: 0.6894 - 75s/epoch - 214ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100\n",
      "352/352 - 76s - loss: 0.5848 - accuracy: 0.8033 - val_loss: 1.0174 - val_accuracy: 0.6825 - 76s/epoch - 215ms/step\n",
      "Epoch 15/100\n",
      "352/352 - 75s - loss: 0.5484 - accuracy: 0.8186 - val_loss: 0.9748 - val_accuracy: 0.6941 - 75s/epoch - 214ms/step\n",
      "Epoch 16/100\n",
      "352/352 - 75s - loss: 0.5338 - accuracy: 0.8230 - val_loss: 0.9550 - val_accuracy: 0.6911 - 75s/epoch - 213ms/step\n",
      "Epoch 17/100\n",
      "352/352 - 76s - loss: 0.4984 - accuracy: 0.8344 - val_loss: 0.9757 - val_accuracy: 0.6943 - 76s/epoch - 215ms/step\n",
      "Epoch 18/100\n",
      "352/352 - 74s - loss: 0.4764 - accuracy: 0.8416 - val_loss: 1.0557 - val_accuracy: 0.6931 - 74s/epoch - 210ms/step\n",
      "Epoch 19/100\n",
      "352/352 - 75s - loss: 0.4532 - accuracy: 0.8498 - val_loss: 0.9967 - val_accuracy: 0.6937 - 75s/epoch - 213ms/step\n",
      "Epoch 20/100\n",
      "352/352 - 76s - loss: 0.4261 - accuracy: 0.8588 - val_loss: 1.0154 - val_accuracy: 0.6841 - 76s/epoch - 215ms/step\n",
      "Epoch 21/100\n",
      "352/352 - 76s - loss: 0.4092 - accuracy: 0.8658 - val_loss: 1.0430 - val_accuracy: 0.6936 - 76s/epoch - 215ms/step\n",
      "Epoch 22/100\n",
      "352/352 - 79s - loss: 0.4055 - accuracy: 0.8652 - val_loss: 1.0527 - val_accuracy: 0.6913 - 79s/epoch - 225ms/step\n",
      "Epoch 23/100\n",
      "352/352 - 79s - loss: 0.3873 - accuracy: 0.8731 - val_loss: 1.0182 - val_accuracy: 0.6992 - 79s/epoch - 225ms/step\n",
      "Epoch 24/100\n",
      "352/352 - 81s - loss: 0.3806 - accuracy: 0.8745 - val_loss: 1.1362 - val_accuracy: 0.6855 - 81s/epoch - 229ms/step\n",
      "Epoch 25/100\n",
      "352/352 - 77s - loss: 0.3751 - accuracy: 0.8758 - val_loss: 1.1564 - val_accuracy: 0.6823 - 77s/epoch - 220ms/step\n",
      "Epoch 26/100\n",
      "352/352 - 80s - loss: 0.3514 - accuracy: 0.8866 - val_loss: 1.0968 - val_accuracy: 0.6931 - 80s/epoch - 227ms/step\n",
      "Epoch 27/100\n",
      "352/352 - 81s - loss: 0.3530 - accuracy: 0.8845 - val_loss: 1.1290 - val_accuracy: 0.6771 - 81s/epoch - 231ms/step\n",
      "Epoch 28/100\n",
      "352/352 - 83s - loss: 0.3403 - accuracy: 0.8888 - val_loss: 1.1609 - val_accuracy: 0.6800 - 83s/epoch - 236ms/step\n",
      "Epoch 29/100\n",
      "352/352 - 84s - loss: 0.3371 - accuracy: 0.8892 - val_loss: 1.2392 - val_accuracy: 0.6853 - 84s/epoch - 237ms/step\n",
      "Epoch 30/100\n",
      "352/352 - 82s - loss: 0.3230 - accuracy: 0.8933 - val_loss: 1.1645 - val_accuracy: 0.6875 - 82s/epoch - 234ms/step\n",
      "Epoch 31/100\n",
      "352/352 - 80s - loss: 0.3147 - accuracy: 0.8970 - val_loss: 1.1727 - val_accuracy: 0.6876 - 80s/epoch - 226ms/step\n",
      "Epoch 32/100\n",
      "352/352 - 78s - loss: 0.3190 - accuracy: 0.8944 - val_loss: 1.1665 - val_accuracy: 0.6941 - 78s/epoch - 223ms/step\n",
      "Epoch 33/100\n",
      "352/352 - 78s - loss: 0.3115 - accuracy: 0.8979 - val_loss: 1.0847 - val_accuracy: 0.6889 - 78s/epoch - 222ms/step\n",
      "Epoch 34/100\n",
      "352/352 - 77s - loss: 0.3016 - accuracy: 0.9012 - val_loss: 1.2080 - val_accuracy: 0.6797 - 77s/epoch - 218ms/step\n",
      "Epoch 35/100\n",
      "352/352 - 76s - loss: 0.3010 - accuracy: 0.9020 - val_loss: 1.2528 - val_accuracy: 0.6812 - 76s/epoch - 216ms/step\n",
      "Epoch 36/100\n",
      "352/352 - 76s - loss: 0.2932 - accuracy: 0.9034 - val_loss: 1.2517 - val_accuracy: 0.6769 - 76s/epoch - 215ms/step\n",
      "Epoch 37/100\n",
      "352/352 - 76s - loss: 0.2867 - accuracy: 0.9059 - val_loss: 1.1494 - val_accuracy: 0.6885 - 76s/epoch - 215ms/step\n",
      "Epoch 38/100\n",
      "352/352 - 75s - loss: 0.2923 - accuracy: 0.9047 - val_loss: 1.2046 - val_accuracy: 0.6853 - 75s/epoch - 214ms/step\n",
      "Epoch 39/100\n",
      "352/352 - 76s - loss: 0.2864 - accuracy: 0.9060 - val_loss: 1.1454 - val_accuracy: 0.6885 - 76s/epoch - 216ms/step\n",
      "Epoch 40/100\n",
      "352/352 - 76s - loss: 0.2828 - accuracy: 0.9069 - val_loss: 1.2713 - val_accuracy: 0.6801 - 76s/epoch - 215ms/step\n",
      "Epoch 41/100\n",
      "352/352 - 77s - loss: 0.2792 - accuracy: 0.9076 - val_loss: 1.1821 - val_accuracy: 0.6913 - 77s/epoch - 217ms/step\n",
      "Epoch 42/100\n",
      "352/352 - 76s - loss: 0.2767 - accuracy: 0.9088 - val_loss: 1.2433 - val_accuracy: 0.6809 - 76s/epoch - 217ms/step\n",
      "Epoch 43/100\n",
      "352/352 - 77s - loss: 0.2778 - accuracy: 0.9080 - val_loss: 1.2296 - val_accuracy: 0.6738 - 77s/epoch - 218ms/step\n",
      "Epoch 44/100\n",
      "352/352 - 77s - loss: 0.2742 - accuracy: 0.9105 - val_loss: 1.2592 - val_accuracy: 0.6930 - 77s/epoch - 218ms/step\n",
      "Epoch 45/100\n",
      "352/352 - 75s - loss: 0.2838 - accuracy: 0.9080 - val_loss: 1.2067 - val_accuracy: 0.6811 - 75s/epoch - 212ms/step\n",
      "Epoch 46/100\n",
      "352/352 - 74s - loss: 0.2834 - accuracy: 0.9082 - val_loss: 1.1809 - val_accuracy: 0.6913 - 74s/epoch - 211ms/step\n",
      "Epoch 47/100\n",
      "352/352 - 77s - loss: 0.2626 - accuracy: 0.9137 - val_loss: 1.1472 - val_accuracy: 0.6902 - 77s/epoch - 218ms/step\n",
      "Epoch 48/100\n",
      "352/352 - 77s - loss: 0.2652 - accuracy: 0.9120 - val_loss: 1.1863 - val_accuracy: 0.6875 - 77s/epoch - 219ms/step\n",
      "Epoch 49/100\n",
      "352/352 - 77s - loss: 0.2571 - accuracy: 0.9160 - val_loss: 1.1412 - val_accuracy: 0.6898 - 77s/epoch - 219ms/step\n",
      "Epoch 50/100\n",
      "352/352 - 78s - loss: 0.2649 - accuracy: 0.9129 - val_loss: 1.2545 - val_accuracy: 0.6805 - 78s/epoch - 220ms/step\n",
      "Epoch 51/100\n",
      "352/352 - 78s - loss: 0.2656 - accuracy: 0.9126 - val_loss: 1.2541 - val_accuracy: 0.6941 - 78s/epoch - 220ms/step\n",
      "Epoch 52/100\n",
      "352/352 - 77s - loss: 0.2544 - accuracy: 0.9157 - val_loss: 1.2898 - val_accuracy: 0.6809 - 77s/epoch - 219ms/step\n",
      "Epoch 53/100\n",
      "352/352 - 77s - loss: 0.2668 - accuracy: 0.9128 - val_loss: 1.2901 - val_accuracy: 0.6798 - 77s/epoch - 219ms/step\n",
      "Epoch 54/100\n",
      "352/352 - 76s - loss: 0.2714 - accuracy: 0.9119 - val_loss: 1.2065 - val_accuracy: 0.6846 - 76s/epoch - 216ms/step\n",
      "Epoch 55/100\n",
      "352/352 - 76s - loss: 0.2590 - accuracy: 0.9151 - val_loss: 1.3763 - val_accuracy: 0.6759 - 76s/epoch - 216ms/step\n",
      "Epoch 56/100\n",
      "352/352 - 76s - loss: 0.2732 - accuracy: 0.9093 - val_loss: 1.3407 - val_accuracy: 0.6825 - 76s/epoch - 216ms/step\n",
      "Epoch 57/100\n",
      "352/352 - 75s - loss: 0.2607 - accuracy: 0.9151 - val_loss: 1.4061 - val_accuracy: 0.6794 - 75s/epoch - 214ms/step\n",
      "Epoch 58/100\n",
      "352/352 - 76s - loss: 0.2607 - accuracy: 0.9132 - val_loss: 1.2347 - val_accuracy: 0.6840 - 76s/epoch - 216ms/step\n",
      "Epoch 59/100\n",
      "352/352 - 77s - loss: 0.2561 - accuracy: 0.9161 - val_loss: 1.2654 - val_accuracy: 0.6833 - 77s/epoch - 217ms/step\n",
      "Epoch 60/100\n",
      "352/352 - 76s - loss: 0.2599 - accuracy: 0.9135 - val_loss: 1.3459 - val_accuracy: 0.6781 - 76s/epoch - 216ms/step\n",
      "Epoch 61/100\n",
      "352/352 - 76s - loss: 0.2650 - accuracy: 0.9130 - val_loss: 1.3284 - val_accuracy: 0.6867 - 76s/epoch - 217ms/step\n",
      "Epoch 62/100\n",
      "352/352 - 75s - loss: 0.2556 - accuracy: 0.9157 - val_loss: 1.2597 - val_accuracy: 0.6875 - 75s/epoch - 212ms/step\n",
      "Epoch 63/100\n",
      "352/352 - 75s - loss: 0.2593 - accuracy: 0.9146 - val_loss: 1.1800 - val_accuracy: 0.6847 - 75s/epoch - 214ms/step\n",
      "Epoch 64/100\n",
      "352/352 - 76s - loss: 0.2503 - accuracy: 0.9157 - val_loss: 1.2581 - val_accuracy: 0.6781 - 76s/epoch - 215ms/step\n",
      "Epoch 65/100\n",
      "352/352 - 76s - loss: 0.2589 - accuracy: 0.9147 - val_loss: 1.2578 - val_accuracy: 0.6809 - 76s/epoch - 216ms/step\n",
      "Epoch 66/100\n",
      "352/352 - 76s - loss: 0.2642 - accuracy: 0.9134 - val_loss: 1.3095 - val_accuracy: 0.6816 - 76s/epoch - 216ms/step\n",
      "Epoch 67/100\n",
      "352/352 - 77s - loss: 0.2566 - accuracy: 0.9158 - val_loss: 1.2755 - val_accuracy: 0.6919 - 77s/epoch - 217ms/step\n",
      "Epoch 68/100\n",
      "352/352 - 76s - loss: 0.2656 - accuracy: 0.9120 - val_loss: 1.2099 - val_accuracy: 0.6885 - 76s/epoch - 217ms/step\n",
      "Epoch 69/100\n",
      "352/352 - 76s - loss: 0.2518 - accuracy: 0.9163 - val_loss: 1.1740 - val_accuracy: 0.6957 - 76s/epoch - 217ms/step\n",
      "Epoch 70/100\n",
      "352/352 - 79s - loss: 0.2483 - accuracy: 0.9179 - val_loss: 1.2491 - val_accuracy: 0.6865 - 79s/epoch - 224ms/step\n",
      "Epoch 71/100\n",
      "352/352 - 77s - loss: 0.2463 - accuracy: 0.9192 - val_loss: 1.3250 - val_accuracy: 0.6829 - 77s/epoch - 219ms/step\n",
      "Epoch 72/100\n",
      "352/352 - 76s - loss: 0.2575 - accuracy: 0.9154 - val_loss: 1.2743 - val_accuracy: 0.6835 - 76s/epoch - 215ms/step\n",
      "Epoch 73/100\n",
      "352/352 - 75s - loss: 0.2635 - accuracy: 0.9141 - val_loss: 1.2900 - val_accuracy: 0.6918 - 75s/epoch - 214ms/step\n",
      "Epoch 74/100\n",
      "352/352 - 75s - loss: 0.2624 - accuracy: 0.9115 - val_loss: 1.2860 - val_accuracy: 0.6872 - 75s/epoch - 214ms/step\n",
      "Epoch 75/100\n",
      "352/352 - 76s - loss: 0.2610 - accuracy: 0.9149 - val_loss: 1.1643 - val_accuracy: 0.6883 - 76s/epoch - 217ms/step\n",
      "Epoch 76/100\n",
      "352/352 - 76s - loss: 0.2417 - accuracy: 0.9194 - val_loss: 1.3382 - val_accuracy: 0.6908 - 76s/epoch - 216ms/step\n",
      "Epoch 77/100\n",
      "352/352 - 76s - loss: 0.2450 - accuracy: 0.9195 - val_loss: 1.2726 - val_accuracy: 0.6842 - 76s/epoch - 215ms/step\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 - 75s - loss: 0.2680 - accuracy: 0.9100 - val_loss: 1.2770 - val_accuracy: 0.6910 - 75s/epoch - 214ms/step\n",
      "Epoch 79/100\n",
      "352/352 - 75s - loss: 0.2775 - accuracy: 0.9080 - val_loss: 1.2036 - val_accuracy: 0.6913 - 75s/epoch - 214ms/step\n",
      "Epoch 80/100\n",
      "352/352 - 72s - loss: 0.2656 - accuracy: 0.9114 - val_loss: 1.1875 - val_accuracy: 0.6907 - 72s/epoch - 206ms/step\n",
      "Epoch 81/100\n",
      "352/352 - 76s - loss: 0.2565 - accuracy: 0.9155 - val_loss: 1.2674 - val_accuracy: 0.6929 - 76s/epoch - 215ms/step\n",
      "Epoch 82/100\n",
      "352/352 - 77s - loss: 0.2476 - accuracy: 0.9180 - val_loss: 1.2013 - val_accuracy: 0.6847 - 77s/epoch - 219ms/step\n",
      "Epoch 83/100\n",
      "352/352 - 76s - loss: 0.2651 - accuracy: 0.9117 - val_loss: 1.3418 - val_accuracy: 0.6962 - 76s/epoch - 216ms/step\n",
      "Epoch 84/100\n",
      "352/352 - 76s - loss: 0.2516 - accuracy: 0.9172 - val_loss: 1.2739 - val_accuracy: 0.6912 - 76s/epoch - 216ms/step\n",
      "Epoch 85/100\n",
      "352/352 - 76s - loss: 0.2712 - accuracy: 0.9107 - val_loss: 1.1860 - val_accuracy: 0.6872 - 76s/epoch - 216ms/step\n",
      "Epoch 86/100\n",
      "352/352 - 77s - loss: 0.2762 - accuracy: 0.9082 - val_loss: 1.2923 - val_accuracy: 0.6863 - 77s/epoch - 217ms/step\n",
      "Epoch 87/100\n",
      "352/352 - 76s - loss: 0.2579 - accuracy: 0.9153 - val_loss: 1.2241 - val_accuracy: 0.6911 - 76s/epoch - 216ms/step\n",
      "Epoch 88/100\n",
      "352/352 - 75s - loss: 0.2514 - accuracy: 0.9171 - val_loss: 1.3624 - val_accuracy: 0.6867 - 75s/epoch - 213ms/step\n",
      "Epoch 89/100\n",
      "352/352 - 76s - loss: 0.2694 - accuracy: 0.9110 - val_loss: 1.3829 - val_accuracy: 0.6919 - 76s/epoch - 215ms/step\n",
      "Epoch 90/100\n",
      "352/352 - 76s - loss: 0.2637 - accuracy: 0.9124 - val_loss: 1.3338 - val_accuracy: 0.6839 - 76s/epoch - 215ms/step\n",
      "Epoch 91/100\n",
      "352/352 - 75s - loss: 0.2664 - accuracy: 0.9114 - val_loss: 1.2206 - val_accuracy: 0.6964 - 75s/epoch - 214ms/step\n",
      "Epoch 92/100\n",
      "352/352 - 76s - loss: 0.2523 - accuracy: 0.9161 - val_loss: 1.2069 - val_accuracy: 0.6903 - 76s/epoch - 215ms/step\n",
      "Epoch 93/100\n",
      "352/352 - 75s - loss: 0.2598 - accuracy: 0.9152 - val_loss: 1.2141 - val_accuracy: 0.6859 - 75s/epoch - 214ms/step\n",
      "Epoch 94/100\n",
      "352/352 - 76s - loss: 0.2668 - accuracy: 0.9128 - val_loss: 1.3511 - val_accuracy: 0.6788 - 76s/epoch - 216ms/step\n",
      "Epoch 95/100\n",
      "352/352 - 76s - loss: 0.2578 - accuracy: 0.9148 - val_loss: 1.2596 - val_accuracy: 0.6943 - 76s/epoch - 215ms/step\n",
      "Epoch 96/100\n",
      "352/352 - 75s - loss: 0.2553 - accuracy: 0.9166 - val_loss: 1.2154 - val_accuracy: 0.6953 - 75s/epoch - 214ms/step\n",
      "Epoch 97/100\n",
      "352/352 - 75s - loss: 0.2626 - accuracy: 0.9134 - val_loss: 1.3421 - val_accuracy: 0.6822 - 75s/epoch - 213ms/step\n",
      "Epoch 98/100\n",
      "352/352 - 75s - loss: 0.2587 - accuracy: 0.9155 - val_loss: 1.2256 - val_accuracy: 0.6903 - 75s/epoch - 213ms/step\n",
      "Epoch 99/100\n",
      "352/352 - 75s - loss: 0.2622 - accuracy: 0.9132 - val_loss: 1.2549 - val_accuracy: 0.6890 - 75s/epoch - 213ms/step\n",
      "Epoch 100/100\n",
      "352/352 - 75s - loss: 0.2491 - accuracy: 0.9180 - val_loss: 1.1882 - val_accuracy: 0.6956 - 75s/epoch - 214ms/step\n",
      "[0.980400025844574, 0.9567999839782715, 0.9177333116531372, 0.8320000171661377, 0.6955999732017517, 0, 0, 0, 0, 0]\n",
      "79/79 [==============================] - 6s 72ms/step - loss: 0.3368 - accuracy: 0.9410\n",
      "[0.9822999835014343, 0.9740999937057495, 0.9749000072479248, 0.9620000123977661, 0.9409999847412109, 0, 0, 0, 0, 0]\n",
      "Epoch 1/100\n",
      "352/352 - 81s - loss: 2.1015 - accuracy: 0.2267 - val_loss: 1.7560 - val_accuracy: 0.3850 - 81s/epoch - 230ms/step\n",
      "Epoch 2/100\n",
      "352/352 - 74s - loss: 1.6926 - accuracy: 0.4033 - val_loss: 1.5732 - val_accuracy: 0.4521 - 74s/epoch - 211ms/step\n",
      "Epoch 3/100\n",
      "352/352 - 74s - loss: 1.5905 - accuracy: 0.4441 - val_loss: 1.5568 - val_accuracy: 0.4611 - 74s/epoch - 211ms/step\n",
      "Epoch 4/100\n",
      "352/352 - 74s - loss: 1.5278 - accuracy: 0.4685 - val_loss: 1.5326 - val_accuracy: 0.4691 - 74s/epoch - 210ms/step\n",
      "Epoch 5/100\n",
      "352/352 - 74s - loss: 1.4777 - accuracy: 0.4848 - val_loss: 1.4914 - val_accuracy: 0.4829 - 74s/epoch - 210ms/step\n",
      "Epoch 6/100\n",
      "352/352 - 74s - loss: 1.4253 - accuracy: 0.5069 - val_loss: 1.4584 - val_accuracy: 0.5031 - 74s/epoch - 211ms/step\n",
      "Epoch 7/100\n",
      "352/352 - 74s - loss: 1.3794 - accuracy: 0.5222 - val_loss: 1.5235 - val_accuracy: 0.4714 - 74s/epoch - 210ms/step\n",
      "Epoch 8/100\n",
      "352/352 - 74s - loss: 1.3254 - accuracy: 0.5397 - val_loss: 1.5539 - val_accuracy: 0.4738 - 74s/epoch - 211ms/step\n",
      "Epoch 9/100\n",
      "352/352 - 75s - loss: 1.2789 - accuracy: 0.5578 - val_loss: 1.4361 - val_accuracy: 0.5119 - 75s/epoch - 212ms/step\n",
      "Epoch 10/100\n",
      "352/352 - 74s - loss: 1.2289 - accuracy: 0.5772 - val_loss: 1.5130 - val_accuracy: 0.4849 - 74s/epoch - 212ms/step\n",
      "Epoch 11/100\n",
      "352/352 - 74s - loss: 1.1701 - accuracy: 0.5991 - val_loss: 1.4678 - val_accuracy: 0.5059 - 74s/epoch - 210ms/step\n",
      "Epoch 12/100\n",
      "352/352 - 74s - loss: 1.1273 - accuracy: 0.6132 - val_loss: 1.5203 - val_accuracy: 0.4971 - 74s/epoch - 210ms/step\n",
      "Epoch 13/100\n",
      "352/352 - 74s - loss: 1.0712 - accuracy: 0.6323 - val_loss: 1.5632 - val_accuracy: 0.4865 - 74s/epoch - 210ms/step\n",
      "Epoch 14/100\n",
      "352/352 - 75s - loss: 1.0092 - accuracy: 0.6540 - val_loss: 1.4835 - val_accuracy: 0.4959 - 75s/epoch - 214ms/step\n",
      "Epoch 15/100\n",
      "352/352 - 75s - loss: 0.9668 - accuracy: 0.6677 - val_loss: 1.5346 - val_accuracy: 0.5009 - 75s/epoch - 214ms/step\n",
      "Epoch 16/100\n",
      "352/352 - 76s - loss: 0.9300 - accuracy: 0.6809 - val_loss: 1.5711 - val_accuracy: 0.4891 - 76s/epoch - 216ms/step\n",
      "Epoch 17/100\n",
      "352/352 - 77s - loss: 0.8808 - accuracy: 0.7004 - val_loss: 1.6287 - val_accuracy: 0.4944 - 77s/epoch - 219ms/step\n",
      "Epoch 18/100\n",
      "352/352 - 79s - loss: 0.8561 - accuracy: 0.7074 - val_loss: 1.6649 - val_accuracy: 0.4861 - 79s/epoch - 223ms/step\n",
      "Epoch 19/100\n",
      "352/352 - 75s - loss: 0.8115 - accuracy: 0.7243 - val_loss: 1.6706 - val_accuracy: 0.4989 - 75s/epoch - 214ms/step\n",
      "Epoch 20/100\n",
      "352/352 - 76s - loss: 0.7798 - accuracy: 0.7348 - val_loss: 1.7888 - val_accuracy: 0.4900 - 76s/epoch - 216ms/step\n",
      "Epoch 21/100\n",
      "352/352 - 76s - loss: 0.7589 - accuracy: 0.7388 - val_loss: 1.7531 - val_accuracy: 0.4843 - 76s/epoch - 215ms/step\n",
      "Epoch 22/100\n",
      "352/352 - 76s - loss: 0.7117 - accuracy: 0.7589 - val_loss: 1.7801 - val_accuracy: 0.4806 - 76s/epoch - 217ms/step\n",
      "Epoch 23/100\n",
      "352/352 - 75s - loss: 0.7013 - accuracy: 0.7646 - val_loss: 1.6797 - val_accuracy: 0.4894 - 75s/epoch - 212ms/step\n",
      "Epoch 24/100\n",
      "352/352 - 75s - loss: 0.6783 - accuracy: 0.7675 - val_loss: 1.8686 - val_accuracy: 0.4703 - 75s/epoch - 213ms/step\n",
      "Epoch 25/100\n",
      "352/352 - 75s - loss: 0.6541 - accuracy: 0.7769 - val_loss: 1.7778 - val_accuracy: 0.4857 - 75s/epoch - 214ms/step\n",
      "Epoch 26/100\n",
      "352/352 - 77s - loss: 0.6358 - accuracy: 0.7848 - val_loss: 1.9241 - val_accuracy: 0.4738 - 77s/epoch - 219ms/step\n",
      "Epoch 27/100\n",
      "352/352 - 75s - loss: 0.6120 - accuracy: 0.7923 - val_loss: 1.8891 - val_accuracy: 0.4756 - 75s/epoch - 213ms/step\n",
      "Epoch 28/100\n",
      "352/352 - 73s - loss: 0.6039 - accuracy: 0.7944 - val_loss: 1.8528 - val_accuracy: 0.4792 - 73s/epoch - 208ms/step\n",
      "Epoch 29/100\n",
      "352/352 - 74s - loss: 0.5846 - accuracy: 0.8030 - val_loss: 2.0575 - val_accuracy: 0.4698 - 74s/epoch - 211ms/step\n",
      "Epoch 30/100\n",
      "352/352 - 76s - loss: 0.5640 - accuracy: 0.8086 - val_loss: 2.0902 - val_accuracy: 0.4667 - 76s/epoch - 215ms/step\n",
      "Epoch 31/100\n",
      "352/352 - 74s - loss: 0.5569 - accuracy: 0.8116 - val_loss: 1.9243 - val_accuracy: 0.4650 - 74s/epoch - 212ms/step\n",
      "Epoch 32/100\n",
      "352/352 - 75s - loss: 0.5569 - accuracy: 0.8125 - val_loss: 2.1499 - val_accuracy: 0.4623 - 75s/epoch - 214ms/step\n",
      "Epoch 33/100\n",
      "352/352 - 76s - loss: 0.5534 - accuracy: 0.8132 - val_loss: 1.9394 - val_accuracy: 0.4414 - 76s/epoch - 215ms/step\n",
      "Epoch 34/100\n",
      "352/352 - 75s - loss: 0.5335 - accuracy: 0.8184 - val_loss: 2.0114 - val_accuracy: 0.4741 - 75s/epoch - 213ms/step\n",
      "Epoch 35/100\n",
      "352/352 - 75s - loss: 0.5056 - accuracy: 0.8290 - val_loss: 2.0997 - val_accuracy: 0.4716 - 75s/epoch - 214ms/step\n",
      "Epoch 36/100\n",
      "352/352 - 75s - loss: 0.5134 - accuracy: 0.8266 - val_loss: 2.1166 - val_accuracy: 0.4654 - 75s/epoch - 214ms/step\n",
      "Epoch 37/100\n",
      "352/352 - 75s - loss: 0.5109 - accuracy: 0.8258 - val_loss: 2.1351 - val_accuracy: 0.4647 - 75s/epoch - 214ms/step\n",
      "Epoch 38/100\n",
      "352/352 - 75s - loss: 0.5050 - accuracy: 0.8292 - val_loss: 2.0778 - val_accuracy: 0.4675 - 75s/epoch - 213ms/step\n",
      "Epoch 39/100\n",
      "352/352 - 75s - loss: 0.4974 - accuracy: 0.8318 - val_loss: 2.1001 - val_accuracy: 0.4610 - 75s/epoch - 213ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "352/352 - 73s - loss: 0.5055 - accuracy: 0.8275 - val_loss: 2.1743 - val_accuracy: 0.4599 - 73s/epoch - 207ms/step\n",
      "Epoch 41/100\n",
      "352/352 - 72s - loss: 0.4787 - accuracy: 0.8371 - val_loss: 2.1566 - val_accuracy: 0.4622 - 72s/epoch - 206ms/step\n",
      "Epoch 42/100\n",
      "352/352 - 74s - loss: 0.4763 - accuracy: 0.8426 - val_loss: 2.3341 - val_accuracy: 0.4585 - 74s/epoch - 209ms/step\n",
      "Epoch 43/100\n",
      "352/352 - 74s - loss: 0.4673 - accuracy: 0.8423 - val_loss: 2.0354 - val_accuracy: 0.4697 - 74s/epoch - 212ms/step\n",
      "Epoch 44/100\n",
      "352/352 - 75s - loss: 0.4742 - accuracy: 0.8407 - val_loss: 2.1413 - val_accuracy: 0.4648 - 75s/epoch - 213ms/step\n",
      "Epoch 45/100\n",
      "352/352 - 75s - loss: 0.4623 - accuracy: 0.8437 - val_loss: 2.0427 - val_accuracy: 0.4613 - 75s/epoch - 214ms/step\n",
      "Epoch 46/100\n",
      "352/352 - 75s - loss: 0.4633 - accuracy: 0.8446 - val_loss: 2.2301 - val_accuracy: 0.4656 - 75s/epoch - 213ms/step\n",
      "Epoch 47/100\n",
      "352/352 - 75s - loss: 0.4591 - accuracy: 0.8441 - val_loss: 2.1553 - val_accuracy: 0.4575 - 75s/epoch - 212ms/step\n",
      "Epoch 48/100\n",
      "352/352 - 75s - loss: 0.4501 - accuracy: 0.8481 - val_loss: 2.0758 - val_accuracy: 0.4618 - 75s/epoch - 213ms/step\n",
      "Epoch 49/100\n",
      "352/352 - 75s - loss: 0.4616 - accuracy: 0.8447 - val_loss: 2.2086 - val_accuracy: 0.4689 - 75s/epoch - 214ms/step\n",
      "Epoch 50/100\n",
      "352/352 - 76s - loss: 0.4454 - accuracy: 0.8500 - val_loss: 2.2302 - val_accuracy: 0.4615 - 76s/epoch - 215ms/step\n",
      "Epoch 51/100\n",
      "352/352 - 75s - loss: 0.4428 - accuracy: 0.8514 - val_loss: 2.1598 - val_accuracy: 0.4670 - 75s/epoch - 212ms/step\n",
      "Epoch 52/100\n",
      "352/352 - 74s - loss: 0.4474 - accuracy: 0.8490 - val_loss: 2.0463 - val_accuracy: 0.4775 - 74s/epoch - 212ms/step\n",
      "Epoch 53/100\n",
      "352/352 - 75s - loss: 0.4494 - accuracy: 0.8488 - val_loss: 2.1202 - val_accuracy: 0.4678 - 75s/epoch - 212ms/step\n",
      "Epoch 54/100\n",
      "352/352 - 74s - loss: 0.4500 - accuracy: 0.8497 - val_loss: 2.1884 - val_accuracy: 0.4591 - 74s/epoch - 211ms/step\n",
      "Epoch 55/100\n",
      "352/352 - 75s - loss: 0.4389 - accuracy: 0.8536 - val_loss: 2.2316 - val_accuracy: 0.4697 - 75s/epoch - 212ms/step\n",
      "Epoch 56/100\n",
      "352/352 - 74s - loss: 0.4379 - accuracy: 0.8531 - val_loss: 2.2532 - val_accuracy: 0.4703 - 74s/epoch - 211ms/step\n",
      "Epoch 57/100\n",
      "352/352 - 74s - loss: 0.4368 - accuracy: 0.8517 - val_loss: 2.3920 - val_accuracy: 0.4661 - 74s/epoch - 211ms/step\n",
      "Epoch 58/100\n",
      "352/352 - 75s - loss: 0.4333 - accuracy: 0.8543 - val_loss: 2.1475 - val_accuracy: 0.4656 - 75s/epoch - 214ms/step\n",
      "Epoch 59/100\n",
      "352/352 - 75s - loss: 0.4202 - accuracy: 0.8591 - val_loss: 2.1218 - val_accuracy: 0.4741 - 75s/epoch - 213ms/step\n",
      "Epoch 60/100\n",
      "352/352 - 75s - loss: 0.4204 - accuracy: 0.8577 - val_loss: 2.1429 - val_accuracy: 0.4707 - 75s/epoch - 212ms/step\n",
      "Epoch 61/100\n",
      "352/352 - 74s - loss: 0.4251 - accuracy: 0.8582 - val_loss: 2.3050 - val_accuracy: 0.4629 - 74s/epoch - 211ms/step\n",
      "Epoch 62/100\n",
      "352/352 - 76s - loss: 0.4171 - accuracy: 0.8599 - val_loss: 2.3077 - val_accuracy: 0.4671 - 76s/epoch - 215ms/step\n",
      "Epoch 63/100\n",
      "352/352 - 75s - loss: 0.4229 - accuracy: 0.8568 - val_loss: 2.4159 - val_accuracy: 0.4663 - 75s/epoch - 214ms/step\n",
      "Epoch 64/100\n",
      "352/352 - 76s - loss: 0.4182 - accuracy: 0.8594 - val_loss: 2.3061 - val_accuracy: 0.4655 - 76s/epoch - 216ms/step\n",
      "Epoch 65/100\n",
      "352/352 - 76s - loss: 0.4187 - accuracy: 0.8590 - val_loss: 2.1822 - val_accuracy: 0.4668 - 76s/epoch - 215ms/step\n",
      "Epoch 66/100\n",
      "352/352 - 80s - loss: 0.4260 - accuracy: 0.8554 - val_loss: 2.1658 - val_accuracy: 0.4626 - 80s/epoch - 228ms/step\n",
      "Epoch 67/100\n",
      "352/352 - 75s - loss: 0.4126 - accuracy: 0.8604 - val_loss: 2.1999 - val_accuracy: 0.4622 - 75s/epoch - 214ms/step\n",
      "Epoch 68/100\n",
      "352/352 - 76s - loss: 0.4367 - accuracy: 0.8521 - val_loss: 2.4677 - val_accuracy: 0.4595 - 76s/epoch - 217ms/step\n",
      "Epoch 69/100\n",
      "352/352 - 76s - loss: 0.4210 - accuracy: 0.8584 - val_loss: 2.1614 - val_accuracy: 0.4685 - 76s/epoch - 216ms/step\n",
      "Epoch 70/100\n",
      "352/352 - 76s - loss: 0.4230 - accuracy: 0.8572 - val_loss: 2.0987 - val_accuracy: 0.4713 - 76s/epoch - 215ms/step\n",
      "Epoch 71/100\n",
      "352/352 - 76s - loss: 0.4017 - accuracy: 0.8652 - val_loss: 2.2359 - val_accuracy: 0.4708 - 76s/epoch - 216ms/step\n",
      "Epoch 72/100\n",
      "352/352 - 76s - loss: 0.4043 - accuracy: 0.8626 - val_loss: 2.3727 - val_accuracy: 0.4636 - 76s/epoch - 215ms/step\n",
      "Epoch 73/100\n",
      "352/352 - 76s - loss: 0.4253 - accuracy: 0.8575 - val_loss: 2.1264 - val_accuracy: 0.4579 - 76s/epoch - 215ms/step\n",
      "Epoch 74/100\n",
      "352/352 - 76s - loss: 0.4212 - accuracy: 0.8570 - val_loss: 2.2749 - val_accuracy: 0.4605 - 76s/epoch - 215ms/step\n",
      "Epoch 75/100\n",
      "352/352 - 76s - loss: 0.4151 - accuracy: 0.8605 - val_loss: 2.2298 - val_accuracy: 0.4646 - 76s/epoch - 215ms/step\n",
      "Epoch 76/100\n",
      "352/352 - 76s - loss: 0.4126 - accuracy: 0.8602 - val_loss: 2.2503 - val_accuracy: 0.4593 - 76s/epoch - 217ms/step\n",
      "Epoch 77/100\n",
      "352/352 - 76s - loss: 0.4032 - accuracy: 0.8643 - val_loss: 2.4256 - val_accuracy: 0.4667 - 76s/epoch - 216ms/step\n",
      "Epoch 78/100\n",
      "352/352 - 77s - loss: 0.3911 - accuracy: 0.8694 - val_loss: 2.2723 - val_accuracy: 0.4617 - 77s/epoch - 218ms/step\n",
      "Epoch 79/100\n",
      "352/352 - 76s - loss: 0.3935 - accuracy: 0.8685 - val_loss: 2.4710 - val_accuracy: 0.4536 - 76s/epoch - 216ms/step\n",
      "Epoch 80/100\n",
      "352/352 - 76s - loss: 0.4098 - accuracy: 0.8626 - val_loss: 2.3290 - val_accuracy: 0.4782 - 76s/epoch - 216ms/step\n",
      "Epoch 81/100\n",
      "352/352 - 71s - loss: 0.4029 - accuracy: 0.8635 - val_loss: 2.1987 - val_accuracy: 0.4715 - 71s/epoch - 200ms/step\n",
      "Epoch 82/100\n",
      "352/352 - 75s - loss: 0.4207 - accuracy: 0.8574 - val_loss: 2.2473 - val_accuracy: 0.4648 - 75s/epoch - 213ms/step\n",
      "Epoch 83/100\n",
      "352/352 - 75s - loss: 0.4078 - accuracy: 0.8641 - val_loss: 2.2160 - val_accuracy: 0.4667 - 75s/epoch - 214ms/step\n",
      "Epoch 84/100\n",
      "352/352 - 76s - loss: 0.4015 - accuracy: 0.8646 - val_loss: 2.0429 - val_accuracy: 0.4597 - 76s/epoch - 216ms/step\n",
      "Epoch 85/100\n",
      "352/352 - 76s - loss: 0.3972 - accuracy: 0.8661 - val_loss: 2.2191 - val_accuracy: 0.4674 - 76s/epoch - 216ms/step\n",
      "Epoch 86/100\n",
      "352/352 - 76s - loss: 0.4034 - accuracy: 0.8622 - val_loss: 2.3623 - val_accuracy: 0.4560 - 76s/epoch - 215ms/step\n",
      "Epoch 87/100\n",
      "352/352 - 75s - loss: 0.3985 - accuracy: 0.8645 - val_loss: 2.2898 - val_accuracy: 0.4679 - 75s/epoch - 214ms/step\n",
      "Epoch 88/100\n",
      "352/352 - 76s - loss: 0.4052 - accuracy: 0.8638 - val_loss: 2.2707 - val_accuracy: 0.4721 - 76s/epoch - 216ms/step\n",
      "Epoch 89/100\n",
      "352/352 - 76s - loss: 0.4017 - accuracy: 0.8652 - val_loss: 2.2131 - val_accuracy: 0.4744 - 76s/epoch - 216ms/step\n",
      "Epoch 90/100\n",
      "352/352 - 76s - loss: 0.3998 - accuracy: 0.8661 - val_loss: 2.2700 - val_accuracy: 0.4671 - 76s/epoch - 217ms/step\n",
      "Epoch 91/100\n",
      "352/352 - 76s - loss: 0.3946 - accuracy: 0.8655 - val_loss: 2.4259 - val_accuracy: 0.4541 - 76s/epoch - 216ms/step\n",
      "Epoch 92/100\n",
      "352/352 - 76s - loss: 0.3894 - accuracy: 0.8686 - val_loss: 2.2207 - val_accuracy: 0.4693 - 76s/epoch - 215ms/step\n",
      "Epoch 93/100\n",
      "352/352 - 76s - loss: 0.3859 - accuracy: 0.8703 - val_loss: 2.3000 - val_accuracy: 0.4661 - 76s/epoch - 216ms/step\n",
      "Epoch 94/100\n",
      "352/352 - 78s - loss: 0.3955 - accuracy: 0.8662 - val_loss: 2.2000 - val_accuracy: 0.4663 - 78s/epoch - 221ms/step\n",
      "Epoch 95/100\n",
      "352/352 - 77s - loss: 0.4061 - accuracy: 0.8629 - val_loss: 2.5513 - val_accuracy: 0.4700 - 77s/epoch - 219ms/step\n",
      "Epoch 96/100\n",
      "352/352 - 76s - loss: 0.4001 - accuracy: 0.8674 - val_loss: 2.4747 - val_accuracy: 0.4493 - 76s/epoch - 216ms/step\n",
      "Epoch 97/100\n",
      "352/352 - 76s - loss: 0.4121 - accuracy: 0.8596 - val_loss: 2.3176 - val_accuracy: 0.4618 - 76s/epoch - 216ms/step\n",
      "Epoch 98/100\n",
      "352/352 - 76s - loss: 0.4102 - accuracy: 0.8616 - val_loss: 2.1689 - val_accuracy: 0.4768 - 76s/epoch - 217ms/step\n",
      "Epoch 99/100\n",
      "352/352 - 76s - loss: 0.3976 - accuracy: 0.8662 - val_loss: 2.1673 - val_accuracy: 0.4759 - 76s/epoch - 216ms/step\n",
      "Epoch 100/100\n",
      "352/352 - 77s - loss: 0.3966 - accuracy: 0.8655 - val_loss: 2.2312 - val_accuracy: 0.4718 - 77s/epoch - 220ms/step\n",
      "[0.980400025844574, 0.9567999839782715, 0.9177333116531372, 0.8320000171661377, 0.6955999732017517, 0.4717999994754791, 0, 0, 0, 0]\n",
      "79/79 [==============================] - 6s 72ms/step - loss: 0.6961 - accuracy: 0.8545\n",
      "[0.9822999835014343, 0.9740999937057495, 0.9749000072479248, 0.9620000123977661, 0.9409999847412109, 0.8544999957084656, 0, 0, 0, 0]\n",
      "Epoch 1/100\n",
      "352/352 - 80s - loss: 2.3148 - accuracy: 0.1304 - val_loss: 2.1924 - val_accuracy: 0.1897 - 80s/epoch - 228ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "352/352 - 75s - loss: 2.1347 - accuracy: 0.2200 - val_loss: 2.0284 - val_accuracy: 0.2763 - 75s/epoch - 214ms/step\n",
      "Epoch 3/100\n",
      "352/352 - 100s - loss: 2.0206 - accuracy: 0.2775 - val_loss: 1.9679 - val_accuracy: 0.3011 - 100s/epoch - 283ms/step\n",
      "Epoch 4/100\n",
      "352/352 - 112s - loss: 1.9496 - accuracy: 0.3098 - val_loss: 1.8953 - val_accuracy: 0.3283 - 112s/epoch - 317ms/step\n",
      "Epoch 5/100\n",
      "352/352 - 112s - loss: 1.9170 - accuracy: 0.3230 - val_loss: 1.9199 - val_accuracy: 0.3253 - 112s/epoch - 319ms/step\n",
      "Epoch 6/100\n",
      "352/352 - 112s - loss: 1.8849 - accuracy: 0.3364 - val_loss: 1.8870 - val_accuracy: 0.3363 - 112s/epoch - 319ms/step\n",
      "Epoch 7/100\n",
      "352/352 - 114s - loss: 1.8497 - accuracy: 0.3459 - val_loss: 1.9322 - val_accuracy: 0.3161 - 114s/epoch - 325ms/step\n",
      "Epoch 8/100\n",
      "352/352 - 114s - loss: 1.8175 - accuracy: 0.3599 - val_loss: 1.8916 - val_accuracy: 0.3357 - 114s/epoch - 324ms/step\n",
      "Epoch 9/100\n",
      "352/352 - 116s - loss: 1.7675 - accuracy: 0.3795 - val_loss: 1.8985 - val_accuracy: 0.3335 - 116s/epoch - 329ms/step\n",
      "Epoch 10/100\n",
      "352/352 - 114s - loss: 1.7353 - accuracy: 0.3926 - val_loss: 1.9297 - val_accuracy: 0.3349 - 114s/epoch - 325ms/step\n",
      "Epoch 11/100\n",
      "352/352 - 113s - loss: 1.6804 - accuracy: 0.4115 - val_loss: 1.9386 - val_accuracy: 0.3183 - 113s/epoch - 321ms/step\n",
      "Epoch 12/100\n",
      "352/352 - 113s - loss: 1.6229 - accuracy: 0.4331 - val_loss: 1.9868 - val_accuracy: 0.3172 - 113s/epoch - 320ms/step\n",
      "Epoch 13/100\n",
      "352/352 - 112s - loss: 1.5619 - accuracy: 0.4566 - val_loss: 2.0583 - val_accuracy: 0.3097 - 112s/epoch - 319ms/step\n",
      "Epoch 14/100\n",
      "352/352 - 114s - loss: 1.4971 - accuracy: 0.4789 - val_loss: 2.0376 - val_accuracy: 0.3071 - 114s/epoch - 323ms/step\n",
      "Epoch 15/100\n",
      "352/352 - 114s - loss: 1.4454 - accuracy: 0.4974 - val_loss: 2.0910 - val_accuracy: 0.3145 - 114s/epoch - 325ms/step\n",
      "Epoch 16/100\n",
      "352/352 - 114s - loss: 1.3872 - accuracy: 0.5182 - val_loss: 2.1263 - val_accuracy: 0.3030 - 114s/epoch - 324ms/step\n",
      "Epoch 17/100\n",
      "352/352 - 114s - loss: 1.3218 - accuracy: 0.5424 - val_loss: 2.1800 - val_accuracy: 0.3032 - 114s/epoch - 323ms/step\n",
      "Epoch 18/100\n",
      "352/352 - 114s - loss: 1.2815 - accuracy: 0.5525 - val_loss: 2.2690 - val_accuracy: 0.3076 - 114s/epoch - 323ms/step\n",
      "Epoch 19/100\n",
      "352/352 - 114s - loss: 1.2313 - accuracy: 0.5727 - val_loss: 2.3153 - val_accuracy: 0.2988 - 114s/epoch - 324ms/step\n",
      "Epoch 20/100\n",
      "352/352 - 115s - loss: 1.1786 - accuracy: 0.5893 - val_loss: 2.4639 - val_accuracy: 0.2988 - 115s/epoch - 326ms/step\n",
      "Epoch 21/100\n",
      "352/352 - 114s - loss: 1.1395 - accuracy: 0.6014 - val_loss: 2.3670 - val_accuracy: 0.2847 - 114s/epoch - 324ms/step\n",
      "Epoch 22/100\n",
      "352/352 - 114s - loss: 1.1068 - accuracy: 0.6126 - val_loss: 2.4433 - val_accuracy: 0.2969 - 114s/epoch - 323ms/step\n",
      "Epoch 23/100\n",
      "352/352 - 113s - loss: 1.0646 - accuracy: 0.6269 - val_loss: 2.4946 - val_accuracy: 0.2907 - 113s/epoch - 322ms/step\n",
      "Epoch 24/100\n",
      "352/352 - 113s - loss: 1.0337 - accuracy: 0.6395 - val_loss: 2.5134 - val_accuracy: 0.2887 - 113s/epoch - 322ms/step\n",
      "Epoch 25/100\n",
      "352/352 - 112s - loss: 1.0062 - accuracy: 0.6488 - val_loss: 2.4356 - val_accuracy: 0.2860 - 112s/epoch - 319ms/step\n",
      "Epoch 26/100\n",
      "352/352 - 113s - loss: 0.9752 - accuracy: 0.6611 - val_loss: 2.7790 - val_accuracy: 0.2842 - 113s/epoch - 322ms/step\n",
      "Epoch 27/100\n",
      "352/352 - 113s - loss: 0.9610 - accuracy: 0.6649 - val_loss: 2.6255 - val_accuracy: 0.2784 - 113s/epoch - 320ms/step\n",
      "Epoch 28/100\n",
      "352/352 - 113s - loss: 0.9402 - accuracy: 0.6723 - val_loss: 2.7206 - val_accuracy: 0.2871 - 113s/epoch - 320ms/step\n",
      "Epoch 29/100\n",
      "352/352 - 113s - loss: 0.9117 - accuracy: 0.6827 - val_loss: 2.9412 - val_accuracy: 0.2680 - 113s/epoch - 322ms/step\n",
      "Epoch 30/100\n",
      "352/352 - 113s - loss: 0.9018 - accuracy: 0.6875 - val_loss: 2.8872 - val_accuracy: 0.2797 - 113s/epoch - 321ms/step\n",
      "Epoch 31/100\n",
      "352/352 - 113s - loss: 0.8888 - accuracy: 0.6894 - val_loss: 2.9738 - val_accuracy: 0.2836 - 113s/epoch - 320ms/step\n",
      "Epoch 32/100\n",
      "352/352 - 113s - loss: 0.8711 - accuracy: 0.6949 - val_loss: 2.9238 - val_accuracy: 0.2833 - 113s/epoch - 321ms/step\n",
      "Epoch 33/100\n",
      "352/352 - 113s - loss: 0.8395 - accuracy: 0.7076 - val_loss: 2.8777 - val_accuracy: 0.2793 - 113s/epoch - 321ms/step\n",
      "Epoch 34/100\n",
      "352/352 - 113s - loss: 0.8382 - accuracy: 0.7073 - val_loss: 2.7381 - val_accuracy: 0.2861 - 113s/epoch - 320ms/step\n",
      "Epoch 35/100\n",
      "352/352 - 113s - loss: 0.8269 - accuracy: 0.7131 - val_loss: 2.9395 - val_accuracy: 0.2746 - 113s/epoch - 320ms/step\n",
      "Epoch 36/100\n",
      "352/352 - 113s - loss: 0.7982 - accuracy: 0.7239 - val_loss: 2.7210 - val_accuracy: 0.2814 - 113s/epoch - 322ms/step\n",
      "Epoch 37/100\n",
      "352/352 - 113s - loss: 0.7923 - accuracy: 0.7234 - val_loss: 2.8837 - val_accuracy: 0.2743 - 113s/epoch - 320ms/step\n",
      "Epoch 38/100\n",
      "352/352 - 113s - loss: 0.7870 - accuracy: 0.7275 - val_loss: 2.8776 - val_accuracy: 0.2829 - 113s/epoch - 321ms/step\n",
      "Epoch 39/100\n",
      "352/352 - 115s - loss: 0.7832 - accuracy: 0.7298 - val_loss: 2.9312 - val_accuracy: 0.2775 - 115s/epoch - 325ms/step\n",
      "Epoch 40/100\n",
      "352/352 - 115s - loss: 0.7644 - accuracy: 0.7342 - val_loss: 3.0335 - val_accuracy: 0.2726 - 115s/epoch - 326ms/step\n",
      "Epoch 41/100\n",
      "352/352 - 117s - loss: 0.7521 - accuracy: 0.7393 - val_loss: 3.1539 - val_accuracy: 0.2665 - 117s/epoch - 333ms/step\n",
      "Epoch 42/100\n",
      "352/352 - 115s - loss: 0.7475 - accuracy: 0.7398 - val_loss: 2.8578 - val_accuracy: 0.2609 - 115s/epoch - 326ms/step\n",
      "Epoch 43/100\n",
      "352/352 - 114s - loss: 0.7468 - accuracy: 0.7424 - val_loss: 3.0472 - val_accuracy: 0.2791 - 114s/epoch - 324ms/step\n",
      "Epoch 44/100\n",
      "352/352 - 113s - loss: 0.7232 - accuracy: 0.7499 - val_loss: 2.7248 - val_accuracy: 0.2741 - 113s/epoch - 321ms/step\n",
      "Epoch 45/100\n",
      "352/352 - 139s - loss: 0.7310 - accuracy: 0.7463 - val_loss: 3.1841 - val_accuracy: 0.2657 - 139s/epoch - 394ms/step\n",
      "Epoch 46/100\n",
      "352/352 - 157s - loss: 0.7301 - accuracy: 0.7463 - val_loss: 3.1444 - val_accuracy: 0.2740 - 157s/epoch - 446ms/step\n",
      "Epoch 47/100\n",
      "352/352 - 160s - loss: 0.7218 - accuracy: 0.7496 - val_loss: 3.0166 - val_accuracy: 0.2743 - 160s/epoch - 455ms/step\n",
      "Epoch 48/100\n",
      "352/352 - 160s - loss: 0.7148 - accuracy: 0.7541 - val_loss: 3.1492 - val_accuracy: 0.2672 - 160s/epoch - 455ms/step\n",
      "Epoch 49/100\n",
      "352/352 - 158s - loss: 0.6973 - accuracy: 0.7588 - val_loss: 3.1644 - val_accuracy: 0.2752 - 158s/epoch - 450ms/step\n",
      "Epoch 50/100\n",
      "352/352 - 158s - loss: 0.6957 - accuracy: 0.7586 - val_loss: 3.3418 - val_accuracy: 0.2711 - 158s/epoch - 449ms/step\n",
      "Epoch 51/100\n",
      "352/352 - 158s - loss: 0.6896 - accuracy: 0.7625 - val_loss: 3.0694 - val_accuracy: 0.2783 - 158s/epoch - 449ms/step\n",
      "Epoch 52/100\n",
      "352/352 - 157s - loss: 0.6919 - accuracy: 0.7597 - val_loss: 3.2759 - val_accuracy: 0.2617 - 157s/epoch - 447ms/step\n",
      "Epoch 53/100\n",
      "352/352 - 159s - loss: 0.6941 - accuracy: 0.7622 - val_loss: 3.2575 - val_accuracy: 0.2691 - 159s/epoch - 452ms/step\n",
      "Epoch 54/100\n",
      "352/352 - 158s - loss: 0.6765 - accuracy: 0.7674 - val_loss: 3.2558 - val_accuracy: 0.2686 - 158s/epoch - 450ms/step\n",
      "Epoch 55/100\n",
      "352/352 - 159s - loss: 0.6780 - accuracy: 0.7675 - val_loss: 3.1558 - val_accuracy: 0.2695 - 159s/epoch - 452ms/step\n",
      "Epoch 56/100\n",
      "352/352 - 159s - loss: 0.6814 - accuracy: 0.7653 - val_loss: 3.0511 - val_accuracy: 0.2680 - 159s/epoch - 451ms/step\n",
      "Epoch 57/100\n",
      "352/352 - 159s - loss: 0.6861 - accuracy: 0.7648 - val_loss: 3.1480 - val_accuracy: 0.2668 - 159s/epoch - 452ms/step\n",
      "Epoch 58/100\n",
      "352/352 - 160s - loss: 0.6675 - accuracy: 0.7726 - val_loss: 3.1336 - val_accuracy: 0.2653 - 160s/epoch - 453ms/step\n",
      "Epoch 59/100\n",
      "352/352 - 158s - loss: 0.6543 - accuracy: 0.7742 - val_loss: 3.0072 - val_accuracy: 0.2655 - 158s/epoch - 450ms/step\n",
      "Epoch 60/100\n",
      "352/352 - 161s - loss: 0.6526 - accuracy: 0.7770 - val_loss: 3.4872 - val_accuracy: 0.2726 - 161s/epoch - 458ms/step\n",
      "Epoch 61/100\n",
      "352/352 - 167s - loss: 0.6777 - accuracy: 0.7662 - val_loss: 3.1059 - val_accuracy: 0.2623 - 167s/epoch - 474ms/step\n",
      "Epoch 62/100\n",
      "352/352 - 164s - loss: 0.6584 - accuracy: 0.7715 - val_loss: 3.5270 - val_accuracy: 0.2605 - 164s/epoch - 466ms/step\n",
      "Epoch 63/100\n",
      "352/352 - 165s - loss: 0.6605 - accuracy: 0.7736 - val_loss: 3.2132 - val_accuracy: 0.2708 - 165s/epoch - 467ms/step\n",
      "Epoch 64/100\n",
      "352/352 - 167s - loss: 0.6427 - accuracy: 0.7786 - val_loss: 3.4572 - val_accuracy: 0.2761 - 167s/epoch - 474ms/step\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 - 184s - loss: 0.6518 - accuracy: 0.7774 - val_loss: 3.3946 - val_accuracy: 0.2640 - 184s/epoch - 524ms/step\n",
      "Epoch 66/100\n",
      "352/352 - 223s - loss: 0.6375 - accuracy: 0.7815 - val_loss: 3.2752 - val_accuracy: 0.2718 - 223s/epoch - 633ms/step\n",
      "Epoch 67/100\n",
      "352/352 - 211s - loss: 0.6376 - accuracy: 0.7824 - val_loss: 3.2207 - val_accuracy: 0.2690 - 211s/epoch - 600ms/step\n",
      "Epoch 68/100\n",
      "352/352 - 208s - loss: 0.6319 - accuracy: 0.7827 - val_loss: 3.4154 - val_accuracy: 0.2701 - 208s/epoch - 590ms/step\n",
      "Epoch 69/100\n",
      "352/352 - 207s - loss: 0.6248 - accuracy: 0.7851 - val_loss: 3.4964 - val_accuracy: 0.2666 - 207s/epoch - 589ms/step\n",
      "Epoch 70/100\n",
      "352/352 - 208s - loss: 0.6243 - accuracy: 0.7841 - val_loss: 3.3628 - val_accuracy: 0.2720 - 208s/epoch - 589ms/step\n",
      "Epoch 71/100\n",
      "352/352 - 209s - loss: 0.6163 - accuracy: 0.7881 - val_loss: 3.5848 - val_accuracy: 0.2685 - 209s/epoch - 593ms/step\n",
      "Epoch 72/100\n",
      "352/352 - 208s - loss: 0.6282 - accuracy: 0.7823 - val_loss: 3.4860 - val_accuracy: 0.2683 - 208s/epoch - 590ms/step\n",
      "Epoch 73/100\n",
      "352/352 - 206s - loss: 0.6252 - accuracy: 0.7848 - val_loss: 3.4089 - val_accuracy: 0.2675 - 206s/epoch - 584ms/step\n",
      "Epoch 74/100\n",
      "352/352 - 201s - loss: 0.6134 - accuracy: 0.7901 - val_loss: 3.2844 - val_accuracy: 0.2634 - 201s/epoch - 572ms/step\n",
      "Epoch 75/100\n",
      "352/352 - 202s - loss: 0.6055 - accuracy: 0.7930 - val_loss: 3.4819 - val_accuracy: 0.2629 - 202s/epoch - 574ms/step\n",
      "Epoch 76/100\n",
      "352/352 - 200s - loss: 0.6197 - accuracy: 0.7878 - val_loss: 3.4525 - val_accuracy: 0.2712 - 200s/epoch - 569ms/step\n",
      "Epoch 77/100\n",
      "352/352 - 201s - loss: 0.6199 - accuracy: 0.7874 - val_loss: 3.2748 - val_accuracy: 0.2695 - 201s/epoch - 571ms/step\n",
      "Epoch 78/100\n",
      "352/352 - 201s - loss: 0.6188 - accuracy: 0.7871 - val_loss: 3.2615 - val_accuracy: 0.2679 - 201s/epoch - 570ms/step\n",
      "Epoch 79/100\n",
      "352/352 - 207s - loss: 0.5960 - accuracy: 0.7959 - val_loss: 3.3504 - val_accuracy: 0.2571 - 207s/epoch - 587ms/step\n",
      "Epoch 80/100\n",
      "352/352 - 213s - loss: 0.6103 - accuracy: 0.7906 - val_loss: 3.4710 - val_accuracy: 0.2629 - 213s/epoch - 604ms/step\n",
      "Epoch 81/100\n",
      "352/352 - 196s - loss: 0.5824 - accuracy: 0.8019 - val_loss: 3.5406 - val_accuracy: 0.2673 - 196s/epoch - 557ms/step\n",
      "Epoch 82/100\n",
      "352/352 - 192s - loss: 0.5936 - accuracy: 0.7953 - val_loss: 3.2761 - val_accuracy: 0.2715 - 192s/epoch - 546ms/step\n",
      "Epoch 83/100\n",
      "352/352 - 193s - loss: 0.5970 - accuracy: 0.7940 - val_loss: 3.3005 - val_accuracy: 0.2730 - 193s/epoch - 548ms/step\n",
      "Epoch 84/100\n",
      "352/352 - 193s - loss: 0.5913 - accuracy: 0.7977 - val_loss: 3.5293 - val_accuracy: 0.2639 - 193s/epoch - 549ms/step\n",
      "Epoch 85/100\n",
      "352/352 - 182s - loss: 0.5774 - accuracy: 0.8000 - val_loss: 3.4288 - val_accuracy: 0.2640 - 182s/epoch - 517ms/step\n",
      "Epoch 86/100\n",
      "352/352 - 194s - loss: 0.5894 - accuracy: 0.7984 - val_loss: 3.1410 - val_accuracy: 0.2745 - 194s/epoch - 550ms/step\n",
      "Epoch 87/100\n",
      "352/352 - 193s - loss: 0.5873 - accuracy: 0.7984 - val_loss: 3.3030 - val_accuracy: 0.2689 - 193s/epoch - 549ms/step\n",
      "Epoch 88/100\n",
      "352/352 - 195s - loss: 0.5963 - accuracy: 0.7962 - val_loss: 3.5185 - val_accuracy: 0.2603 - 195s/epoch - 553ms/step\n",
      "Epoch 89/100\n",
      "352/352 - 196s - loss: 0.5702 - accuracy: 0.8036 - val_loss: 3.4524 - val_accuracy: 0.2587 - 196s/epoch - 556ms/step\n",
      "Epoch 90/100\n",
      "352/352 - 182s - loss: 0.5888 - accuracy: 0.7967 - val_loss: 3.4718 - val_accuracy: 0.2596 - 182s/epoch - 517ms/step\n",
      "Epoch 91/100\n",
      "352/352 - 193s - loss: 0.5775 - accuracy: 0.8011 - val_loss: 3.4362 - val_accuracy: 0.2645 - 193s/epoch - 548ms/step\n",
      "Epoch 92/100\n",
      "352/352 - 195s - loss: 0.5849 - accuracy: 0.8005 - val_loss: 3.2139 - val_accuracy: 0.2699 - 195s/epoch - 553ms/step\n",
      "Epoch 93/100\n",
      "352/352 - 194s - loss: 0.5748 - accuracy: 0.8007 - val_loss: 3.3435 - val_accuracy: 0.2706 - 194s/epoch - 551ms/step\n",
      "Epoch 94/100\n",
      "352/352 - 194s - loss: 0.5770 - accuracy: 0.8007 - val_loss: 3.3782 - val_accuracy: 0.2636 - 194s/epoch - 551ms/step\n",
      "Epoch 95/100\n",
      "352/352 - 183s - loss: 0.5574 - accuracy: 0.8075 - val_loss: 3.6840 - val_accuracy: 0.2711 - 183s/epoch - 521ms/step\n",
      "Epoch 96/100\n",
      "352/352 - 193s - loss: 0.5637 - accuracy: 0.8062 - val_loss: 3.3189 - val_accuracy: 0.2605 - 193s/epoch - 547ms/step\n",
      "Epoch 97/100\n",
      "352/352 - 185s - loss: 0.5661 - accuracy: 0.8040 - val_loss: 3.4846 - val_accuracy: 0.2695 - 185s/epoch - 524ms/step\n",
      "Epoch 98/100\n",
      "352/352 - 189s - loss: 0.5801 - accuracy: 0.8016 - val_loss: 3.4544 - val_accuracy: 0.2653 - 189s/epoch - 537ms/step\n",
      "Epoch 99/100\n",
      "352/352 - 189s - loss: 0.5556 - accuracy: 0.8091 - val_loss: 3.4572 - val_accuracy: 0.2684 - 189s/epoch - 537ms/step\n",
      "Epoch 100/100\n",
      "352/352 - 180s - loss: 0.5765 - accuracy: 0.8012 - val_loss: 3.6851 - val_accuracy: 0.2616 - 180s/epoch - 512ms/step\n",
      "[0.980400025844574, 0.9567999839782715, 0.9177333116531372, 0.8320000171661377, 0.6955999732017517, 0.4717999994754791, 0.26159998774528503, 0, 0, 0]\n",
      "79/79 [==============================] - 13s 166ms/step - loss: 1.9360 - accuracy: 0.6090\n",
      "[0.9822999835014343, 0.9740999937057495, 0.9749000072479248, 0.9620000123977661, 0.9409999847412109, 0.8544999957084656, 0.609000027179718, 0, 0, 0]\n",
      "Epoch 1/100\n",
      "352/352 - 176s - loss: 2.3350 - accuracy: 0.1069 - val_loss: 2.2920 - val_accuracy: 0.1207 - 176s/epoch - 499ms/step\n",
      "Epoch 2/100\n",
      "352/352 - 142s - loss: 2.2681 - accuracy: 0.1429 - val_loss: 2.2587 - val_accuracy: 0.1556 - 142s/epoch - 403ms/step\n",
      "Epoch 3/100\n",
      "352/352 - 141s - loss: 2.2436 - accuracy: 0.1612 - val_loss: 2.2426 - val_accuracy: 0.1617 - 141s/epoch - 400ms/step\n",
      "Epoch 4/100\n",
      "352/352 - 140s - loss: 2.2156 - accuracy: 0.1864 - val_loss: 2.2079 - val_accuracy: 0.1879 - 140s/epoch - 398ms/step\n",
      "Epoch 5/100\n",
      "352/352 - 140s - loss: 2.1868 - accuracy: 0.2015 - val_loss: 2.1870 - val_accuracy: 0.2012 - 140s/epoch - 396ms/step\n",
      "Epoch 6/100\n",
      "352/352 - 128s - loss: 2.1667 - accuracy: 0.2133 - val_loss: 2.2043 - val_accuracy: 0.1986 - 128s/epoch - 364ms/step\n",
      "Epoch 7/100\n",
      "352/352 - 137s - loss: 2.1429 - accuracy: 0.2239 - val_loss: 2.1777 - val_accuracy: 0.2089 - 137s/epoch - 390ms/step\n",
      "Epoch 8/100\n",
      "352/352 - 139s - loss: 2.1181 - accuracy: 0.2361 - val_loss: 2.2106 - val_accuracy: 0.1911 - 139s/epoch - 394ms/step\n",
      "Epoch 9/100\n",
      "352/352 - 139s - loss: 2.0877 - accuracy: 0.2523 - val_loss: 2.1999 - val_accuracy: 0.1993 - 139s/epoch - 394ms/step\n",
      "Epoch 10/100\n",
      "352/352 - 139s - loss: 2.0545 - accuracy: 0.2657 - val_loss: 2.2115 - val_accuracy: 0.1985 - 139s/epoch - 394ms/step\n",
      "Epoch 11/100\n",
      "352/352 - 137s - loss: 2.0134 - accuracy: 0.2843 - val_loss: 2.2366 - val_accuracy: 0.1947 - 137s/epoch - 390ms/step\n",
      "Epoch 12/100\n",
      "352/352 - 138s - loss: 1.9727 - accuracy: 0.3018 - val_loss: 2.2686 - val_accuracy: 0.1902 - 138s/epoch - 392ms/step\n",
      "Epoch 13/100\n",
      "352/352 - 137s - loss: 1.9236 - accuracy: 0.3198 - val_loss: 2.2868 - val_accuracy: 0.1896 - 137s/epoch - 390ms/step\n",
      "Epoch 14/100\n",
      "352/352 - 137s - loss: 1.8751 - accuracy: 0.3406 - val_loss: 2.3176 - val_accuracy: 0.1850 - 137s/epoch - 388ms/step\n",
      "Epoch 15/100\n",
      "352/352 - 128s - loss: 1.8243 - accuracy: 0.3580 - val_loss: 2.3322 - val_accuracy: 0.1855 - 128s/epoch - 365ms/step\n",
      "Epoch 16/100\n",
      "352/352 - 133s - loss: 1.7769 - accuracy: 0.3755 - val_loss: 2.3562 - val_accuracy: 0.1851 - 133s/epoch - 378ms/step\n",
      "Epoch 17/100\n",
      "352/352 - 140s - loss: 1.7352 - accuracy: 0.3885 - val_loss: 2.4432 - val_accuracy: 0.1795 - 140s/epoch - 397ms/step\n",
      "Epoch 18/100\n",
      "352/352 - 126s - loss: 1.6933 - accuracy: 0.4032 - val_loss: 2.5074 - val_accuracy: 0.1797 - 126s/epoch - 357ms/step\n",
      "Epoch 19/100\n",
      "352/352 - 109s - loss: 1.6584 - accuracy: 0.4165 - val_loss: 2.5593 - val_accuracy: 0.1819 - 109s/epoch - 309ms/step\n",
      "Epoch 20/100\n",
      "352/352 - 109s - loss: 1.6205 - accuracy: 0.4280 - val_loss: 2.6163 - val_accuracy: 0.1781 - 109s/epoch - 310ms/step\n",
      "Epoch 21/100\n",
      "352/352 - 108s - loss: 1.5878 - accuracy: 0.4420 - val_loss: 2.6432 - val_accuracy: 0.1781 - 108s/epoch - 308ms/step\n",
      "Epoch 22/100\n",
      "352/352 - 109s - loss: 1.5625 - accuracy: 0.4467 - val_loss: 2.6025 - val_accuracy: 0.1715 - 109s/epoch - 310ms/step\n",
      "Epoch 23/100\n",
      "352/352 - 109s - loss: 1.5259 - accuracy: 0.4649 - val_loss: 2.6403 - val_accuracy: 0.1777 - 109s/epoch - 310ms/step\n",
      "Epoch 24/100\n",
      "352/352 - 103s - loss: 1.5028 - accuracy: 0.4701 - val_loss: 2.6284 - val_accuracy: 0.1807 - 103s/epoch - 293ms/step\n",
      "Epoch 25/100\n",
      "352/352 - 101s - loss: 1.4863 - accuracy: 0.4746 - val_loss: 2.7982 - val_accuracy: 0.1687 - 101s/epoch - 287ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "352/352 - 109s - loss: 1.4582 - accuracy: 0.4858 - val_loss: 2.8046 - val_accuracy: 0.1687 - 109s/epoch - 311ms/step\n",
      "Epoch 27/100\n",
      "352/352 - 110s - loss: 1.4481 - accuracy: 0.4904 - val_loss: 2.6185 - val_accuracy: 0.1711 - 110s/epoch - 312ms/step\n",
      "Epoch 28/100\n",
      "352/352 - 109s - loss: 1.4331 - accuracy: 0.4958 - val_loss: 2.7609 - val_accuracy: 0.1723 - 109s/epoch - 311ms/step\n",
      "Epoch 29/100\n",
      "352/352 - 110s - loss: 1.4159 - accuracy: 0.4995 - val_loss: 2.7192 - val_accuracy: 0.1716 - 110s/epoch - 312ms/step\n",
      "Epoch 30/100\n",
      "352/352 - 111s - loss: 1.4031 - accuracy: 0.5050 - val_loss: 2.7751 - val_accuracy: 0.1705 - 111s/epoch - 316ms/step\n",
      "Epoch 31/100\n",
      "352/352 - 111s - loss: 1.3828 - accuracy: 0.5141 - val_loss: 2.8312 - val_accuracy: 0.1697 - 111s/epoch - 316ms/step\n",
      "Epoch 32/100\n",
      "352/352 - 111s - loss: 1.3764 - accuracy: 0.5168 - val_loss: 2.8035 - val_accuracy: 0.1739 - 111s/epoch - 316ms/step\n",
      "Epoch 33/100\n",
      "352/352 - 110s - loss: 1.3629 - accuracy: 0.5217 - val_loss: 2.8205 - val_accuracy: 0.1667 - 110s/epoch - 312ms/step\n",
      "Epoch 34/100\n",
      "352/352 - 99s - loss: 1.3504 - accuracy: 0.5242 - val_loss: 2.9152 - val_accuracy: 0.1686 - 99s/epoch - 282ms/step\n",
      "Epoch 35/100\n",
      "352/352 - 104s - loss: 1.3401 - accuracy: 0.5294 - val_loss: 2.9584 - val_accuracy: 0.1722 - 104s/epoch - 294ms/step\n",
      "Epoch 36/100\n",
      "352/352 - 111s - loss: 1.3203 - accuracy: 0.5372 - val_loss: 2.8747 - val_accuracy: 0.1665 - 111s/epoch - 315ms/step\n",
      "Epoch 37/100\n",
      "352/352 - 107s - loss: 1.3318 - accuracy: 0.5313 - val_loss: 2.8893 - val_accuracy: 0.1644 - 107s/epoch - 305ms/step\n",
      "Epoch 38/100\n",
      "352/352 - 105s - loss: 1.3213 - accuracy: 0.5353 - val_loss: 2.8696 - val_accuracy: 0.1675 - 105s/epoch - 299ms/step\n",
      "Epoch 39/100\n",
      "352/352 - 107s - loss: 1.3227 - accuracy: 0.5376 - val_loss: 2.9155 - val_accuracy: 0.1615 - 107s/epoch - 305ms/step\n",
      "Epoch 40/100\n",
      "352/352 - 108s - loss: 1.3171 - accuracy: 0.5375 - val_loss: 2.9280 - val_accuracy: 0.1665 - 108s/epoch - 307ms/step\n",
      "Epoch 41/100\n",
      "352/352 - 103s - loss: 1.3006 - accuracy: 0.5452 - val_loss: 2.9115 - val_accuracy: 0.1755 - 103s/epoch - 294ms/step\n",
      "Epoch 42/100\n",
      "352/352 - 104s - loss: 1.3007 - accuracy: 0.5447 - val_loss: 2.8946 - val_accuracy: 0.1693 - 104s/epoch - 296ms/step\n",
      "Epoch 43/100\n",
      "352/352 - 104s - loss: 1.2914 - accuracy: 0.5466 - val_loss: 2.9782 - val_accuracy: 0.1701 - 104s/epoch - 295ms/step\n",
      "Epoch 44/100\n",
      "352/352 - 105s - loss: 1.3012 - accuracy: 0.5456 - val_loss: 2.8464 - val_accuracy: 0.1707 - 105s/epoch - 297ms/step\n",
      "Epoch 45/100\n",
      "352/352 - 104s - loss: 1.2887 - accuracy: 0.5496 - val_loss: 2.8646 - val_accuracy: 0.1677 - 104s/epoch - 294ms/step\n",
      "Epoch 46/100\n",
      "352/352 - 103s - loss: 1.2791 - accuracy: 0.5545 - val_loss: 2.9866 - val_accuracy: 0.1699 - 103s/epoch - 294ms/step\n",
      "Epoch 47/100\n",
      "352/352 - 103s - loss: 1.2746 - accuracy: 0.5545 - val_loss: 3.0137 - val_accuracy: 0.1647 - 103s/epoch - 293ms/step\n",
      "Epoch 48/100\n",
      "352/352 - 103s - loss: 1.2779 - accuracy: 0.5542 - val_loss: 3.0045 - val_accuracy: 0.1716 - 103s/epoch - 293ms/step\n",
      "Epoch 49/100\n",
      "352/352 - 103s - loss: 1.3017 - accuracy: 0.5468 - val_loss: 2.9457 - val_accuracy: 0.1735 - 103s/epoch - 293ms/step\n",
      "Epoch 50/100\n",
      "352/352 - 103s - loss: 1.2845 - accuracy: 0.5516 - val_loss: 2.9578 - val_accuracy: 0.1703 - 103s/epoch - 294ms/step\n",
      "Epoch 51/100\n",
      "352/352 - 103s - loss: 1.3009 - accuracy: 0.5459 - val_loss: 3.0047 - val_accuracy: 0.1705 - 103s/epoch - 293ms/step\n",
      "Epoch 52/100\n",
      "352/352 - 103s - loss: 1.2899 - accuracy: 0.5507 - val_loss: 2.9416 - val_accuracy: 0.1723 - 103s/epoch - 293ms/step\n",
      "Epoch 53/100\n",
      "352/352 - 103s - loss: 1.3009 - accuracy: 0.5470 - val_loss: 3.0095 - val_accuracy: 0.1703 - 103s/epoch - 293ms/step\n",
      "Epoch 54/100\n",
      "352/352 - 99s - loss: 1.3087 - accuracy: 0.5442 - val_loss: 3.0787 - val_accuracy: 0.1665 - 99s/epoch - 282ms/step\n",
      "Epoch 55/100\n",
      "352/352 - 101s - loss: 1.3066 - accuracy: 0.5446 - val_loss: 3.0672 - val_accuracy: 0.1664 - 101s/epoch - 286ms/step\n",
      "Epoch 56/100\n",
      "352/352 - 108s - loss: 1.3095 - accuracy: 0.5433 - val_loss: 2.9167 - val_accuracy: 0.1669 - 108s/epoch - 306ms/step\n",
      "Epoch 57/100\n",
      "352/352 - 107s - loss: 1.3030 - accuracy: 0.5453 - val_loss: 3.0132 - val_accuracy: 0.1671 - 107s/epoch - 304ms/step\n",
      "Epoch 58/100\n",
      "352/352 - 103s - loss: 1.3074 - accuracy: 0.5433 - val_loss: 2.9867 - val_accuracy: 0.1671 - 103s/epoch - 293ms/step\n",
      "Epoch 59/100\n",
      "352/352 - 104s - loss: 1.3217 - accuracy: 0.5418 - val_loss: 2.8633 - val_accuracy: 0.1677 - 104s/epoch - 294ms/step\n",
      "Epoch 60/100\n",
      "352/352 - 103s - loss: 1.3122 - accuracy: 0.5422 - val_loss: 2.8813 - val_accuracy: 0.1660 - 103s/epoch - 293ms/step\n",
      "Epoch 61/100\n",
      "352/352 - 103s - loss: 1.3228 - accuracy: 0.5399 - val_loss: 2.9438 - val_accuracy: 0.1729 - 103s/epoch - 294ms/step\n",
      "Epoch 62/100\n",
      "352/352 - 104s - loss: 1.3148 - accuracy: 0.5421 - val_loss: 2.7933 - val_accuracy: 0.1673 - 104s/epoch - 294ms/step\n",
      "Epoch 63/100\n",
      "352/352 - 105s - loss: 1.3364 - accuracy: 0.5364 - val_loss: 3.0423 - val_accuracy: 0.1680 - 105s/epoch - 299ms/step\n",
      "Epoch 64/100\n",
      "352/352 - 105s - loss: 1.3308 - accuracy: 0.5382 - val_loss: 2.9418 - val_accuracy: 0.1700 - 105s/epoch - 298ms/step\n",
      "Epoch 65/100\n",
      "352/352 - 107s - loss: 1.3331 - accuracy: 0.5400 - val_loss: 2.9335 - val_accuracy: 0.1661 - 107s/epoch - 304ms/step\n",
      "Epoch 66/100\n",
      "352/352 - 104s - loss: 1.3449 - accuracy: 0.5337 - val_loss: 2.9627 - val_accuracy: 0.1651 - 104s/epoch - 296ms/step\n",
      "Epoch 67/100\n",
      "352/352 - 103s - loss: 1.3410 - accuracy: 0.5360 - val_loss: 2.7171 - val_accuracy: 0.1677 - 103s/epoch - 293ms/step\n",
      "Epoch 68/100\n",
      "352/352 - 103s - loss: 1.3508 - accuracy: 0.5331 - val_loss: 2.9272 - val_accuracy: 0.1656 - 103s/epoch - 292ms/step\n",
      "Epoch 69/100\n",
      "352/352 - 103s - loss: 1.3637 - accuracy: 0.5266 - val_loss: 2.8734 - val_accuracy: 0.1755 - 103s/epoch - 293ms/step\n",
      "Epoch 70/100\n",
      "352/352 - 103s - loss: 1.3581 - accuracy: 0.5270 - val_loss: 2.8289 - val_accuracy: 0.1662 - 103s/epoch - 293ms/step\n",
      "Epoch 71/100\n",
      "352/352 - 97s - loss: 1.3523 - accuracy: 0.5300 - val_loss: 2.8064 - val_accuracy: 0.1729 - 97s/epoch - 276ms/step\n",
      "Epoch 72/100\n",
      "352/352 - 96s - loss: 1.3560 - accuracy: 0.5276 - val_loss: 2.9238 - val_accuracy: 0.1703 - 96s/epoch - 273ms/step\n",
      "Epoch 73/100\n",
      "352/352 - 95s - loss: 1.3597 - accuracy: 0.5258 - val_loss: 2.8737 - val_accuracy: 0.1709 - 95s/epoch - 269ms/step\n",
      "Epoch 74/100\n",
      "352/352 - 95s - loss: 1.3738 - accuracy: 0.5224 - val_loss: 2.8860 - val_accuracy: 0.1628 - 95s/epoch - 269ms/step\n",
      "Epoch 75/100\n",
      "352/352 - 94s - loss: 1.3783 - accuracy: 0.5230 - val_loss: 2.8963 - val_accuracy: 0.1670 - 94s/epoch - 268ms/step\n",
      "Epoch 76/100\n",
      "352/352 - 96s - loss: 1.3682 - accuracy: 0.5240 - val_loss: 2.9294 - val_accuracy: 0.1679 - 96s/epoch - 272ms/step\n",
      "Epoch 77/100\n",
      "352/352 - 96s - loss: 1.3590 - accuracy: 0.5284 - val_loss: 2.8345 - val_accuracy: 0.1625 - 96s/epoch - 273ms/step\n",
      "Epoch 78/100\n",
      "352/352 - 112s - loss: 1.3541 - accuracy: 0.5305 - val_loss: 3.0359 - val_accuracy: 0.1646 - 112s/epoch - 318ms/step\n",
      "Epoch 79/100\n",
      "352/352 - 125s - loss: 1.3681 - accuracy: 0.5238 - val_loss: 2.9056 - val_accuracy: 0.1657 - 125s/epoch - 355ms/step\n",
      "Epoch 80/100\n",
      "352/352 - 123s - loss: 1.3651 - accuracy: 0.5253 - val_loss: 2.8285 - val_accuracy: 0.1679 - 123s/epoch - 349ms/step\n",
      "Epoch 81/100\n",
      "352/352 - 105s - loss: 1.3840 - accuracy: 0.5196 - val_loss: 2.9457 - val_accuracy: 0.1681 - 105s/epoch - 298ms/step\n",
      "Epoch 82/100\n",
      "352/352 - 96s - loss: 1.3855 - accuracy: 0.5195 - val_loss: 2.7174 - val_accuracy: 0.1695 - 96s/epoch - 272ms/step\n",
      "Epoch 83/100\n",
      "352/352 - 96s - loss: 1.4100 - accuracy: 0.5116 - val_loss: 2.8122 - val_accuracy: 0.1699 - 96s/epoch - 273ms/step\n",
      "Epoch 84/100\n",
      "352/352 - 95s - loss: 1.3819 - accuracy: 0.5214 - val_loss: 2.9644 - val_accuracy: 0.1687 - 95s/epoch - 271ms/step\n",
      "Epoch 85/100\n",
      "352/352 - 95s - loss: 1.3741 - accuracy: 0.5247 - val_loss: 2.9075 - val_accuracy: 0.1726 - 95s/epoch - 271ms/step\n",
      "Epoch 86/100\n",
      "352/352 - 94s - loss: 1.3990 - accuracy: 0.5155 - val_loss: 2.8609 - val_accuracy: 0.1705 - 94s/epoch - 268ms/step\n",
      "Epoch 87/100\n",
      "352/352 - 94s - loss: 1.3765 - accuracy: 0.5210 - val_loss: 2.9468 - val_accuracy: 0.1621 - 94s/epoch - 267ms/step\n",
      "Epoch 88/100\n",
      "352/352 - 95s - loss: 1.3760 - accuracy: 0.5237 - val_loss: 2.9184 - val_accuracy: 0.1700 - 95s/epoch - 269ms/step\n",
      "Epoch 89/100\n",
      "352/352 - 93s - loss: 1.3862 - accuracy: 0.5170 - val_loss: 2.8625 - val_accuracy: 0.1651 - 93s/epoch - 265ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100\n",
      "352/352 - 94s - loss: 1.3793 - accuracy: 0.5246 - val_loss: 2.9803 - val_accuracy: 0.1744 - 94s/epoch - 266ms/step\n",
      "Epoch 91/100\n",
      "352/352 - 95s - loss: 1.4042 - accuracy: 0.5143 - val_loss: 2.8130 - val_accuracy: 0.1717 - 95s/epoch - 270ms/step\n",
      "Epoch 92/100\n",
      "352/352 - 96s - loss: 1.4079 - accuracy: 0.5140 - val_loss: 2.8063 - val_accuracy: 0.1666 - 96s/epoch - 272ms/step\n",
      "Epoch 93/100\n",
      "352/352 - 98s - loss: 1.3980 - accuracy: 0.5146 - val_loss: 2.8841 - val_accuracy: 0.1696 - 98s/epoch - 278ms/step\n",
      "Epoch 94/100\n",
      "352/352 - 96s - loss: 1.4238 - accuracy: 0.5035 - val_loss: 2.8953 - val_accuracy: 0.1725 - 96s/epoch - 274ms/step\n",
      "Epoch 95/100\n",
      "352/352 - 96s - loss: 1.4207 - accuracy: 0.5072 - val_loss: 2.8021 - val_accuracy: 0.1728 - 96s/epoch - 271ms/step\n",
      "Epoch 96/100\n",
      "352/352 - 96s - loss: 1.4122 - accuracy: 0.5095 - val_loss: 2.8969 - val_accuracy: 0.1675 - 96s/epoch - 272ms/step\n",
      "Epoch 97/100\n",
      "352/352 - 96s - loss: 1.4262 - accuracy: 0.5050 - val_loss: 2.7070 - val_accuracy: 0.1647 - 96s/epoch - 272ms/step\n",
      "Epoch 98/100\n",
      "352/352 - 96s - loss: 1.4227 - accuracy: 0.5082 - val_loss: 2.8264 - val_accuracy: 0.1687 - 96s/epoch - 273ms/step\n",
      "Epoch 99/100\n",
      "352/352 - 96s - loss: 1.4303 - accuracy: 0.5039 - val_loss: 2.9116 - val_accuracy: 0.1703 - 96s/epoch - 273ms/step\n",
      "Epoch 100/100\n",
      "352/352 - 97s - loss: 1.4153 - accuracy: 0.5087 - val_loss: 2.7566 - val_accuracy: 0.1674 - 97s/epoch - 277ms/step\n",
      "[0.980400025844574, 0.9567999839782715, 0.9177333116531372, 0.8320000171661377, 0.6955999732017517, 0.4717999994754791, 0.26159998774528503, 0.16740000247955322, 0, 0]\n",
      "79/79 [==============================] - 7s 86ms/step - loss: 1.6544 - accuracy: 0.4215\n",
      "[0.9822999835014343, 0.9740999937057495, 0.9749000072479248, 0.9620000123977661, 0.9409999847412109, 0.8544999957084656, 0.609000027179718, 0.42149999737739563, 0, 0]\n",
      "Epoch 1/100\n",
      "352/352 - 91s - loss: 2.3197 - accuracy: 0.1050 - val_loss: 2.3031 - val_accuracy: 0.1071 - 91s/epoch - 259ms/step\n",
      "Epoch 2/100\n",
      "352/352 - 81s - loss: 2.2993 - accuracy: 0.1152 - val_loss: 2.2995 - val_accuracy: 0.1153 - 81s/epoch - 231ms/step\n",
      "Epoch 3/100\n",
      "352/352 - 82s - loss: 2.2923 - accuracy: 0.1240 - val_loss: 2.2983 - val_accuracy: 0.1153 - 82s/epoch - 232ms/step\n",
      "Epoch 4/100\n",
      "352/352 - 86s - loss: 2.2853 - accuracy: 0.1306 - val_loss: 2.3010 - val_accuracy: 0.1107 - 86s/epoch - 244ms/step\n",
      "Epoch 5/100\n",
      "352/352 - 86s - loss: 2.2770 - accuracy: 0.1432 - val_loss: 2.2998 - val_accuracy: 0.1159 - 86s/epoch - 245ms/step\n",
      "Epoch 6/100\n",
      "352/352 - 86s - loss: 2.2652 - accuracy: 0.1500 - val_loss: 2.3022 - val_accuracy: 0.1149 - 86s/epoch - 244ms/step\n",
      "Epoch 7/100\n",
      "352/352 - 85s - loss: 2.2522 - accuracy: 0.1604 - val_loss: 2.3062 - val_accuracy: 0.1161 - 85s/epoch - 243ms/step\n",
      "Epoch 8/100\n",
      "352/352 - 86s - loss: 2.2346 - accuracy: 0.1735 - val_loss: 2.3255 - val_accuracy: 0.1183 - 86s/epoch - 245ms/step\n",
      "Epoch 9/100\n",
      "352/352 - 86s - loss: 2.2182 - accuracy: 0.1826 - val_loss: 2.3219 - val_accuracy: 0.1167 - 86s/epoch - 245ms/step\n",
      "Epoch 10/100\n",
      "352/352 - 85s - loss: 2.2022 - accuracy: 0.1919 - val_loss: 2.3310 - val_accuracy: 0.1159 - 85s/epoch - 243ms/step\n",
      "Epoch 11/100\n",
      "352/352 - 85s - loss: 2.1868 - accuracy: 0.2014 - val_loss: 2.3520 - val_accuracy: 0.1151 - 85s/epoch - 243ms/step\n",
      "Epoch 12/100\n",
      "352/352 - 86s - loss: 2.1739 - accuracy: 0.2089 - val_loss: 2.3592 - val_accuracy: 0.1171 - 86s/epoch - 243ms/step\n",
      "Epoch 13/100\n",
      "352/352 - 86s - loss: 2.1582 - accuracy: 0.2145 - val_loss: 2.3800 - val_accuracy: 0.1179 - 86s/epoch - 243ms/step\n",
      "Epoch 14/100\n",
      "352/352 - 86s - loss: 2.1430 - accuracy: 0.2216 - val_loss: 2.3860 - val_accuracy: 0.1107 - 86s/epoch - 243ms/step\n",
      "Epoch 15/100\n",
      "352/352 - 85s - loss: 2.1300 - accuracy: 0.2314 - val_loss: 2.3913 - val_accuracy: 0.1117 - 85s/epoch - 243ms/step\n",
      "Epoch 16/100\n",
      "352/352 - 85s - loss: 2.1142 - accuracy: 0.2378 - val_loss: 2.4051 - val_accuracy: 0.1152 - 85s/epoch - 242ms/step\n",
      "Epoch 17/100\n",
      "352/352 - 82s - loss: 2.1057 - accuracy: 0.2425 - val_loss: 2.4044 - val_accuracy: 0.1156 - 82s/epoch - 232ms/step\n",
      "Epoch 18/100\n",
      "352/352 - 85s - loss: 2.0977 - accuracy: 0.2413 - val_loss: 2.3931 - val_accuracy: 0.1121 - 85s/epoch - 240ms/step\n",
      "Epoch 19/100\n",
      "352/352 - 85s - loss: 2.0886 - accuracy: 0.2491 - val_loss: 2.4366 - val_accuracy: 0.1122 - 85s/epoch - 241ms/step\n",
      "Epoch 20/100\n",
      "352/352 - 85s - loss: 2.0810 - accuracy: 0.2529 - val_loss: 2.4246 - val_accuracy: 0.1108 - 85s/epoch - 242ms/step\n",
      "Epoch 21/100\n",
      "352/352 - 86s - loss: 2.0752 - accuracy: 0.2546 - val_loss: 2.4296 - val_accuracy: 0.1126 - 86s/epoch - 244ms/step\n",
      "Epoch 22/100\n",
      "352/352 - 86s - loss: 2.0666 - accuracy: 0.2606 - val_loss: 2.4473 - val_accuracy: 0.1121 - 86s/epoch - 244ms/step\n",
      "Epoch 23/100\n",
      "352/352 - 87s - loss: 2.0579 - accuracy: 0.2616 - val_loss: 2.4561 - val_accuracy: 0.1094 - 87s/epoch - 247ms/step\n",
      "Epoch 24/100\n",
      "352/352 - 86s - loss: 2.0569 - accuracy: 0.2618 - val_loss: 2.4512 - val_accuracy: 0.1106 - 86s/epoch - 243ms/step\n",
      "Epoch 25/100\n",
      "352/352 - 86s - loss: 2.0526 - accuracy: 0.2661 - val_loss: 2.4529 - val_accuracy: 0.1097 - 86s/epoch - 245ms/step\n",
      "Epoch 26/100\n",
      "352/352 - 86s - loss: 2.0502 - accuracy: 0.2631 - val_loss: 2.4584 - val_accuracy: 0.1124 - 86s/epoch - 244ms/step\n",
      "Epoch 27/100\n",
      "352/352 - 87s - loss: 2.0541 - accuracy: 0.2637 - val_loss: 2.4753 - val_accuracy: 0.1085 - 87s/epoch - 247ms/step\n",
      "Epoch 28/100\n",
      "352/352 - 86s - loss: 2.0521 - accuracy: 0.2654 - val_loss: 2.4517 - val_accuracy: 0.1083 - 86s/epoch - 245ms/step\n",
      "Epoch 29/100\n",
      "352/352 - 86s - loss: 2.0502 - accuracy: 0.2663 - val_loss: 2.4524 - val_accuracy: 0.1064 - 86s/epoch - 244ms/step\n",
      "Epoch 30/100\n",
      "352/352 - 86s - loss: 2.0467 - accuracy: 0.2672 - val_loss: 2.5003 - val_accuracy: 0.1065 - 86s/epoch - 246ms/step\n",
      "Epoch 31/100\n",
      "352/352 - 86s - loss: 2.0415 - accuracy: 0.2722 - val_loss: 2.4551 - val_accuracy: 0.1101 - 86s/epoch - 244ms/step\n",
      "Epoch 32/100\n",
      "352/352 - 86s - loss: 2.0332 - accuracy: 0.2726 - val_loss: 2.4483 - val_accuracy: 0.1089 - 86s/epoch - 243ms/step\n",
      "Epoch 33/100\n",
      "352/352 - 86s - loss: 2.0445 - accuracy: 0.2688 - val_loss: 2.4594 - val_accuracy: 0.1138 - 86s/epoch - 244ms/step\n",
      "Epoch 34/100\n",
      "352/352 - 86s - loss: 2.0358 - accuracy: 0.2738 - val_loss: 2.4728 - val_accuracy: 0.1123 - 86s/epoch - 245ms/step\n",
      "Epoch 35/100\n",
      "352/352 - 85s - loss: 2.0344 - accuracy: 0.2704 - val_loss: 2.4589 - val_accuracy: 0.1073 - 85s/epoch - 242ms/step\n",
      "Epoch 36/100\n",
      "352/352 - 86s - loss: 2.0393 - accuracy: 0.2703 - val_loss: 2.4607 - val_accuracy: 0.1077 - 86s/epoch - 244ms/step\n",
      "Epoch 37/100\n",
      "352/352 - 86s - loss: 2.0458 - accuracy: 0.2710 - val_loss: 2.4669 - val_accuracy: 0.1103 - 86s/epoch - 243ms/step\n",
      "Epoch 38/100\n",
      "352/352 - 87s - loss: 2.0524 - accuracy: 0.2666 - val_loss: 2.4504 - val_accuracy: 0.1098 - 87s/epoch - 246ms/step\n",
      "Epoch 39/100\n",
      "352/352 - 87s - loss: 2.0633 - accuracy: 0.2612 - val_loss: 2.4573 - val_accuracy: 0.1072 - 87s/epoch - 247ms/step\n",
      "Epoch 40/100\n",
      "352/352 - 86s - loss: 2.0694 - accuracy: 0.2612 - val_loss: 2.4735 - val_accuracy: 0.1115 - 86s/epoch - 244ms/step\n",
      "Epoch 41/100\n",
      "352/352 - 86s - loss: 2.0626 - accuracy: 0.2621 - val_loss: 2.4712 - val_accuracy: 0.1102 - 86s/epoch - 244ms/step\n",
      "Epoch 42/100\n",
      "352/352 - 89s - loss: 2.0583 - accuracy: 0.2661 - val_loss: 2.4527 - val_accuracy: 0.1107 - 89s/epoch - 252ms/step\n",
      "Epoch 43/100\n",
      "352/352 - 88s - loss: 2.0528 - accuracy: 0.2674 - val_loss: 2.4618 - val_accuracy: 0.1134 - 88s/epoch - 251ms/step\n",
      "Epoch 44/100\n",
      "352/352 - 86s - loss: 2.0589 - accuracy: 0.2631 - val_loss: 2.4622 - val_accuracy: 0.1117 - 86s/epoch - 244ms/step\n",
      "Epoch 45/100\n",
      "352/352 - 85s - loss: 2.0731 - accuracy: 0.2583 - val_loss: 2.4640 - val_accuracy: 0.1066 - 85s/epoch - 242ms/step\n",
      "Epoch 46/100\n",
      "352/352 - 85s - loss: 2.0705 - accuracy: 0.2563 - val_loss: 2.4631 - val_accuracy: 0.1076 - 85s/epoch - 243ms/step\n",
      "Epoch 47/100\n",
      "352/352 - 86s - loss: 2.0700 - accuracy: 0.2570 - val_loss: 2.4590 - val_accuracy: 0.1095 - 86s/epoch - 244ms/step\n",
      "Epoch 48/100\n",
      "352/352 - 86s - loss: 2.0836 - accuracy: 0.2556 - val_loss: 2.4300 - val_accuracy: 0.1098 - 86s/epoch - 245ms/step\n",
      "Epoch 49/100\n",
      "352/352 - 88s - loss: 2.0972 - accuracy: 0.2458 - val_loss: 2.4529 - val_accuracy: 0.1123 - 88s/epoch - 250ms/step\n",
      "Epoch 50/100\n",
      "352/352 - 87s - loss: 2.0950 - accuracy: 0.2486 - val_loss: 2.4503 - val_accuracy: 0.1124 - 87s/epoch - 247ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "352/352 - 85s - loss: 2.1033 - accuracy: 0.2441 - val_loss: 2.4198 - val_accuracy: 0.1083 - 85s/epoch - 242ms/step\n",
      "Epoch 52/100\n",
      "352/352 - 85s - loss: 2.1145 - accuracy: 0.2395 - val_loss: 2.4264 - val_accuracy: 0.1070 - 85s/epoch - 240ms/step\n",
      "Epoch 53/100\n",
      "352/352 - 85s - loss: 2.1080 - accuracy: 0.2422 - val_loss: 2.4348 - val_accuracy: 0.1093 - 85s/epoch - 241ms/step\n",
      "Epoch 54/100\n",
      "352/352 - 86s - loss: 2.0997 - accuracy: 0.2474 - val_loss: 2.4395 - val_accuracy: 0.1092 - 86s/epoch - 244ms/step\n",
      "Epoch 55/100\n",
      "352/352 - 90s - loss: 2.1542 - accuracy: 0.2174 - val_loss: 2.3975 - val_accuracy: 0.1063 - 90s/epoch - 256ms/step\n",
      "Epoch 56/100\n",
      "352/352 - 94s - loss: 2.1274 - accuracy: 0.2301 - val_loss: 2.4035 - val_accuracy: 0.1072 - 94s/epoch - 266ms/step\n",
      "Epoch 57/100\n",
      "352/352 - 88s - loss: 2.1251 - accuracy: 0.2321 - val_loss: 2.4084 - val_accuracy: 0.1097 - 88s/epoch - 249ms/step\n",
      "Epoch 58/100\n",
      "352/352 - 114s - loss: 2.1406 - accuracy: 0.2252 - val_loss: 2.4116 - val_accuracy: 0.1098 - 114s/epoch - 324ms/step\n",
      "Epoch 59/100\n",
      "352/352 - 182s - loss: 2.1227 - accuracy: 0.2338 - val_loss: 2.4463 - val_accuracy: 0.1081 - 182s/epoch - 517ms/step\n",
      "Epoch 60/100\n",
      "352/352 - 173s - loss: 2.1223 - accuracy: 0.2363 - val_loss: 2.4206 - val_accuracy: 0.1102 - 173s/epoch - 492ms/step\n",
      "Epoch 61/100\n",
      "352/352 - 172s - loss: 2.1155 - accuracy: 0.2374 - val_loss: 2.4121 - val_accuracy: 0.1128 - 172s/epoch - 489ms/step\n",
      "Epoch 62/100\n",
      "352/352 - 182s - loss: 2.1334 - accuracy: 0.2308 - val_loss: 2.4078 - val_accuracy: 0.1084 - 182s/epoch - 516ms/step\n",
      "Epoch 63/100\n",
      "352/352 - 181s - loss: 2.1527 - accuracy: 0.2190 - val_loss: 2.4073 - val_accuracy: 0.1109 - 181s/epoch - 515ms/step\n",
      "Epoch 64/100\n",
      "352/352 - 179s - loss: 2.1540 - accuracy: 0.2219 - val_loss: 2.4102 - val_accuracy: 0.1081 - 179s/epoch - 508ms/step\n",
      "Epoch 65/100\n",
      "352/352 - 182s - loss: 2.1358 - accuracy: 0.2295 - val_loss: 2.4100 - val_accuracy: 0.1093 - 182s/epoch - 518ms/step\n",
      "Epoch 66/100\n",
      "352/352 - 180s - loss: 2.1512 - accuracy: 0.2227 - val_loss: 2.4071 - val_accuracy: 0.1060 - 180s/epoch - 511ms/step\n",
      "Epoch 67/100\n",
      "352/352 - 177s - loss: 2.1584 - accuracy: 0.2186 - val_loss: 2.3916 - val_accuracy: 0.1049 - 177s/epoch - 502ms/step\n",
      "Epoch 68/100\n",
      "352/352 - 182s - loss: 2.1473 - accuracy: 0.2245 - val_loss: 2.4032 - val_accuracy: 0.1109 - 182s/epoch - 516ms/step\n",
      "Epoch 69/100\n",
      "352/352 - 181s - loss: 2.1550 - accuracy: 0.2192 - val_loss: 2.3920 - val_accuracy: 0.1077 - 181s/epoch - 513ms/step\n",
      "Epoch 70/100\n",
      "352/352 - 179s - loss: 2.1430 - accuracy: 0.2235 - val_loss: 2.4070 - val_accuracy: 0.1083 - 179s/epoch - 508ms/step\n",
      "Epoch 71/100\n",
      "352/352 - 181s - loss: 2.1397 - accuracy: 0.2273 - val_loss: 2.4192 - val_accuracy: 0.1080 - 181s/epoch - 515ms/step\n",
      "Epoch 72/100\n",
      "352/352 - 182s - loss: 2.1422 - accuracy: 0.2259 - val_loss: 2.3859 - val_accuracy: 0.1087 - 182s/epoch - 516ms/step\n",
      "Epoch 73/100\n",
      "352/352 - 183s - loss: 2.1518 - accuracy: 0.2206 - val_loss: 2.4066 - val_accuracy: 0.1067 - 183s/epoch - 519ms/step\n",
      "Epoch 74/100\n",
      "352/352 - 179s - loss: 2.1442 - accuracy: 0.2261 - val_loss: 2.3950 - val_accuracy: 0.1091 - 179s/epoch - 507ms/step\n",
      "Epoch 75/100\n",
      "352/352 - 182s - loss: 2.1480 - accuracy: 0.2216 - val_loss: 2.3938 - val_accuracy: 0.1071 - 182s/epoch - 516ms/step\n",
      "Epoch 76/100\n",
      "352/352 - 179s - loss: 2.1986 - accuracy: 0.1951 - val_loss: 2.3720 - val_accuracy: 0.1059 - 179s/epoch - 508ms/step\n",
      "Epoch 77/100\n",
      "352/352 - 180s - loss: 2.1774 - accuracy: 0.2067 - val_loss: 2.3774 - val_accuracy: 0.1102 - 180s/epoch - 512ms/step\n",
      "Epoch 78/100\n",
      "352/352 - 181s - loss: 2.1575 - accuracy: 0.2173 - val_loss: 2.3911 - val_accuracy: 0.1087 - 181s/epoch - 514ms/step\n",
      "Epoch 79/100\n",
      "352/352 - 177s - loss: 2.1780 - accuracy: 0.2050 - val_loss: 2.3832 - val_accuracy: 0.1056 - 177s/epoch - 504ms/step\n",
      "Epoch 80/100\n",
      "352/352 - 181s - loss: 2.1776 - accuracy: 0.2073 - val_loss: 2.3957 - val_accuracy: 0.1061 - 181s/epoch - 513ms/step\n",
      "Epoch 81/100\n",
      "352/352 - 182s - loss: 2.2034 - accuracy: 0.1947 - val_loss: 2.3748 - val_accuracy: 0.1027 - 182s/epoch - 517ms/step\n",
      "Epoch 82/100\n",
      "352/352 - 178s - loss: 2.1949 - accuracy: 0.1965 - val_loss: 2.3740 - val_accuracy: 0.1076 - 178s/epoch - 505ms/step\n",
      "Epoch 83/100\n",
      "352/352 - 180s - loss: 2.2024 - accuracy: 0.1911 - val_loss: 2.3768 - val_accuracy: 0.1063 - 180s/epoch - 512ms/step\n",
      "Epoch 84/100\n",
      "352/352 - 180s - loss: 2.1977 - accuracy: 0.1934 - val_loss: 2.3718 - val_accuracy: 0.1099 - 180s/epoch - 512ms/step\n",
      "Epoch 85/100\n",
      "352/352 - 175s - loss: 2.1852 - accuracy: 0.2053 - val_loss: 2.3726 - val_accuracy: 0.1063 - 175s/epoch - 498ms/step\n",
      "Epoch 86/100\n",
      "352/352 - 180s - loss: 2.1936 - accuracy: 0.2008 - val_loss: 2.3727 - val_accuracy: 0.1085 - 180s/epoch - 511ms/step\n",
      "Epoch 87/100\n",
      "352/352 - 178s - loss: 2.1785 - accuracy: 0.2072 - val_loss: 2.3815 - val_accuracy: 0.1071 - 178s/epoch - 506ms/step\n",
      "Epoch 88/100\n",
      "352/352 - 177s - loss: 2.1858 - accuracy: 0.2052 - val_loss: 2.3853 - val_accuracy: 0.1059 - 177s/epoch - 502ms/step\n",
      "Epoch 89/100\n",
      "352/352 - 180s - loss: 2.1933 - accuracy: 0.1988 - val_loss: 2.3647 - val_accuracy: 0.1054 - 180s/epoch - 513ms/step\n",
      "Epoch 90/100\n",
      "352/352 - 181s - loss: 2.1993 - accuracy: 0.1962 - val_loss: 2.3730 - val_accuracy: 0.1033 - 181s/epoch - 516ms/step\n",
      "Epoch 91/100\n",
      "352/352 - 179s - loss: 2.2218 - accuracy: 0.1828 - val_loss: 2.3605 - val_accuracy: 0.1081 - 179s/epoch - 508ms/step\n",
      "Epoch 92/100\n",
      "352/352 - 180s - loss: 2.2049 - accuracy: 0.1919 - val_loss: 2.3676 - val_accuracy: 0.1132 - 180s/epoch - 512ms/step\n",
      "Epoch 93/100\n",
      "352/352 - 182s - loss: 2.2036 - accuracy: 0.1939 - val_loss: 2.3605 - val_accuracy: 0.1173 - 182s/epoch - 516ms/step\n",
      "Epoch 94/100\n",
      "352/352 - 178s - loss: 2.1969 - accuracy: 0.1971 - val_loss: 2.3646 - val_accuracy: 0.1095 - 178s/epoch - 505ms/step\n",
      "Epoch 95/100\n",
      "352/352 - 182s - loss: 2.1942 - accuracy: 0.1993 - val_loss: 2.3705 - val_accuracy: 0.1128 - 182s/epoch - 516ms/step\n",
      "Epoch 96/100\n",
      "352/352 - 182s - loss: 2.1911 - accuracy: 0.2000 - val_loss: 2.3622 - val_accuracy: 0.1089 - 182s/epoch - 516ms/step\n",
      "Epoch 97/100\n",
      "352/352 - 178s - loss: 2.1911 - accuracy: 0.1996 - val_loss: 2.3671 - val_accuracy: 0.1122 - 178s/epoch - 506ms/step\n",
      "Epoch 98/100\n",
      "352/352 - 180s - loss: 2.2237 - accuracy: 0.1829 - val_loss: 2.3554 - val_accuracy: 0.1112 - 180s/epoch - 512ms/step\n",
      "Epoch 99/100\n",
      "352/352 - 181s - loss: 2.2421 - accuracy: 0.1682 - val_loss: 2.3499 - val_accuracy: 0.1080 - 181s/epoch - 515ms/step\n",
      "Epoch 100/100\n",
      "352/352 - 176s - loss: 2.2174 - accuracy: 0.1819 - val_loss: 2.3534 - val_accuracy: 0.1134 - 176s/epoch - 499ms/step\n",
      "[0.980400025844574, 0.9567999839782715, 0.9177333116531372, 0.8320000171661377, 0.6955999732017517, 0.4717999994754791, 0.26159998774528503, 0.16740000247955322, 0.11339999735355377, 0]\n",
      "79/79 [==============================] - 14s 164ms/step - loss: 2.1831 - accuracy: 0.2127\n",
      "[0.9822999835014343, 0.9740999937057495, 0.9749000072479248, 0.9620000123977661, 0.9409999847412109, 0.8544999957084656, 0.609000027179718, 0.42149999737739563, 0.2126999944448471, 0]\n",
      "Epoch 1/100\n",
      "352/352 - 413s - loss: 2.3117 - accuracy: 0.1080 - val_loss: 2.3028 - val_accuracy: 0.1076 - 413s/epoch - 1s/step\n",
      "Epoch 2/100\n",
      "352/352 - 168s - loss: 2.3003 - accuracy: 0.1132 - val_loss: 2.3021 - val_accuracy: 0.1085 - 168s/epoch - 479ms/step\n",
      "Epoch 3/100\n",
      "352/352 - 169s - loss: 2.2969 - accuracy: 0.1187 - val_loss: 2.3041 - val_accuracy: 0.1076 - 169s/epoch - 481ms/step\n",
      "Epoch 4/100\n",
      "352/352 - 169s - loss: 2.2926 - accuracy: 0.1261 - val_loss: 2.3049 - val_accuracy: 0.1022 - 169s/epoch - 481ms/step\n",
      "Epoch 5/100\n",
      "352/352 - 166s - loss: 2.2857 - accuracy: 0.1328 - val_loss: 2.3101 - val_accuracy: 0.1020 - 166s/epoch - 471ms/step\n",
      "Epoch 6/100\n",
      "352/352 - 171s - loss: 2.2778 - accuracy: 0.1420 - val_loss: 2.3106 - val_accuracy: 0.1044 - 171s/epoch - 486ms/step\n",
      "Epoch 7/100\n",
      "352/352 - 172s - loss: 2.2693 - accuracy: 0.1489 - val_loss: 2.3169 - val_accuracy: 0.1010 - 172s/epoch - 488ms/step\n",
      "Epoch 8/100\n",
      "352/352 - 168s - loss: 2.2589 - accuracy: 0.1590 - val_loss: 2.3215 - val_accuracy: 0.1060 - 168s/epoch - 476ms/step\n",
      "Epoch 9/100\n",
      "352/352 - 170s - loss: 2.2493 - accuracy: 0.1630 - val_loss: 2.3260 - val_accuracy: 0.1059 - 170s/epoch - 482ms/step\n",
      "Epoch 10/100\n",
      "352/352 - 171s - loss: 2.2397 - accuracy: 0.1709 - val_loss: 2.3291 - val_accuracy: 0.1047 - 171s/epoch - 485ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "352/352 - 168s - loss: 2.2295 - accuracy: 0.1781 - val_loss: 2.3360 - val_accuracy: 0.1034 - 168s/epoch - 478ms/step\n",
      "Epoch 12/100\n",
      "352/352 - 162s - loss: 2.2172 - accuracy: 0.1857 - val_loss: 2.3503 - val_accuracy: 0.1024 - 162s/epoch - 461ms/step\n",
      "Epoch 13/100\n",
      "352/352 - 159s - loss: 2.2098 - accuracy: 0.1900 - val_loss: 2.3475 - val_accuracy: 0.1027 - 159s/epoch - 452ms/step\n",
      "Epoch 14/100\n",
      "352/352 - 159s - loss: 2.1993 - accuracy: 0.1954 - val_loss: 2.3580 - val_accuracy: 0.1040 - 159s/epoch - 451ms/step\n",
      "Epoch 15/100\n",
      "352/352 - 157s - loss: 2.1970 - accuracy: 0.1971 - val_loss: 2.3522 - val_accuracy: 0.1017 - 157s/epoch - 446ms/step\n",
      "Epoch 16/100\n",
      "352/352 - 162s - loss: 2.1902 - accuracy: 0.2010 - val_loss: 2.3600 - val_accuracy: 0.1001 - 162s/epoch - 460ms/step\n",
      "Epoch 17/100\n",
      "352/352 - 159s - loss: 2.1840 - accuracy: 0.2040 - val_loss: 2.3711 - val_accuracy: 0.1017 - 159s/epoch - 452ms/step\n",
      "Epoch 18/100\n",
      "352/352 - 166s - loss: 2.1844 - accuracy: 0.2036 - val_loss: 2.3666 - val_accuracy: 0.1064 - 166s/epoch - 471ms/step\n",
      "Epoch 19/100\n",
      "352/352 - 167s - loss: 2.1791 - accuracy: 0.2061 - val_loss: 2.3726 - val_accuracy: 0.1012 - 167s/epoch - 474ms/step\n",
      "Epoch 20/100\n",
      "352/352 - 172s - loss: 2.1767 - accuracy: 0.2079 - val_loss: 2.3778 - val_accuracy: 0.1011 - 172s/epoch - 488ms/step\n",
      "Epoch 21/100\n",
      "352/352 - 167s - loss: 2.1762 - accuracy: 0.2076 - val_loss: 2.3815 - val_accuracy: 0.0991 - 167s/epoch - 475ms/step\n",
      "Epoch 22/100\n",
      "352/352 - 174s - loss: 2.1695 - accuracy: 0.2136 - val_loss: 2.3823 - val_accuracy: 0.1032 - 174s/epoch - 493ms/step\n",
      "Epoch 23/100\n",
      "352/352 - 172s - loss: 2.1747 - accuracy: 0.2106 - val_loss: 2.3796 - val_accuracy: 0.0979 - 172s/epoch - 489ms/step\n",
      "Epoch 24/100\n",
      "352/352 - 169s - loss: 2.1727 - accuracy: 0.2096 - val_loss: 2.3902 - val_accuracy: 0.1011 - 169s/epoch - 481ms/step\n",
      "Epoch 25/100\n",
      "352/352 - 169s - loss: 2.1874 - accuracy: 0.2035 - val_loss: 2.3702 - val_accuracy: 0.1019 - 169s/epoch - 480ms/step\n",
      "Epoch 26/100\n",
      "352/352 - 171s - loss: 2.1744 - accuracy: 0.2107 - val_loss: 2.3753 - val_accuracy: 0.1019 - 171s/epoch - 485ms/step\n",
      "Epoch 27/100\n",
      "352/352 - 154s - loss: 2.1707 - accuracy: 0.2121 - val_loss: 2.3892 - val_accuracy: 0.1052 - 154s/epoch - 438ms/step\n",
      "Epoch 28/100\n",
      "352/352 - 149s - loss: 2.1741 - accuracy: 0.2108 - val_loss: 2.3805 - val_accuracy: 0.0997 - 149s/epoch - 422ms/step\n",
      "Epoch 29/100\n",
      "352/352 - 153s - loss: 2.1877 - accuracy: 0.2037 - val_loss: 2.3701 - val_accuracy: 0.1033 - 153s/epoch - 433ms/step\n",
      "Epoch 30/100\n",
      "352/352 - 152s - loss: 2.1850 - accuracy: 0.2027 - val_loss: 2.3815 - val_accuracy: 0.1021 - 152s/epoch - 432ms/step\n",
      "Epoch 31/100\n",
      "352/352 - 147s - loss: 2.1874 - accuracy: 0.1995 - val_loss: 2.3763 - val_accuracy: 0.0997 - 147s/epoch - 419ms/step\n",
      "Epoch 32/100\n",
      "352/352 - 151s - loss: 2.1811 - accuracy: 0.2054 - val_loss: 2.3838 - val_accuracy: 0.1003 - 151s/epoch - 428ms/step\n",
      "Epoch 33/100\n",
      "352/352 - 151s - loss: 2.1871 - accuracy: 0.2007 - val_loss: 2.3675 - val_accuracy: 0.1024 - 151s/epoch - 429ms/step\n",
      "Epoch 34/100\n",
      "352/352 - 148s - loss: 2.1837 - accuracy: 0.2034 - val_loss: 2.3863 - val_accuracy: 0.1039 - 148s/epoch - 420ms/step\n",
      "Epoch 35/100\n",
      "352/352 - 149s - loss: 2.1949 - accuracy: 0.1991 - val_loss: 2.3770 - val_accuracy: 0.1019 - 149s/epoch - 424ms/step\n",
      "Epoch 36/100\n",
      "352/352 - 150s - loss: 2.1901 - accuracy: 0.2005 - val_loss: 2.3784 - val_accuracy: 0.1050 - 150s/epoch - 426ms/step\n",
      "Epoch 37/100\n",
      "352/352 - 148s - loss: 2.1895 - accuracy: 0.2046 - val_loss: 2.3779 - val_accuracy: 0.1031 - 148s/epoch - 421ms/step\n",
      "Epoch 38/100\n",
      "352/352 - 149s - loss: 2.1929 - accuracy: 0.1995 - val_loss: 2.3682 - val_accuracy: 0.1051 - 149s/epoch - 423ms/step\n",
      "Epoch 39/100\n",
      "352/352 - 151s - loss: 2.2046 - accuracy: 0.1917 - val_loss: 2.3577 - val_accuracy: 0.1069 - 151s/epoch - 428ms/step\n",
      "Epoch 40/100\n",
      "352/352 - 147s - loss: 2.1937 - accuracy: 0.1996 - val_loss: 2.3658 - val_accuracy: 0.1023 - 147s/epoch - 419ms/step\n",
      "Epoch 41/100\n",
      "352/352 - 148s - loss: 2.2000 - accuracy: 0.1947 - val_loss: 2.3719 - val_accuracy: 0.1024 - 148s/epoch - 422ms/step\n",
      "Epoch 42/100\n",
      "352/352 - 150s - loss: 2.2152 - accuracy: 0.1866 - val_loss: 2.3638 - val_accuracy: 0.1023 - 150s/epoch - 426ms/step\n",
      "Epoch 43/100\n",
      "352/352 - 151s - loss: 2.2041 - accuracy: 0.1932 - val_loss: 2.3752 - val_accuracy: 0.1011 - 151s/epoch - 428ms/step\n",
      "Epoch 44/100\n",
      "352/352 - 147s - loss: 2.2101 - accuracy: 0.1888 - val_loss: 2.3607 - val_accuracy: 0.1053 - 147s/epoch - 418ms/step\n",
      "Epoch 45/100\n",
      "352/352 - 151s - loss: 2.2023 - accuracy: 0.1944 - val_loss: 2.3821 - val_accuracy: 0.1018 - 151s/epoch - 429ms/step\n",
      "Epoch 46/100\n",
      "352/352 - 151s - loss: 2.2231 - accuracy: 0.1808 - val_loss: 2.3587 - val_accuracy: 0.1046 - 151s/epoch - 430ms/step\n",
      "Epoch 47/100\n",
      "352/352 - 147s - loss: 2.2136 - accuracy: 0.1859 - val_loss: 2.3640 - val_accuracy: 0.1067 - 147s/epoch - 417ms/step\n",
      "Epoch 48/100\n",
      "352/352 - 151s - loss: 2.2030 - accuracy: 0.1946 - val_loss: 2.3666 - val_accuracy: 0.1056 - 151s/epoch - 428ms/step\n",
      "Epoch 49/100\n",
      "352/352 - 150s - loss: 2.2068 - accuracy: 0.1897 - val_loss: 2.3626 - val_accuracy: 0.1075 - 150s/epoch - 425ms/step\n",
      "Epoch 50/100\n",
      "352/352 - 149s - loss: 2.2261 - accuracy: 0.1774 - val_loss: 2.3572 - val_accuracy: 0.1027 - 149s/epoch - 422ms/step\n",
      "Epoch 51/100\n",
      "352/352 - 151s - loss: 2.2191 - accuracy: 0.1849 - val_loss: 2.3635 - val_accuracy: 0.1083 - 151s/epoch - 428ms/step\n",
      "Epoch 52/100\n",
      "352/352 - 152s - loss: 2.2158 - accuracy: 0.1860 - val_loss: 2.3642 - val_accuracy: 0.1011 - 152s/epoch - 433ms/step\n",
      "Epoch 53/100\n",
      "352/352 - 150s - loss: 2.2151 - accuracy: 0.1881 - val_loss: 2.3644 - val_accuracy: 0.1027 - 150s/epoch - 426ms/step\n",
      "Epoch 54/100\n",
      "352/352 - 154s - loss: 2.2117 - accuracy: 0.1896 - val_loss: 2.3705 - val_accuracy: 0.1014 - 154s/epoch - 437ms/step\n",
      "Epoch 55/100\n",
      "352/352 - 152s - loss: 2.2236 - accuracy: 0.1801 - val_loss: 2.3550 - val_accuracy: 0.0997 - 152s/epoch - 432ms/step\n",
      "Epoch 56/100\n",
      "352/352 - 149s - loss: 2.2321 - accuracy: 0.1771 - val_loss: 2.3557 - val_accuracy: 0.1033 - 149s/epoch - 424ms/step\n",
      "Epoch 57/100\n",
      "352/352 - 151s - loss: 2.2470 - accuracy: 0.1653 - val_loss: 2.3483 - val_accuracy: 0.1003 - 151s/epoch - 429ms/step\n",
      "Epoch 58/100\n",
      "352/352 - 152s - loss: 2.2304 - accuracy: 0.1746 - val_loss: 2.3538 - val_accuracy: 0.1062 - 152s/epoch - 431ms/step\n",
      "Epoch 59/100\n",
      "352/352 - 150s - loss: 2.2339 - accuracy: 0.1764 - val_loss: 2.3550 - val_accuracy: 0.0993 - 150s/epoch - 426ms/step\n",
      "Epoch 60/100\n",
      "352/352 - 149s - loss: 2.2363 - accuracy: 0.1718 - val_loss: 2.3519 - val_accuracy: 0.1045 - 149s/epoch - 423ms/step\n",
      "Epoch 61/100\n",
      "352/352 - 152s - loss: 2.2535 - accuracy: 0.1637 - val_loss: 2.3363 - val_accuracy: 0.1045 - 152s/epoch - 433ms/step\n",
      "Epoch 62/100\n",
      "352/352 - 151s - loss: 2.2424 - accuracy: 0.1699 - val_loss: 2.3505 - val_accuracy: 0.1033 - 151s/epoch - 429ms/step\n",
      "Epoch 63/100\n",
      "352/352 - 142s - loss: 2.2427 - accuracy: 0.1670 - val_loss: 2.3403 - val_accuracy: 0.1033 - 142s/epoch - 404ms/step\n",
      "Epoch 64/100\n",
      "352/352 - 145s - loss: 2.2483 - accuracy: 0.1673 - val_loss: 2.3470 - val_accuracy: 0.1002 - 145s/epoch - 411ms/step\n",
      "Epoch 65/100\n",
      "352/352 - 147s - loss: 2.2676 - accuracy: 0.1520 - val_loss: 2.3339 - val_accuracy: 0.1019 - 147s/epoch - 418ms/step\n",
      "Epoch 66/100\n",
      "352/352 - 145s - loss: 2.2617 - accuracy: 0.1562 - val_loss: 2.3379 - val_accuracy: 0.1009 - 145s/epoch - 412ms/step\n",
      "Epoch 67/100\n",
      "352/352 - 152s - loss: 2.2573 - accuracy: 0.1594 - val_loss: 2.3364 - val_accuracy: 0.0989 - 152s/epoch - 433ms/step\n",
      "Epoch 68/100\n",
      "352/352 - 152s - loss: 2.2461 - accuracy: 0.1680 - val_loss: 2.3383 - val_accuracy: 0.1045 - 152s/epoch - 431ms/step\n",
      "Epoch 69/100\n",
      "352/352 - 149s - loss: 2.2385 - accuracy: 0.1704 - val_loss: 2.3421 - val_accuracy: 0.1017 - 149s/epoch - 424ms/step\n",
      "Epoch 70/100\n",
      "352/352 - 154s - loss: 2.2549 - accuracy: 0.1609 - val_loss: 2.3450 - val_accuracy: 0.1000 - 154s/epoch - 438ms/step\n",
      "Epoch 71/100\n",
      "352/352 - 155s - loss: 2.2687 - accuracy: 0.1484 - val_loss: 2.3322 - val_accuracy: 0.1051 - 155s/epoch - 439ms/step\n",
      "Epoch 72/100\n",
      "352/352 - 151s - loss: 2.2530 - accuracy: 0.1605 - val_loss: 2.3314 - val_accuracy: 0.1045 - 151s/epoch - 430ms/step\n",
      "Epoch 73/100\n",
      "352/352 - 152s - loss: 2.2459 - accuracy: 0.1649 - val_loss: 2.3395 - val_accuracy: 0.1036 - 152s/epoch - 432ms/step\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 - 154s - loss: 2.2474 - accuracy: 0.1653 - val_loss: 2.3333 - val_accuracy: 0.1027 - 154s/epoch - 436ms/step\n",
      "Epoch 75/100\n",
      "352/352 - 150s - loss: 2.2687 - accuracy: 0.1567 - val_loss: 2.3588 - val_accuracy: 0.1013 - 150s/epoch - 426ms/step\n",
      "Epoch 76/100\n",
      "352/352 - 155s - loss: 2.2926 - accuracy: 0.1319 - val_loss: 2.3253 - val_accuracy: 0.1023 - 155s/epoch - 441ms/step\n",
      "Epoch 77/100\n",
      "352/352 - 156s - loss: 2.2750 - accuracy: 0.1432 - val_loss: 2.3320 - val_accuracy: 0.0994 - 156s/epoch - 444ms/step\n",
      "Epoch 78/100\n",
      "352/352 - 152s - loss: 2.2672 - accuracy: 0.1507 - val_loss: 2.3299 - val_accuracy: 0.1010 - 152s/epoch - 430ms/step\n",
      "Epoch 79/100\n",
      "352/352 - 152s - loss: 2.2601 - accuracy: 0.1570 - val_loss: 2.3354 - val_accuracy: 0.0979 - 152s/epoch - 432ms/step\n",
      "Epoch 80/100\n",
      "352/352 - 152s - loss: 2.2973 - accuracy: 0.1350 - val_loss: 2.3246 - val_accuracy: 0.0995 - 152s/epoch - 432ms/step\n",
      "Epoch 81/100\n",
      "352/352 - 151s - loss: 2.2952 - accuracy: 0.1279 - val_loss: 2.3187 - val_accuracy: 0.1025 - 151s/epoch - 430ms/step\n",
      "Epoch 82/100\n",
      "352/352 - 150s - loss: 2.2806 - accuracy: 0.1398 - val_loss: 2.3188 - val_accuracy: 0.0995 - 150s/epoch - 427ms/step\n",
      "Epoch 83/100\n",
      "352/352 - 153s - loss: 2.2735 - accuracy: 0.1458 - val_loss: 2.3236 - val_accuracy: 0.1003 - 153s/epoch - 435ms/step\n",
      "Epoch 84/100\n",
      "352/352 - 153s - loss: 2.2733 - accuracy: 0.1429 - val_loss: 2.3220 - val_accuracy: 0.1025 - 153s/epoch - 434ms/step\n",
      "Epoch 85/100\n",
      "352/352 - 150s - loss: 2.2775 - accuracy: 0.1395 - val_loss: 2.3227 - val_accuracy: 0.1015 - 150s/epoch - 427ms/step\n",
      "Epoch 86/100\n",
      "352/352 - 152s - loss: 2.2831 - accuracy: 0.1374 - val_loss: 2.3274 - val_accuracy: 0.1034 - 152s/epoch - 433ms/step\n",
      "Epoch 87/100\n",
      "352/352 - 153s - loss: 2.3669 - accuracy: 0.1131 - val_loss: 2.3293 - val_accuracy: 0.1041 - 153s/epoch - 436ms/step\n",
      "Epoch 88/100\n",
      "352/352 - 150s - loss: 2.3100 - accuracy: 0.1085 - val_loss: 2.3163 - val_accuracy: 0.1041 - 150s/epoch - 426ms/step\n",
      "Epoch 89/100\n",
      "352/352 - 153s - loss: 2.3040 - accuracy: 0.1120 - val_loss: 2.3081 - val_accuracy: 0.1048 - 153s/epoch - 435ms/step\n",
      "Epoch 90/100\n",
      "352/352 - 153s - loss: 2.3015 - accuracy: 0.1149 - val_loss: 2.3109 - val_accuracy: 0.1067 - 153s/epoch - 436ms/step\n",
      "Epoch 91/100\n",
      "352/352 - 150s - loss: 2.3031 - accuracy: 0.1120 - val_loss: 2.3111 - val_accuracy: 0.1055 - 150s/epoch - 425ms/step\n",
      "Epoch 92/100\n",
      "352/352 - 152s - loss: 2.3012 - accuracy: 0.1161 - val_loss: 2.3110 - val_accuracy: 0.1024 - 152s/epoch - 431ms/step\n",
      "Epoch 93/100\n",
      "352/352 - 151s - loss: 2.3003 - accuracy: 0.1179 - val_loss: 2.3085 - val_accuracy: 0.1078 - 151s/epoch - 430ms/step\n",
      "Epoch 94/100\n",
      "352/352 - 147s - loss: 2.3035 - accuracy: 0.1152 - val_loss: 2.3073 - val_accuracy: 0.1039 - 147s/epoch - 418ms/step\n",
      "Epoch 95/100\n",
      "352/352 - 151s - loss: 2.2995 - accuracy: 0.1163 - val_loss: 2.3066 - val_accuracy: 0.1068 - 151s/epoch - 429ms/step\n",
      "Epoch 96/100\n",
      "352/352 - 152s - loss: 2.3623 - accuracy: 0.1132 - val_loss: 2.3132 - val_accuracy: 0.1024 - 152s/epoch - 432ms/step\n",
      "Epoch 97/100\n",
      "352/352 - 149s - loss: 2.3081 - accuracy: 0.1085 - val_loss: 2.3057 - val_accuracy: 0.1045 - 149s/epoch - 424ms/step\n",
      "Epoch 98/100\n",
      "352/352 - 153s - loss: 2.3022 - accuracy: 0.1125 - val_loss: 2.3053 - val_accuracy: 0.1039 - 153s/epoch - 434ms/step\n",
      "Epoch 99/100\n",
      "352/352 - 153s - loss: 2.3007 - accuracy: 0.1136 - val_loss: 2.3072 - val_accuracy: 0.1051 - 153s/epoch - 433ms/step\n",
      "Epoch 100/100\n",
      "352/352 - 150s - loss: 2.3022 - accuracy: 0.1138 - val_loss: 2.3461 - val_accuracy: 0.0986 - 150s/epoch - 426ms/step\n",
      "[0.980400025844574, 0.9567999839782715, 0.9177333116531372, 0.8320000171661377, 0.6955999732017517, 0.4717999994754791, 0.26159998774528503, 0.16740000247955322, 0.11339999735355377, 0.09860000014305115]\n",
      "79/79 [==============================] - 12s 142ms/step - loss: 2.3216 - accuracy: 0.1467\n",
      "[0.9822999835014343, 0.9740999937057495, 0.9749000072479248, 0.9620000123977661, 0.9409999847412109, 0.8544999957084656, 0.609000027179718, 0.42149999737739563, 0.2126999944448471, 0.14669999480247498]\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 28, 28)]          0         \n",
      "                                                                 \n",
      " simple_rnn_18 (SimpleRNN)   (None, 28, 512)           276992    \n",
      "                                                                 \n",
      " simple_rnn_19 (SimpleRNN)   (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 806922 (3.08 MB)\n",
      "Trainable params: 806922 (3.08 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, SimpleRNN\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.datasets import mnist, cifar10\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "training_acc = [0]*10\n",
    "test_acc = [0]*10\n",
    "noise = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for i in range(10):\n",
    "    # load mnist dataset\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "    # compute the number of labels\n",
    "    num_labels = len(np.unique(y_train))\n",
    "\n",
    "    # convert to one-hot vector\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "\n",
    "    # resize and normalize\n",
    "    image_size = X_train.shape[1]\n",
    "    X_train = np.reshape(X_train,[-1, image_size, image_size])\n",
    "    X_test = np.reshape(X_test,[-1, image_size, image_size])\n",
    "    X_train = X_train.astype('float32') / 255\n",
    "    X_test = X_test.astype('float32') / 255\n",
    "    \n",
    "    X_train = add_salt_and_pepper_noise(X_train, noise[i])\n",
    "\n",
    "    input = Input(shape=(X_train.shape[1],X_train.shape[2]))\n",
    "    x = SimpleRNN(512, activation='relu', return_sequences=True, kernel_constraint=SpectralConstraint())(input)\n",
    "    x = SimpleRNN(512, activation='relu', return_sequences=False, kernel_constraint=SpectralConstraint())(x)\n",
    "    x = Dense(num_labels, activation='softmax', kernel_constraint=tf.keras.constraints.NonNeg())(x)\n",
    "    model = Model(input, x)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, epochs=100, batch_size=128, validation_split=0.25, verbose=2)\n",
    "\n",
    "    training_acc[i] = history.history['val_accuracy'][-1]\n",
    "    print(training_acc)\n",
    "    \n",
    "    loss, acc = model.evaluate(X_test, y_test, batch_size=128)\n",
    "\n",
    "    test_acc[i] = acc\n",
    "    print(test_acc)\n",
    "\n",
    "    name = 'iclrnn_512_'\n",
    "    name = name + str(noise[i]) + '.h5'\n",
    "    model.save(name)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d414685a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\zihaow19\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\profiler\\internal\\flops_registry.py:453: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
      "The FLOPs is:1613884\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.framework.convert_to_constants import  convert_variables_to_constants_v2_as_graph\n",
    "\n",
    "def get_flops(model):\n",
    "    concrete = tf.function(lambda inputs: model(inputs))\n",
    "    concrete_func = concrete.get_concrete_function(\n",
    "        [tf.TensorSpec([1, *inputs.shape[1:]]) for inputs in model.inputs])\n",
    "    frozen_func, graph_def = convert_variables_to_constants_v2_as_graph(concrete_func, lower_control_flow=False)\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.graph_util.import_graph_def(graph_def, name='')\n",
    "        run_meta = tf.compat.v1.RunMetadata()\n",
    "        opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "        flops = tf.compat.v1.profiler.profile(graph=graph, run_meta=run_meta, cmd=\"op\", options=opts)\n",
    "        return flops.total_float_ops\n",
    "\n",
    "print(\"The FLOPs is:{}\".format(get_flops(model)) ,flush=True )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
