{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc986002",
   "metadata": {
    "id": "cc986002"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, Input, Activation, Dropout, Add, LSTM, GRU, RNN, LayerNormalization, BatchNormalization, Conv1D, MaxPooling1D, Flatten, Layer\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam,SGD\n",
    "import tensorflow as tf\n",
    "from keras import Model, regularizers, activations\n",
    "from keras.constraints import Constraint\n",
    "import pickle\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8LlThIlQoUAl",
   "metadata": {
    "id": "8LlThIlQoUAl"
   },
   "outputs": [],
   "source": [
    "class MyLRNNCell(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, units, eps=0.01, gamma=0.01, beta=0.8, alpha=1, **kwargs):\n",
    "        self.units = units\n",
    "        self.state_size = units\n",
    "        self.I = tf.eye(units)\n",
    "        self.eps = eps\n",
    "        self.gamma = gamma\n",
    "        self.beta = beta\n",
    "        self.alpha = alpha\n",
    "        super(MyLRNNCell, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.C = self.add_weight(shape=(self.units, self.units),\n",
    "                                      initializer='random_normal',\n",
    "                                      name='C',\n",
    "                                      trainable=True)\n",
    "        self.B = self.add_weight(shape=(self.units, self.units),\n",
    "                                                initializer='random_normal',\n",
    "                                                name='B',\n",
    "                                                trainable=True)\n",
    "        self.U = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                                initializer='random_normal',\n",
    "                                                name='U',\n",
    "                                                trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.units,),\n",
    "                                    initializer='zeros',\n",
    "                                    name='b',\n",
    "                                    trainable=True)\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, states):\n",
    "        prev_h = states[0]\n",
    "\n",
    "        A = self.beta * (self.B - tf.transpose(self.B)) + (1 - self.beta) * (self.B + tf.transpose(self.B)) - self.gamma * self.I\n",
    "        W = self.beta * (self.C - tf.transpose(self.C)) + (1 - self.beta) * (self.C + tf.transpose(self.C)) - self.gamma * self.I\n",
    "\n",
    "        h = prev_h + self.eps * self.alpha * K.dot(prev_h, A) + self.eps * tf.nn.tanh(K.dot(prev_h, W) + K.dot(inputs, self.U) + self.b)\n",
    "        return h, [h]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(MyLRNNCell, self).get_config()\n",
    "        config.update({\"units\": self.units, \"eps\":self.eps, \"gamma\":self.gamma, \"beta\":self.beta, \"alpha\":self.alpha})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dbff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_salt_and_pepper_noise(images, amount):\n",
    "    noisy_images = images.copy()\n",
    "    num_images = images.shape[0]\n",
    "    num_pixels = images.shape[1] * images.shape[2]\n",
    "    num_salt = np.ceil(amount * num_pixels)\n",
    "    for i in range(num_images):\n",
    "        # Add salt noise\n",
    "        salt_indices = np.random.choice(num_pixels, size=int(num_salt), replace=False)\n",
    "        noisy_images[i].flat[salt_indices] = 1\n",
    "        \n",
    "        # Add pepper noise\n",
    "        pepper_indices = np.random.choice(num_pixels, size=int(num_salt), replace=False)\n",
    "        noisy_images[i].flat[pepper_indices] = 0\n",
    "    return noisy_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82db546",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "# load mnist dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# compute the number of labels\n",
    "num_labels = len(np.unique(y_train))\n",
    "\n",
    "# convert to one-hot vector\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# resize and normalize\n",
    "image_size = X_train.shape[1]\n",
    "X_train = np.reshape(X_train,[-1, image_size, image_size])\n",
    "X_test = np.reshape(X_test,[-1, image_size, image_size])\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "# add noise\n",
    "noise = 0\n",
    "X_train = add_salt_and_pepper_noise(X_train, noise)\n",
    "\n",
    "input = Input(shape=(X_train.shape[1],X_train.shape[2]))\n",
    "x = RNN(MyLRNNCell(units=64),return_sequences=True)(input)\n",
    "x = RNN(MyLRNNCell(units=64),return_sequences=False)(x)\n",
    "x = Dense(num_labels, activation='softmax')(x)\n",
    "model = Model(input, x)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=128, validation_split=0.25, verbose=2)\n",
    "\n",
    "training_acc = history.history['val_accuracy'][-1]\n",
    "print(training_acc)\n",
    "\n",
    "loss, acc = model.evaluate(X_test, y_test, batch_size=128)\n",
    "\n",
    "test_acc = acc\n",
    "print(test_acc)\n",
    "\n",
    "name = 'lrnn_64_'\n",
    "name = name + str(noise) + '.h5'\n",
    "model.save(name)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23a8417",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.convert_to_constants import  convert_variables_to_constants_v2_as_graph\n",
    "\n",
    "def get_flops(model):\n",
    "    concrete = tf.function(lambda inputs: model(inputs))\n",
    "    concrete_func = concrete.get_concrete_function(\n",
    "        [tf.TensorSpec([1, *inputs.shape[1:]]) for inputs in model.inputs])\n",
    "    frozen_func, graph_def = convert_variables_to_constants_v2_as_graph(concrete_func, lower_control_flow=False)\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.graph_util.import_graph_def(graph_def, name='')\n",
    "        run_meta = tf.compat.v1.RunMetadata()\n",
    "        opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "        flops = tf.compat.v1.profiler.profile(graph=graph, run_meta=run_meta, cmd=\"op\", options=opts)\n",
    "        return flops.total_float_ops\n",
    "\n",
    "print(\"The FLOPs is:{}\".format(get_flops(model)) ,flush=True )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
