{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc986002",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1701230006067,
     "user": {
      "displayName": "Wang Zihao",
      "userId": "13688795653924779981"
     },
     "user_tz": -480
    },
    "id": "cc986002"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, Input, Activation, Dropout, Add, LSTM, GRU, RNN, LayerNormalization, BatchNormalization, Conv1D, MaxPooling1D, Flatten, Layer\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam,SGD\n",
    "import tensorflow as tf\n",
    "from keras import Model, regularizers, activations\n",
    "from keras.constraints import Constraint\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a09c682",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1701230013867,
     "user": {
      "displayName": "Wang Zihao",
      "userId": "13688795653924779981"
     },
     "user_tz": -480
    },
    "id": "6a09c682"
   },
   "outputs": [],
   "source": [
    "# specifying constant parameters\n",
    "\n",
    "T_0 = 300\n",
    "V = 1\n",
    "k_0 = 8.46*(np.power(10,6))\n",
    "C_p = 0.231\n",
    "rho_L = 1000\n",
    "Q_s = 0.0\n",
    "T_s = 401.8727\n",
    "F = 5\n",
    "E = 5*(np.power(10,4))\n",
    "delta_H = -1.15*(np.power(10,4))\n",
    "R = 8.314\n",
    "C_A0s = 4\n",
    "C_As = 1.9537\n",
    "t_final = 0.005\n",
    "t_step = 1e-4\n",
    "P = np.array([[1060, 22], [22, 0.52]])\n",
    "\n",
    "num_step = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2f7b55",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1701230014340,
     "user": {
      "displayName": "Wang Zihao",
      "userId": "13688795653924779981"
     },
     "user_tz": -480
    },
    "id": "da2f7b55"
   },
   "outputs": [],
   "source": [
    "# generating inputs and initial states for CSTR, all expressed in deviation form\n",
    "\n",
    "u1_list = np.linspace(-3.5, 3.5, 4, endpoint=True)\n",
    "u2_list = np.linspace(-5e5, 5e5, 4, endpoint=True)\n",
    "T_initial = np.linspace(300, 600, 100, endpoint=True) - T_s\n",
    "CA_initial = np.linspace(0, 6, 100, endpoint=True) - C_As"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e9e386",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1701230014704,
     "user": {
      "displayName": "Wang Zihao",
      "userId": "13688795653924779981"
     },
     "user_tz": -480
    },
    "id": "e2e9e386",
    "outputId": "827bdb0e-d52b-4c6e-b7e8-d695d47e355a"
   },
   "outputs": [],
   "source": [
    "# sieve out initial states that lie outside of stability region\n",
    "\n",
    "T_start = list()\n",
    "CA_start = list()\n",
    "\n",
    "for T in T_initial:\n",
    "    for CA in CA_initial:\n",
    "        x = np.array([CA, T])\n",
    "        if x @ P @ x < 372:\n",
    "            CA_start.append(CA)\n",
    "            T_start.append(T)\n",
    "print(\"number of initial conditions: {}\".format(len(CA_start)))\n",
    "\n",
    "# convert to np.arrays\n",
    "CA_start = np.array([CA_start])\n",
    "T_start = np.array([T_start])\n",
    "x_deviation = np.concatenate((CA_start.T, T_start.T), axis=1)  # every row is a pair of initial states within stability region\n",
    "print(\"shape of x_deviation is {}\".format(x_deviation.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadad8ed",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1701230016324,
     "user": {
      "displayName": "Wang Zihao",
      "userId": "13688795653924779981"
     },
     "user_tz": -480
    },
    "id": "eadad8ed"
   },
   "outputs": [],
   "source": [
    "def CSTR_simulation(F, V, C_A0, k_0, E, R, T_0, delta_H, rho_L, C_p, Q, t_final, t_step, C_A_initial, T_initial):\n",
    "    \"\"\"\n",
    "        simulating CSTR using forward Euler method\n",
    "    \"\"\"\n",
    "\n",
    "    C_A_list = list()  # evolution of CA over time\n",
    "    T_list = list()  # evolution of T over time\n",
    "\n",
    "    C_A = C_A_initial + C_As\n",
    "    T = T_initial + T_s\n",
    "\n",
    "    for i in range(int(t_final / t_step)):\n",
    "        dCAdt = F / V * (C_A0 - C_A) - k_0 * np.exp(-E / (R * T)) * C_A**2\n",
    "        dTdt = F / V * (T_0 - T) - delta_H / (rho_L * C_p) * k_0 * np.exp(-E / (R * T)) * C_A**2 + Q / (rho_L * C_p * V)\n",
    "\n",
    "        T += dTdt * t_step\n",
    "        C_A += dCAdt * t_step\n",
    "\n",
    "        if i % 5 == 0:\n",
    "          C_A_list.append(C_A - C_As)  # in deviation form\n",
    "          T_list.append(T - T_s)  # in deviation form\n",
    "\n",
    "    return C_A_list, T_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59882525",
   "metadata": {
    "executionInfo": {
     "elapsed": 12120,
     "status": "ok",
     "timestamp": 1701230033171,
     "user": {
      "displayName": "Wang Zihao",
      "userId": "13688795653924779981"
     },
     "user_tz": -480
    },
    "id": "59882525"
   },
   "outputs": [],
   "source": [
    "# get X and y data for training and testing\n",
    "\n",
    "CA_output = list()\n",
    "T_output = list()\n",
    "CA_input = list()\n",
    "T_input = list()\n",
    "CA0_input = list()\n",
    "Q_input = list()\n",
    "\n",
    "for u1 in u1_list:\n",
    "    C_A0 = u1 + C_A0s\n",
    "\n",
    "    for u2 in u2_list:\n",
    "        Q = u2 + Q_s\n",
    "\n",
    "        for C_A_initial, T_initial in x_deviation:\n",
    "            CA0_input.append(u1)\n",
    "            Q_input.append(u2)\n",
    "            CA_input.append(C_A_initial)\n",
    "            T_input.append(T_initial)\n",
    "\n",
    "            C_A_list, T_list = CSTR_simulation(F, V, C_A0, k_0, E, R, T_0, delta_H, rho_L, C_p, Q, t_final, t_step, C_A_initial, T_initial)\n",
    "            CA_output.append(C_A_list)\n",
    "            T_output.append(T_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8X_9tOfuxL0o",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1701230033172,
     "user": {
      "displayName": "Wang Zihao",
      "userId": "13688795653924779981"
     },
     "user_tz": -480
    },
    "id": "8X_9tOfuxL0o",
    "outputId": "123f3325-ec84-4f04-c552-762b142c62d3"
   },
   "outputs": [],
   "source": [
    "CA0_input = np.array(CA0_input)\n",
    "print(CA0_input.shape)\n",
    "CA_output = np.array(CA_output)\n",
    "print(CA_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc6ede5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1701230033172,
     "user": {
      "displayName": "Wang Zihao",
      "userId": "13688795653924779981"
     },
     "user_tz": -480
    },
    "id": "2fc6ede5",
    "outputId": "4e18f0d6-ea3a-4b39-8fd2-7858c7bc9d9a"
   },
   "outputs": [],
   "source": [
    "# collate input for RNN\n",
    "\n",
    "CA0_input = np.array(CA0_input)\n",
    "CA0_input = CA0_input.reshape(-1,1,1)\n",
    "\n",
    "Q_input = np.array(Q_input)\n",
    "Q_input = Q_input.reshape(-1,1,1)\n",
    "\n",
    "CA_input = np.array(CA_input)\n",
    "CA_input = CA_input.reshape(-1,1,1)\n",
    "\n",
    "T_input = np.array(T_input)\n",
    "T_input = T_input.reshape(-1,1,1)\n",
    "\n",
    "RNN_input = np.concatenate((T_input, CA_input, Q_input, CA0_input), axis=2)\n",
    "\n",
    "\"\"\"\n",
    "    the input to RNN is in the shape [number of samples x timestep x variables], and the input variables are same for every\n",
    "    time step, not sure if my treatment here is correct\n",
    "\"\"\"\n",
    "\n",
    "RNN_input = RNN_input.repeat(num_step, axis=1)\n",
    "print(\"RNN_input shape is {}\".format(RNN_input.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358446c1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 654,
     "status": "ok",
     "timestamp": 1701230033824,
     "user": {
      "displayName": "Wang Zihao",
      "userId": "13688795653924779981"
     },
     "user_tz": -480
    },
    "id": "358446c1",
    "outputId": "5aac961e-06e8-41ba-847f-89ecdaef94ef"
   },
   "outputs": [],
   "source": [
    "# checking the input is duplicated 100 times for each time step\n",
    "print(RNN_input[0, 0])\n",
    "print(RNN_input[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd86ba27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1701230033825,
     "user": {
      "displayName": "Wang Zihao",
      "userId": "13688795653924779981"
     },
     "user_tz": -480
    },
    "id": "fd86ba27",
    "outputId": "ab98cb39-7ff1-4676-ba3c-2be02beca864"
   },
   "outputs": [],
   "source": [
    "# collate output for RNN\n",
    "\n",
    "CA_output = np.array(CA_output)\n",
    "CA_output = CA_output.reshape(-1, num_step, 1)\n",
    "\n",
    "T_output = np.array(T_output)\n",
    "T_output = T_output.reshape(-1, num_step, 1)\n",
    "\n",
    "RNN_output = np.concatenate((T_output, CA_output), axis=2)\n",
    "print(\"RNN_output shape is {}\".format(RNN_output.shape))  # output shape: number of samples x timestep x variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb81232",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1701230033825,
     "user": {
      "displayName": "Wang Zihao",
      "userId": "13688795653924779981"
     },
     "user_tz": -480
    },
    "id": "1cb81232",
    "outputId": "e54abb37-33f8-4ff4-c0de-3c8947b86184"
   },
   "outputs": [],
   "source": [
    "# checking output\n",
    "print(RNN_output[0, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8LlThIlQoUAl",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1701230033825,
     "user": {
      "displayName": "Wang Zihao",
      "userId": "13688795653924779981"
     },
     "user_tz": -480
    },
    "id": "8LlThIlQoUAl"
   },
   "outputs": [],
   "source": [
    "DEFAULT_BETA_BJORCK = 0.5\n",
    "DEFAULT_EPS_SPECTRAL = 1e-3\n",
    "DEFAULT_EPS_BJORCK = 1e-3\n",
    "DEFAULT_MAXITER_BJORCK = 15\n",
    "DEFAULT_MAXITER_SPECTRAL = 10\n",
    "SWAP_MEMORY = True\n",
    "STOP_GRAD_SPECTRAL = True\n",
    "\n",
    "def reshaped_kernel_orthogonalization(\n",
    "    kernel,\n",
    "    u,\n",
    "    adjustment_coef,\n",
    "    eps_spectral=DEFAULT_EPS_SPECTRAL,\n",
    "    eps_bjorck=DEFAULT_EPS_BJORCK,\n",
    "    beta=DEFAULT_BETA_BJORCK,\n",
    "    maxiter_spectral=DEFAULT_MAXITER_SPECTRAL,\n",
    "    maxiter_bjorck=DEFAULT_MAXITER_BJORCK,\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform reshaped kernel orthogonalization (RKO) to the kernel given as input. It\n",
    "    apply the power method to find the largest singular value and apply the Bjorck\n",
    "    algorithm to the rescaled kernel. This greatly improve the stability and and\n",
    "    speed convergence of the bjorck algorithm.\n",
    "\n",
    "    Args:\n",
    "        kernel (tf.Tensor): the kernel to orthogonalize\n",
    "        u (tf.Tensor): the vector used to do the power iteration method\n",
    "        adjustment_coef (float): the adjustment coefficient as used in convolution\n",
    "        eps_spectral (float): stopping criterion in spectral algorithm\n",
    "        eps_bjorck (float): stopping criterion in bjorck algorithm\n",
    "        beta (float): the beta used in the bjorck algorithm\n",
    "        maxiter_spectral (int): maximum number of iterations for the power iteration\n",
    "        maxiter_bjorck (int): maximum number of iterations for bjorck algorithm\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: the orthogonalized kernel, the new u, and sigma which is the largest\n",
    "            singular value\n",
    "\n",
    "    Reference:\n",
    "        Serrurier, M., Mamalet, F., González-Sanz, A., Boissin, T., Loubes, J. M., & Del Barrio, E. (2021). \n",
    "        Achieving robustness in classification using optimal transport with hinge regularization. \n",
    "        In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 505-514).\n",
    "        \n",
    "    \"\"\"\n",
    "    W_shape = kernel.shape\n",
    "    # Flatten the Tensor\n",
    "    W_reshaped = tf.reshape(kernel, [-1, W_shape[-1]])\n",
    "    W_bar, u, sigma = spectral_normalization(\n",
    "        W_reshaped, u, eps=eps_spectral, maxiter=maxiter_spectral\n",
    "    )\n",
    "    if (eps_bjorck is not None) and (beta is not None):\n",
    "        W_bar = bjorck_normalization(\n",
    "            W_bar, eps=eps_bjorck, beta=beta, maxiter=maxiter_bjorck\n",
    "        )\n",
    "    W_bar = W_bar * adjustment_coef\n",
    "    W_bar = K.reshape(W_bar, kernel.shape)\n",
    "    return W_bar, u, sigma\n",
    "\n",
    "\n",
    "def _wwtw(w):\n",
    "    if w.shape[0] > w.shape[1]:\n",
    "        return w @ (tf.transpose(w) @ w)\n",
    "    else:\n",
    "        return (w @ tf.transpose(w)) @ w\n",
    "\n",
    "\n",
    "def bjorck_normalization(\n",
    "    w, eps=DEFAULT_EPS_BJORCK, beta=DEFAULT_BETA_BJORCK, maxiter=DEFAULT_MAXITER_BJORCK\n",
    "):\n",
    "    \"\"\"\n",
    "    apply Bjorck normalization on w.\n",
    "\n",
    "    Args:\n",
    "        w (tf.Tensor): weight to normalize, in order to work properly, we must have\n",
    "            max_eigenval(w) ~= 1\n",
    "        eps (float): epsilon stopping criterion: norm(wt - wt-1) must be less than eps\n",
    "        beta (float): beta used in each iteration, must be in the interval ]0, 0.5]\n",
    "        maxiter (int): maximum number of iterations for the algorithm\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: the orthonormal weights\n",
    "\n",
    "    Reference:\n",
    "        Serrurier, M., Mamalet, F., González-Sanz, A., Boissin, T., Loubes, J. M., & Del Barrio, E. (2021). \n",
    "        Achieving robustness in classification using optimal transport with hinge regularization. \n",
    "        In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 505-514).\n",
    "        \n",
    "    \"\"\"\n",
    "    # create a fake old_w that does'nt pass the loop condition\n",
    "    # it won't affect computation as the first action done in the loop overwrite it.\n",
    "    old_w = 10 * w\n",
    "    # define the loop condition\n",
    "\n",
    "    def cond(w, old_w):\n",
    "        return tf.linalg.norm(w - old_w) >= eps\n",
    "\n",
    "    # define the loop body\n",
    "    def body(w, old_w):\n",
    "        old_w = w\n",
    "        w = (1 + beta) * w - beta * _wwtw(w)\n",
    "        return w, old_w\n",
    "\n",
    "    # apply the loop\n",
    "    w, old_w = tf.while_loop(\n",
    "        cond,\n",
    "        body,\n",
    "        (w, old_w),\n",
    "        parallel_iterations=30,\n",
    "        maximum_iterations=maxiter,\n",
    "        swap_memory=SWAP_MEMORY,\n",
    "    )\n",
    "    return w\n",
    "\n",
    "\n",
    "def _power_iteration(\n",
    "    linear_operator,\n",
    "    adjoint_operator,\n",
    "    u,\n",
    "    eps=DEFAULT_EPS_SPECTRAL,\n",
    "    maxiter=DEFAULT_MAXITER_SPECTRAL,\n",
    "    axis=None,\n",
    "):\n",
    "    \"\"\"Internal function that performs the power iteration algorithm to estimate the\n",
    "    largest singular vector of a linear operator.\n",
    "\n",
    "    Args:\n",
    "        linear_operator (Callable): a callable object that maps a linear operation.\n",
    "        adjoint_operator (Callable): a callable object that maps the adjoint of the\n",
    "            linear operator.\n",
    "        u (tf.Tensor): initialization of the singular vector.\n",
    "        eps (float, optional): stopping criterion of the algorithm, when\n",
    "            norm(u[t] - u[t-1]) is less than eps. Defaults to DEFAULT_EPS_SPECTRAL.\n",
    "        maxiter (int, optional): maximum number of iterations for the algorithm.\n",
    "            Defaults to DEFAULT_MAXITER_SPECTRAL.\n",
    "        axis (int/list, optional): dimension along which to normalize. Can be set for\n",
    "            depthwise convolution for example. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: the maximum singular vector.\n",
    "        \n",
    "    Reference:\n",
    "        Serrurier, M., Mamalet, F., González-Sanz, A., Boissin, T., Loubes, J. M., & Del Barrio, E. (2021). \n",
    "        Achieving robustness in classification using optimal transport with hinge regularization. \n",
    "        In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 505-514).\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare while loop variables\n",
    "    u = tf.math.l2_normalize(u, axis=axis)\n",
    "    # create a fake old_w that doesn't pass the loop condition, it will be overwritten\n",
    "    old_u = u + 2 * eps\n",
    "\n",
    "    # Loop body\n",
    "    def body(u, old_u):\n",
    "        old_u = u\n",
    "        v = linear_operator(u)\n",
    "        u = adjoint_operator(v)\n",
    "\n",
    "        u = tf.math.l2_normalize(u, axis=axis)\n",
    "\n",
    "        return u, old_u\n",
    "\n",
    "    # Loop stopping condition\n",
    "    def cond(u, old_u):\n",
    "        return tf.linalg.norm(u - old_u) >= eps\n",
    "\n",
    "    # Run the while loop\n",
    "    u, _ = tf.while_loop(\n",
    "        cond,\n",
    "        body,\n",
    "        (u, old_u),\n",
    "        maximum_iterations=maxiter,\n",
    "        swap_memory=SWAP_MEMORY,\n",
    "    )\n",
    "\n",
    "    # Prevent gradient to back-propagate into the while loop\n",
    "    if STOP_GRAD_SPECTRAL:\n",
    "        u = tf.stop_gradient(u)\n",
    "\n",
    "    return u\n",
    "\n",
    "\n",
    "def spectral_normalization(\n",
    "    kernel, u, eps=DEFAULT_EPS_SPECTRAL, maxiter=DEFAULT_MAXITER_SPECTRAL\n",
    "):\n",
    "    \"\"\"\n",
    "    Normalize the kernel to have its maximum singular value equal to 1.\n",
    "\n",
    "    Args:\n",
    "        kernel (tf.Tensor): the kernel to normalize, assuming a 2D kernel.\n",
    "        u (tf.Tensor): initialization of the maximum singular vector.\n",
    "        eps (float, optional): stopping criterion of the algorithm, when\n",
    "            norm(u[t] - u[t-1]) is less than eps. Defaults to DEFAULT_EPS_SPECTRAL.\n",
    "        maxiter (int, optional): maximum number of iterations for the algorithm.\n",
    "            Defaults to DEFAULT_MAXITER_SPECTRAL.\n",
    "\n",
    "    Returns:\n",
    "        the normalized kernel, the maximum singular vector, and the maximum singular\n",
    "            value.\n",
    "            \n",
    "    Reference:\n",
    "        Serrurier, M., Mamalet, F., González-Sanz, A., Boissin, T., Loubes, J. M., & Del Barrio, E. (2021). \n",
    "        Achieving robustness in classification using optimal transport with hinge regularization. \n",
    "        In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 505-514).\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    if u is None:\n",
    "        u = tf.random.uniform(\n",
    "            shape=(1, kernel.shape[-1]), minval=0.0, maxval=1.0, dtype=kernel.dtype\n",
    "        )\n",
    "\n",
    "    def linear_op(u):\n",
    "        return u @ tf.transpose(kernel)\n",
    "\n",
    "    def adjoint_op(v):\n",
    "        return v @ kernel\n",
    "\n",
    "    u = _power_iteration(linear_op, adjoint_op, u, eps, maxiter)\n",
    "\n",
    "    # Compute the largest singular value and the normalized kernel.\n",
    "    # We assume that in the worst case we converged to sigma + eps (as u and v are\n",
    "    # normalized after each iteration)\n",
    "    # In order to be sure that operator norm of normalized kernel is strictly less than\n",
    "    # one we use sigma + eps, which ensures stability of Björck algorithm even when\n",
    "    # beta=0.5\n",
    "    sigma = tf.reshape(tf.norm(linear_op(u)), (1, 1))\n",
    "    normalized_kernel = kernel / (sigma + eps)\n",
    "    return normalized_kernel, u, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "H2CpJ-MGo65c",
   "metadata": {
    "executionInfo": {
     "elapsed": 331,
     "status": "ok",
     "timestamp": 1701240276482,
     "user": {
      "displayName": "Wang Zihao",
      "userId": "13688795653924779981"
     },
     "user_tz": -480
    },
    "id": "H2CpJ-MGo65c"
   },
   "outputs": [],
   "source": [
    "class SpectralConstraint(Constraint):\n",
    "    def __init__(\n",
    "        self,\n",
    "        k_coef_lip=1.0,\n",
    "        eps_spectral=DEFAULT_EPS_SPECTRAL,\n",
    "        eps_bjorck=DEFAULT_EPS_BJORCK,\n",
    "        beta_bjorck=DEFAULT_BETA_BJORCK,\n",
    "        u=None,\n",
    "    ) -> None:\n",
    "        \n",
    "        \"\"\"\n",
    "        Ensure that *all* singular values of the weight matrix equals to 1. Computation\n",
    "        based on Bjorck algorithm. The computation is done in two steps:\n",
    "\n",
    "        1. reduce the larget singular value to k_coef_lip, using iterate power method.\n",
    "        2. increase other singular values to k_coef_lip, using bjorck algorithm.\n",
    "\n",
    "        Args:\n",
    "            k_coef_lip (float): lipschitz coefficient of the weight matrix\n",
    "            eps_spectral (float): stopping criterion for the iterative power algorithm.\n",
    "            eps_bjorck (float): stopping criterion Bjorck algorithm.\n",
    "            beta_bjorck (float): beta parameter in bjorck algorithm.\n",
    "            u (tf.Tensor): vector used for iterated power method, can be set to None\n",
    "                (used for serialization/deserialization purposes).\n",
    "                \n",
    "        Reference:\n",
    "            Serrurier, M., Mamalet, F., González-Sanz, A., Boissin, T., Loubes, J. M., & Del Barrio, E. (2021). \n",
    "            Achieving robustness in classification using optimal transport with hinge regularization. \n",
    "            In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 505-514).\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        self.eps_spectral = eps_spectral\n",
    "        self.eps_bjorck = eps_bjorck\n",
    "        self.beta_bjorck = beta_bjorck\n",
    "        self.k_coef_lip = k_coef_lip\n",
    "        if not (isinstance(u, tf.Tensor) or (u is None)):\n",
    "            u = tf.convert_to_tensor(u)\n",
    "        self.u = u\n",
    "        super(SpectralConstraint, self).__init__()\n",
    "\n",
    "    def __call__(self, w):\n",
    "        # make the largest singular value of W to be 1\n",
    "        wbar, _, _ = reshaped_kernel_orthogonalization(\n",
    "            w,\n",
    "            self.u,\n",
    "            self.k_coef_lip,\n",
    "            self.eps_spectral,\n",
    "            self.eps_bjorck,\n",
    "            self.beta_bjorck,\n",
    "        )\n",
    "\n",
    "        # clip to ensure non-negative weight\n",
    "        wbar = K.clip(wbar, 0, wbar)\n",
    "        return wbar\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            \"k_coef_lip\": self.k_coef_lip,\n",
    "            \"eps_spectral\": self.eps_spectral,\n",
    "            \"eps_bjorck\": self.eps_bjorck,\n",
    "            \"beta_bjorck\": self.beta_bjorck,\n",
    "            \"u\": None if self.u is None else self.u.numpy(),\n",
    "        }\n",
    "        base_config = super(SpectralConstraint, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f05c4fc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6f05c4fc",
    "outputId": "d1e1980c-2c92-45d8-8d5e-daf4cefa1c73"
   },
   "outputs": [],
   "source": [
    "# set the seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "num_dims = 4\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(RNN_input, RNN_output, test_size=0.3, random_state=123)\n",
    "\n",
    "# # define scalers for both X and y base on training data only\n",
    "scaler_X = preprocessing.StandardScaler().fit(X_train.reshape(-1, num_dims))\n",
    "scaler_y = preprocessing.StandardScaler().fit(y_train.reshape(-1, 2))\n",
    "\n",
    "X_train = scaler_X.transform(X_train.reshape(-1, num_dims)).reshape(-1,num_step,num_dims)\n",
    "X_test = scaler_X.transform(X_test.reshape(-1, num_dims)).reshape(-1,num_step,num_dims)\n",
    "y_train = scaler_y.transform(y_train.reshape(-1,2)).reshape(-1,num_step,2)\n",
    "y_test_normalized = scaler_y.transform(y_test.reshape(-1,2)).reshape(-1,num_step,2)\n",
    "\n",
    "# add noise\n",
    "noise = 0\n",
    "y_train = y_train + np.random.normal(0, noise, y_train.shape)\n",
    "\n",
    "# ICLRNN\n",
    "input = Input(shape=(X_train.shape[1],X_train.shape[2]))\n",
    "x = SimpleRNN(64, activation='relu', return_sequences=True, kernel_constraint=SpectralConstraint(), recurrent_constraint=SpectralConstraint())(input) \n",
    "x = LayerNormalization()(x)  \n",
    "x = SimpleRNN(64, activation='relu', return_sequences=True, kernel_constraint=SpectralConstraint(), recurrent_constraint=SpectralConstraint())(x) \n",
    "x = LayerNormalization()(x)  \n",
    "x = Dense(2, activation='linear', kernel_constraint=tf.keras.constraints.NonNeg())(x)\n",
    "model = Model(input, x)\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=256, validation_split=0.25, verbose=2)\n",
    "\n",
    "training_loss = history.history['val_loss'][-1]\n",
    "print(training_loss)\n",
    "\n",
    "loss = model.evaluate(X_test, y_test_normalized, batch_size=256)\n",
    "test_loss = loss[0]\n",
    "print(test_loss)\n",
    "\n",
    "name = 'iclrnn_original_64_'\n",
    "name = name + str(noise) + '.h5'\n",
    "model.save(name)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BdVN9TfSlipC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 303,
     "status": "ok",
     "timestamp": 1701230048313,
     "user": {
      "displayName": "Wang Zihao",
      "userId": "13688795653924779981"
     },
     "user_tz": -480
    },
    "id": "BdVN9TfSlipC",
    "outputId": "c990468f-2957-42f6-f0ef-11b030ccd855"
   },
   "outputs": [],
   "source": [
    "print(\"mean of input T, CA, Q, CA0 = \", scaler_X.mean_)\n",
    "print(\"std of input T, CA, Q, CA0 = \", scaler_X.scale_)\n",
    "print(\"mean of output T, CA = \", scaler_y.mean_)\n",
    "print(\"std of output T, CA = \", scaler_y.scale_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZKR5zu8duwbW",
   "metadata": {
    "id": "ZKR5zu8duwbW"
   },
   "outputs": [],
   "source": [
    "# ICLRNN with ReLU\n",
    "# model.save('iclrnn_0.h5')\n",
    "# model = tf.keras.models.load_model('iclrnn_original_256_0.h5', custom_objects={'SpectralConstraint': SpectralConstraint})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eqjUR_qVYdyq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10706,
     "status": "ok",
     "timestamp": 1701231466503,
     "user": {
      "displayName": "Wang Zihao",
      "userId": "13688795653924779981"
     },
     "user_tz": -480
    },
    "id": "eqjUR_qVYdyq",
    "outputId": "59a60d84-0a2b-43a4-85d2-737c57374609"
   },
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test, y_test_normalized, batch_size=256)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QBqsaQM1AvPk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 310,
     "status": "ok",
     "timestamp": 1701053291100,
     "user": {
      "displayName": "Wang Zihao",
      "userId": "13688795653924779981"
     },
     "user_tz": -480
    },
    "id": "QBqsaQM1AvPk",
    "outputId": "d8e2e40b-e116-4087-afab-c72b592b3338"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.convert_to_constants import  convert_variables_to_constants_v2_as_graph\n",
    "\n",
    "def get_flops(model):\n",
    "    concrete = tf.function(lambda inputs: model(inputs))\n",
    "    concrete_func = concrete.get_concrete_function(\n",
    "        [tf.TensorSpec([1, *inputs.shape[1:]]) for inputs in model.inputs])\n",
    "    frozen_func, graph_def = convert_variables_to_constants_v2_as_graph(concrete_func, lower_control_flow=False)\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.graph_util.import_graph_def(graph_def, name='')\n",
    "        run_meta = tf.compat.v1.RunMetadata()\n",
    "        opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "        flops = tf.compat.v1.profiler.profile(graph=graph, run_meta=run_meta, cmd=\"op\", options=opts)\n",
    "        return flops.total_float_ops\n",
    "\n",
    "print(\"The FLOPs is:{}\".format(get_flops(model)) ,flush=True )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z3WiUyZFw-Py",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "executionInfo": {
     "elapsed": 745,
     "status": "ok",
     "timestamp": 1701053295775,
     "user": {
      "displayName": "Wang Zihao",
      "userId": "13688795653924779981"
     },
     "user_tz": -480
    },
    "id": "z3WiUyZFw-Py",
    "outputId": "da12ce0a-f272-434f-a803-dde518ca5398"
   },
   "outputs": [],
   "source": [
    "# plot training and validation losses against epochs\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Normal RNN Training and validation loss')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xeUbhoNu1HbR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 926
    },
    "executionInfo": {
     "elapsed": 3822,
     "status": "ok",
     "timestamp": 1701053374182,
     "user": {
      "displayName": "Wang Zihao",
      "userId": "13688795653924779981"
     },
     "user_tz": -480
    },
    "id": "xeUbhoNu1HbR",
    "outputId": "48978226-8897-4383-c47c-26108591b2e6"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    equation for the stability ellipse is 1060x^2 + 44xy + 0.52y^2 - 372 = 0\n",
    "\"\"\"\n",
    "# prepare x and y coordinates for plotting the stability region\n",
    "y = np.linspace(-100, 100, 100000, endpoint=True)\n",
    "\n",
    "x_upper = list()\n",
    "x_lower = list()\n",
    "y_plot = list()\n",
    "\n",
    "for i in y:\n",
    "    sqrt = np.sqrt(-2688000 * i**2 + 15772800000)\n",
    "    if sqrt >= 0:\n",
    "        y_plot.append(i)\n",
    "        x_upper.append((-4400 * i + sqrt) / 212000)\n",
    "        x_lower.append((-4400 * i - sqrt) / 212000)\n",
    "        pass\n",
    "    pass\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "# # plot the first 10 samples and their trajectories\n",
    "y_predict = model.predict(X_test)\n",
    "print(y_predict.shape)\n",
    "\n",
    "y_predict = y_predict.reshape(-1,2)\n",
    "y_predict = scaler_y.inverse_transform(y_predict)\n",
    "y_predict = y_predict.reshape(-1,num_step,2)\n",
    "\n",
    "X_plot = X_test.reshape(-1,num_dims)\n",
    "X_plot = scaler_X.inverse_transform(X_plot)\n",
    "X_plot = X_plot.reshape(-1,num_step,num_dims)\n",
    "\n",
    "for i in range(10):\n",
    "    if i == 0:  # only add label to 1 data point\n",
    "        plt.plot(X_plot[i, 0, 1], X_plot[i, 0, 0], marker=\"*\", markersize=15, color='pink')\n",
    "        plt.plot(y_test[i, :, 1], y_test[i, :, 0], color='cyan', lw=2, label='Test')\n",
    "        plt.plot(y_predict[i, :, 1], y_predict[i, :, 0], color='black', lw=2, ls=':', label='Predicted')\n",
    "    else:\n",
    "        plt.plot(X_plot[i, 0, 1], X_plot[i, 0, 0], marker=\"*\", markersize=15, color='pink')\n",
    "        plt.plot(y_test[i, :, 1], y_test[i, :, 0], color='cyan', lw=2)\n",
    "        plt.plot(y_predict[i, :, 1], y_predict[i, :, 0], color='black', lw=2, ls=':')\n",
    "\n",
    "# plot stability region\n",
    "plt.plot(x_lower, y_plot, color='steelblue', label='stability region')\n",
    "plt.plot(x_upper, y_plot, color='steelblue')\n",
    "plt.ylim([-100, 100])\n",
    "plt.xlim([-2, 2])\n",
    "\n",
    "plt.xlabel(\"C_A - C_As\")\n",
    "plt.ylabel(\"T - T_s\")\n",
    "plt.legend()\n",
    "# plt.savefig('iclrnn_noise_0.4.pdf')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
