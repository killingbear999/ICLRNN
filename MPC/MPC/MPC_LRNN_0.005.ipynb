{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a98dacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 08:27:24.431371: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-05 08:27:24.432528: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-05 08:27:24.456341: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-05 08:27:24.457036: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-05 08:27:24.997898: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import pandas\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from scipy.optimize import NonlinearConstraint, LinearConstraint\n",
    "from scipy.optimize import BFGS, minimize, Bounds, SR1\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, SimpleRNN\n",
    "from keras import backend as K\n",
    "import numpy\n",
    "from keras.models import model_from_json, load_model\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "import pyipopt\n",
    "from numpy import *\n",
    "from keras.constraints import Constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14697a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLRNNCell(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, units, eps=0.01, gamma=0.01, beta=0.8, alpha=1, **kwargs):\n",
    "        self.units = units\n",
    "        self.state_size = units\n",
    "        self.I = tf.eye(units)\n",
    "        self.eps = eps\n",
    "        self.gamma = gamma\n",
    "        self.beta = beta\n",
    "        self.alpha = alpha\n",
    "        super(MyLRNNCell, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.C = self.add_weight(shape=(self.units, self.units),\n",
    "                                      initializer='random_normal',\n",
    "                                      name='C',\n",
    "                                      trainable=True)\n",
    "        self.B = self.add_weight(shape=(self.units, self.units),\n",
    "                                                initializer='random_normal',\n",
    "                                                name='B',\n",
    "                                                trainable=True)\n",
    "        self.U = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                                initializer='random_normal',\n",
    "                                                name='U',\n",
    "                                                trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.units,),\n",
    "                                    initializer='zeros',\n",
    "                                    name='b',\n",
    "                                    trainable=True)\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, states):\n",
    "        prev_h = states[0]\n",
    "\n",
    "        A = self.beta * (self.B - tf.transpose(self.B)) + (1 - self.beta) * (self.B + tf.transpose(self.B)) - self.gamma * self.I\n",
    "        W = self.beta * (self.C - tf.transpose(self.C)) + (1 - self.beta) * (self.C + tf.transpose(self.C)) - self.gamma * self.I\n",
    "\n",
    "        h = prev_h + self.eps * self.alpha * K.dot(prev_h, A) + self.eps * tf.nn.tanh(K.dot(prev_h, W) + K.dot(inputs, self.U) + self.b)\n",
    "        return h, [h]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(MyLRNNCell, self).get_config()\n",
    "        config.update({\"units\": self.units, \"eps\":self.eps, \"gamma\":self.gamma, \"beta\":self.beta, \"alpha\":self.alpha})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "889ce0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_L [-2.e+19 -2.e+19] [0 0]\n",
      "Num Iteratin:  0\n",
      "[PyIPOPT] Ipopt will use Hessian approximation.\n",
      "\n",
      "[PyIPOPT] Problem created\n",
      "Going to call solve\n",
      "x0 = [0. 0. 0. 0.]\n",
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit https://github.com/coin-or/Ipopt\n",
      "******************************************************************************\n",
      "\n",
      "The elapsed time is 131.46016311645508 s\n",
      "Solution of the primal variables, x\n",
      "x[0] = 137512.51074092992\n",
      "x[1] = -3.4999975921759447\n",
      "x[2] = 499999.9762134612\n",
      "x[3] = -3.499993609470965\n",
      "status= -1\n",
      "Objective value\n",
      "f(x*) = 695.5702205838154\n",
      "Control action=:   -3.4999975921759447 137512.51074092992\n",
      "Real model output x1 x2 in deviation form:    1.1664696984961047 -47.50641622163178\n",
      "Num Iteratin:  1\n",
      "[PyIPOPT] Ipopt will use Hessian approximation.\n",
      "\n",
      "[PyIPOPT] Problem created\n",
      "Going to call solve\n",
      "x0 = [ 4.99999976e+05 -3.49999361e+00  4.99999976e+05 -3.49999361e+00]\n",
      "The elapsed time is 96.51606512069702 s\n",
      "Solution of the primal variables, x\n",
      "x[0] = 493027.45132448705\n",
      "x[1] = -3.5000000349512215\n",
      "x[2] = 475856.7842588248\n",
      "x[3] = -3.500000034918267\n",
      "status= -1\n",
      "Objective value\n",
      "f(x*) = 534.0153487008364\n",
      "Control action=:   -3.5000000349512215 493027.45132448705\n",
      "Real model output x1 x2 in deviation form:    1.0802224337380668 -37.23484692681158\n",
      "Num Iteratin:  2\n",
      "[PyIPOPT] Ipopt will use Hessian approximation.\n",
      "\n",
      "[PyIPOPT] Problem created\n",
      "Going to call solve\n",
      "x0 = [ 4.75856784e+05 -3.50000003e+00  4.75856784e+05 -3.50000003e+00]\n",
      "The elapsed time is 143.8741693496704 s\n",
      "Solution of the primal variables, x\n",
      "x[0] = 489502.2234288445\n",
      "x[1] = -3.5000000349999714\n",
      "x[2] = 234326.07783148583\n",
      "x[3] = -2.639419891626866\n",
      "status= -1\n",
      "Objective value\n",
      "f(x*) = 376.05978547958273\n",
      "Control action=:   -3.5000000349999714 489502.2234288445\n",
      "Real model output x1 x2 in deviation form:    0.9852359810949669 -26.751216879060443\n",
      "Num Iteratin:  3\n",
      "[PyIPOPT] Ipopt will use Hessian approximation.\n",
      "\n",
      "[PyIPOPT] Problem created\n",
      "Going to call solve\n",
      "x0 = [ 2.34326078e+05 -2.63941989e+00  2.34326078e+05 -2.63941989e+00]\n",
      "The elapsed time is 140.7523729801178 s\n",
      "Solution of the primal variables, x\n",
      "x[0] = 201255.58724720453\n",
      "x[1] = -3.5000000183925506\n",
      "x[2] = 56850.50999347265\n",
      "x[3] = -3.4996661436152725\n",
      "status= -1\n",
      "Objective value\n",
      "f(x*) = 277.20269827895095\n",
      "Control action=:   -3.5000000183925506 201255.58724720453\n",
      "Real model output x1 x2 in deviation form:    0.8832285684076938 -22.223465270714875\n",
      "Num Iteratin:  4\n",
      "[PyIPOPT] Ipopt will use Hessian approximation.\n",
      "\n",
      "[PyIPOPT] Problem created\n",
      "Going to call solve\n",
      "x0 = [ 5.68505100e+04 -3.49966614e+00  5.68505100e+04 -3.49966614e+00]\n",
      "The elapsed time is 150.26342701911926 s\n",
      "Solution of the primal variables, x\n",
      "x[0] = 183047.049748473\n",
      "x[1] = -3.499999411940816\n",
      "x[2] = -499993.27846576856\n",
      "x[3] = -3.4993191559863\n",
      "status= -1\n",
      "Objective value\n",
      "f(x*) = 231.85142483520812\n",
      "Control action=:   -3.499999411940816 183047.049748473\n",
      "Real model output x1 x2 in deviation form:    0.7788426831770172 -17.953042450058057\n",
      "Num Iteratin:  5\n",
      "[PyIPOPT] Ipopt will use Hessian approximation.\n",
      "\n",
      "[PyIPOPT] Problem created\n",
      "Going to call solve\n",
      "x0 = [-4.99993278e+05 -3.49931916e+00 -4.99993278e+05 -3.49931916e+00]\n",
      "The elapsed time is 99.11740922927856 s\n",
      "Solution of the primal variables, x\n",
      "x[0] = 499982.47235522186\n",
      "x[1] = -3.5000000348547275\n",
      "x[2] = -461100.3886483712\n",
      "x[3] = -3.270001106338418\n",
      "status= -1\n",
      "Objective value\n",
      "f(x*) = 133.59998076329262\n",
      "Control action=:   -3.5000000348547275 499982.47235522186\n",
      "Real model output x1 x2 in deviation form:    0.6643116995543289 -6.377979342749601\n",
      "x1_record:  [1.25, 1.2466404962668498, 1.2382485160178027, 1.229866175554231, 1.2214934194704137, 1.2131301927986462, 1.204776441013359, 1.1964321100352926, 1.1880971462357333, 1.1797714964408026, 1.171455107935808, 1.1631453278027644, 1.154794583439242, 1.1463847295234981, 1.137912905679255, 1.129376159061558, 1.120771441233187, 1.112095604909302, 1.10334540056427, 1.0945174728944307, 1.0856083571303765, 1.076614512401308, 1.0675329314311066, 1.0583600823033634, 1.0490920923905374, 1.0397249620995372, 1.0302545602983302, 1.0206766195518886, 1.010986731160766, 1.0011803399956922, 0.991252739121754, 0.9812033297278128, 0.9711051817176909, 0.9609830978927126, 0.9508366560670632, 0.940665432123286, 0.9304690000797969, 0.9202469321635137, 0.9099987988878356, 0.8997241691362214, 0.8894226102516208, 0.8790939847498705, 0.868743224553107, 0.8583717966183285, 0.847979404468381, 0.8375657524389586, 0.8271305458020549, 0.8166734908948687, 0.8061942952543308, 0.7956926677574349, 0.7851683187675487, 0.774615372160273, 0.7639313364775455, 0.7530769597646436, 0.7420458543459795, 0.7308314240612966, 0.7194268576847664, 0.7078251222694532, 0.6960189564443184, 0.6840008636963834, 0.6717631056768969]\n",
      "x2_record:  [-50, -49.90014841607389, -49.6505623047546, -49.40103602531839, -49.151567868599294, -48.90215614461713, -48.65279918278914, -48.403495332144345, -48.15424296154089, -47.905040459886116, -47.655886236359656, -47.09892117971297, -46.079259251020744, -45.05816296049434, -44.035486141414076, -43.011078033049486, -41.98478312513248, -40.95644099577079, -39.92588614250042, -38.89294780616621, -37.8574497873108, -36.822263489477734, -35.78874785873819, -34.752140628085854, -33.71224537787068, -32.66885937670402, -31.621773353756357, -30.570771261563294, -29.515630029005695, -28.456119304135044, -27.39200118652372, -26.57274409694776, -26.125642305555825, -25.677209993656554, -25.227426490271, -24.776271027389782, -24.323722743336337, -23.869760686384833, -23.41436381864443, -22.957511020222217, -22.499181093677596, -22.055128531576234, -21.633410797956685, -21.210430435175603, -20.786173267253332, -20.360625157218852, -19.933772013259336, -19.50559979514108, -19.076094520910406, -18.645242273883404, -18.21302920993351, -17.504829036754174, -16.37957208502509, -15.24731688878591, -14.107741745732385, -12.960514583696966, -11.805292633005031, -10.641722095115636, -9.469437808899688, -8.288062916179173, -7.09720852846164]\n",
      "u1_record:  [-3.4999975921759447, -3.4999975921759447, -3.4999975921759447, -3.4999975921759447, -3.4999975921759447, -3.4999975921759447, -3.4999975921759447, -3.4999975921759447, -3.4999975921759447, -3.4999975921759447, -3.5000000349512215, -3.5000000349512215, -3.5000000349512215, -3.5000000349512215, -3.5000000349512215, -3.5000000349512215, -3.5000000349512215, -3.5000000349512215, -3.5000000349512215, -3.5000000349512215, -3.5000000349999714, -3.5000000349999714, -3.5000000349999714, -3.5000000349999714, -3.5000000349999714, -3.5000000349999714, -3.5000000349999714, -3.5000000349999714, -3.5000000349999714, -3.5000000349999714, -3.5000000183925506, -3.5000000183925506, -3.5000000183925506, -3.5000000183925506, -3.5000000183925506, -3.5000000183925506, -3.5000000183925506, -3.5000000183925506, -3.5000000183925506, -3.5000000183925506, -3.499999411940816, -3.499999411940816, -3.499999411940816, -3.499999411940816, -3.499999411940816, -3.499999411940816, -3.499999411940816, -3.499999411940816, -3.499999411940816, -3.499999411940816, -3.5000000348547275, -3.5000000348547275, -3.5000000348547275, -3.5000000348547275, -3.5000000348547275, -3.5000000348547275, -3.5000000348547275, -3.5000000348547275, -3.5000000348547275, -3.5000000348547275]\n",
      "u2_record:  [137512.51074092992, 137512.51074092992, 137512.51074092992, 137512.51074092992, 137512.51074092992, 137512.51074092992, 137512.51074092992, 137512.51074092992, 137512.51074092992, 137512.51074092992, 493027.45132448705, 493027.45132448705, 493027.45132448705, 493027.45132448705, 493027.45132448705, 493027.45132448705, 493027.45132448705, 493027.45132448705, 493027.45132448705, 493027.45132448705, 489502.2234288445, 489502.2234288445, 489502.2234288445, 489502.2234288445, 489502.2234288445, 489502.2234288445, 489502.2234288445, 489502.2234288445, 489502.2234288445, 489502.2234288445, 201255.58724720453, 201255.58724720453, 201255.58724720453, 201255.58724720453, 201255.58724720453, 201255.58724720453, 201255.58724720453, 201255.58724720453, 201255.58724720453, 201255.58724720453, 183047.049748473, 183047.049748473, 183047.049748473, 183047.049748473, 183047.049748473, 183047.049748473, 183047.049748473, 183047.049748473, 183047.049748473, 183047.049748473, 499982.47235522186, 499982.47235522186, 499982.47235522186, 499982.47235522186, 499982.47235522186, 499982.47235522186, 499982.47235522186, 499982.47235522186, 499982.47235522186, 499982.47235522186]\n",
      "time_record:  [131.46016311645508, 96.51606512069702, 143.8741693496704, 140.7523729801178, 150.26342701911926, 99.11740922927856]\n",
      "total time elapsed:  761.9836068153381 s\n",
      "average time for each iteration: 126.99726780255635 s\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import pandas\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from scipy.optimize import NonlinearConstraint, LinearConstraint\n",
    "from scipy.optimize import BFGS, minimize, Bounds, SR1\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, SimpleRNN\n",
    "import numpy\n",
    "from keras.models import model_from_json, load_model\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "import pyipopt\n",
    "from numpy import *\n",
    "\n",
    "#####Simulation time step\n",
    "delta=0.005\n",
    "hc=1e-4 #delta/100\n",
    "oper_time=0.01\n",
    "short_factor=int(0.005/delta)\n",
    "\n",
    "####Initial states\n",
    "CAi=1.25\n",
    "Ti=-50\n",
    "\n",
    "x1_nn=CAi\n",
    "x2_nn=Ti\n",
    "x1_record=[CAi]\n",
    "x2_record=[Ti]\n",
    "u1_record=[]\n",
    "u2_record=[]\n",
    "time_record=[]\n",
    "\n",
    "a=1060\n",
    "b=22\n",
    "d=0.52\n",
    "F=5\n",
    "V=1\n",
    "k0=8460000\n",
    "E=50000\n",
    "R=8.314\n",
    "T0=300\n",
    "Dh=-11500\n",
    "rho=1000\n",
    "sigma=1000\n",
    "Cp=0.231\n",
    "cp=0.231\n",
    "Qs=0\n",
    "CA0s=4\n",
    "x_record=[0,0]\n",
    "\n",
    "#steady-state\n",
    "CAs= 1.9537\n",
    "Ts=  401.8727\n",
    "\n",
    "w1_std=2.5\n",
    "w2_std=70\n",
    "state_ss=numpy.array([Ts, CAs])\n",
    "input_ss=numpy.array([Qs, CA0s])\n",
    "ROOT_FOLDER=os.getcwd()\n",
    "\n",
    "#### CONSTANTS ####\n",
    "NUM_MPC_ITERATION=50*short_factor   #10000000000\n",
    "OUTPUT_NO=0\n",
    "TOTAL_MODELS=12 # used to be 8\n",
    "NUM_SUBMODELS=1\n",
    "NUM_OUTPUTS=2\n",
    "NUM_INPUTS=4   #used to be 16\n",
    "HORIZON=2\n",
    "NUM_IN_SEQUENCE=10\n",
    "PREDICTION_STORE=0\n",
    "deviation=0\n",
    "NUM_MPC_INPUTS=2*HORIZON\n",
    "NUM_MPC_CONSTRAINTS=HORIZON\n",
    "realtime_data=None\n",
    "setpoint=[0, 0]\n",
    "\n",
    "def my_ens_prediction(num_horizon,my_rawdata,my_inputs):\n",
    "    xx = []\n",
    "    nn_inputs = []\n",
    "    ensemble_output = numpy.zeros((num_horizon,NUM_OUTPUTS,NUM_IN_SEQUENCE))\n",
    "    ensemble_output = ensemble_output.reshape(num_horizon,NUM_IN_SEQUENCE,NUM_OUTPUTS)\n",
    "    predict_output = []\n",
    "    x_test2 = my_rawdata[0:NUM_OUTPUTS].astype(float)\n",
    "    x_test2= (x_test2-state_mean)/state_std\n",
    "\n",
    "    predict_output_normal=[[0 for i in range(NUM_OUTPUTS)] for j in range(NUM_IN_SEQUENCE)]\n",
    "    for i_model in range(num_horizon):       \n",
    "        COUNT_CORRECT_MODEL=0\n",
    "        my_inputs_normalized = (my_inputs[2*i_model:2*(i_model+1)] - input_mean) / input_std\n",
    "        sum=[[0 for i in range(NUM_OUTPUTS)] for j in range(NUM_IN_SEQUENCE)]\n",
    "        xx = numpy.concatenate((x_test2,  my_inputs_normalized), axis=None).reshape((1, NUM_INPUTS))\n",
    "        xx = numpy.tile(xx, (NUM_IN_SEQUENCE, 1))\n",
    "        nn_inputs = xx.reshape(1, NUM_IN_SEQUENCE, NUM_INPUTS)\n",
    "        for j_submodel in range (NUM_SUBMODELS):\n",
    "            predict_output = numpy.array(model[j_submodel].predict(nn_inputs,verbose=0))\n",
    "            predict_output = predict_output.reshape(NUM_IN_SEQUENCE, NUM_OUTPUTS)\n",
    "            sum=sum+predict_output\n",
    "        # MODEL AVERAGING (ENSEMBLE LEARNING)\n",
    "        predict_output=sum/NUM_SUBMODELS\n",
    "        x_test2=predict_output[-1,0:2]\n",
    "\n",
    "        #########  if delta=0.005##########\n",
    "        x_test2 = predict_output[int(NUM_IN_SEQUENCE/short_factor-1), 0:2]\n",
    "        x_test2=x_test2 * output_std + output_mean\n",
    "        x_test2 = (x_test2 - state_mean) / state_std\n",
    "\n",
    "        # RESCALING BY THE CORRESPONDING STANDARD DEVIATION & THE MEAN OF THE OUTPUT STATISTICS OF THE EXITING SURFACE\n",
    "        predict_output_normal = predict_output * output_std + output_mean\n",
    "        ensemble_output[i_model,:,:]=predict_output_normal\n",
    "\n",
    "    return ensemble_output    \n",
    "\n",
    "#################################################\n",
    "################## MPC PROGRAM ##################\n",
    "#################################################\n",
    "### DEFINE THE UPPER BOUND AND LOWER BOUND OF THE MANIPULATED INPUTS ###\n",
    "\n",
    "def eval_f(x):\n",
    "    assert len(x) == int(NUM_MPC_INPUTS)\n",
    "    offset=0\n",
    "    global PREDICTION_STORE\n",
    "    #### CALCULATE OUTLET CONC ###########\n",
    "    df_ensemble_output = my_ens_prediction(num_horizon=int(NUM_MPC_INPUTS/2),my_rawdata=realtime_data,my_inputs=x)\n",
    "    #### account for all intermediate steps ####\n",
    "    for j in range (int(NUM_MPC_INPUTS/2)):\n",
    "        est_outlet_product = df_ensemble_output[j, :, 0:2]\n",
    "        for i in range (int(NUM_IN_SEQUENCE/short_factor)):  #NUM_IN_SEQUENCE/2\n",
    "             offset = offset + (setpoint[0] - (est_outlet_product[i, 0])) ** 2  + (setpoint[1] - (est_outlet_product[i, 1])) ** 2 * 1000\n",
    "        offset=offset+x[2*j] **2 *3e-10 + 1* x[2*j+1] ** 2\n",
    "\n",
    "    return offset/100\n",
    "\n",
    "def eval_grad_f(x):\n",
    "    assert len(x) == int(NUM_MPC_INPUTS)\n",
    "    step = 1e-1 # we just have a small step\n",
    "    objp=objm=0\n",
    "    grad_f = [0]*NUM_MPC_INPUTS\n",
    "    xpstep = [0]*NUM_MPC_INPUTS\n",
    "    xmstep = [0]*NUM_MPC_INPUTS\n",
    "    for i_mpc_input in range(NUM_MPC_INPUTS):\n",
    "        xpstep=x.copy()\n",
    "        xmstep=x.copy()\n",
    "        # for each variables, we need to evaluate the derivative of the function with respect to that variable, This is why we have the for loop\n",
    "        xpstep[i_mpc_input]  = xpstep[i_mpc_input]+step \n",
    "        xmstep[i_mpc_input] = xmstep[i_mpc_input]-step\n",
    "    \n",
    "        # Evaluate the objective function at xpstep and xmstep\n",
    "        objp=eval_f(xpstep) # This function returns the value of the objective function evaluated with the variable x[i] is perturebed +step\n",
    "        objm=eval_f(xmstep) # This function returns the value of the objective function evaluated with the variable x[i] is perturebed -step\n",
    "        grad_f[i_mpc_input] = (objp - objm) / (2 * step) # This evaluates the gradient of the objetive function with repect to the optimization variable x[i]\n",
    "    return array(grad_f)\n",
    "\n",
    "def eval_g(x):\n",
    "    assert len(x) == int(NUM_MPC_INPUTS)\n",
    "    #### CALCULATE FLUID TEMPERATURE ALONG THE FIRST THREE SURFACES ###########\n",
    "    CAd2=realtime_data[1]\n",
    "    Td2=realtime_data[0]\n",
    "    g=array([-5.0]*NUM_MPC_CONSTRAINTS)\n",
    "\n",
    "    df_ensemble_output2 = my_ens_prediction(num_horizon=int(NUM_MPC_INPUTS / 2), my_rawdata=realtime_data, my_inputs=x)\n",
    "    for j in range(int(NUM_MPC_INPUTS / 2)):\n",
    "        est_outlet_product2 = df_ensemble_output2[j, int(NUM_IN_SEQUENCE/short_factor-1), 0:2]  #int(NUM_IN_SEQUENCE/2-1)\n",
    "        g[j]= d * (est_outlet_product2[0]) ** 2+ 2 * b * (est_outlet_product2[0])*(est_outlet_product2[1]) + \\\n",
    "              a*(est_outlet_product2[1]) ** 2 - a*CAd2**2 - 2*b*CAd2*Td2 - d*Td2**2\n",
    "\n",
    "    return  g\n",
    "\n",
    "nnzj = NUM_MPC_CONSTRAINTS*NUM_MPC_INPUTS\n",
    "\n",
    "def eval_jac_g(x, flag):\n",
    "    if flag:\n",
    "        list_x = []\n",
    "        list_y=[]\n",
    "        for i in range(int(NUM_MPC_INPUTS / 2)):\n",
    "            list_x = list_x + [i] * NUM_MPC_INPUTS\n",
    "            list_y = list_y +list(range(0, int(NUM_MPC_INPUTS)))\n",
    "        return (array(list_x),\n",
    "                array(list_y))\n",
    "    else:\n",
    "        assert len(x) == int(NUM_MPC_INPUTS)\n",
    "        step = 1e-1 # we just have a small step\n",
    "        gp=gm=numpy.zeros(NUM_MPC_CONSTRAINTS)\n",
    "        xpstep=xmstep=numpy.zeros(NUM_MPC_INPUTS)\n",
    "        jac_g = [[0]*int(NUM_MPC_INPUTS) for _ in range(NUM_MPC_CONSTRAINTS)]\n",
    "        for i_mpc_input in range(NUM_MPC_INPUTS):\n",
    "            xpstep=x.copy()\n",
    "            xmstep=x.copy()\n",
    "            # for each variables, we need to evaluate the derivative of the function with respect to that variable, This is why we have the for loop\n",
    "            xpstep[i_mpc_input] += step \n",
    "            xmstep[i_mpc_input] -= step\n",
    "            gp=eval_g(xpstep)\n",
    "            gm=eval_g(xmstep)\n",
    "            for num_constraint in range(NUM_MPC_CONSTRAINTS):\n",
    "                jac_g[num_constraint][i_mpc_input] = (gp[num_constraint] - gm[num_constraint]) / (2 * step)\n",
    "        return array(jac_g)\n",
    "\n",
    "def apply_new(x):\n",
    "    return True\n",
    "def print_variable(variable_name, value):\n",
    "    for i in range(len(value)):\n",
    "        print(\"{} {}\".format(variable_name + \"[\"+str(i)+\"] =\", value[i]))\n",
    "\n",
    "nnzh = NUM_MPC_INPUTS**2\n",
    "\n",
    "#####################################################################\n",
    "##### PRE-PROCESSING (THE FOLLOWING COMMANDS ARE EXECUTED ONCE) #####\n",
    "#####################################################################\n",
    "#### LOAD MEAN AND STD FILES###########\n",
    "#### READ MEANS & STD FROM THE FILE #####\n",
    "x1_mean=1.6712e-02 # CA\n",
    "x1_std=8.4936e-01 \n",
    "x2_mean=-6.1691e-01# T\n",
    "x2_std=3.8528e+01 \n",
    "u1_mean=1.1605e-02   # CA0\n",
    "u1_std=2.6116e+00 \n",
    "u2_mean=1.9277e+02    # Q\n",
    "u2_std=3.7388e+05\n",
    "y1_mean=0.01958    # CA\n",
    "y1_std=0.8453\n",
    "y2_mean=-0.7537  # T\n",
    "y2_std=38.7847\n",
    "state_mean=numpy.array([x2_mean, x1_mean])\n",
    "state_std=numpy.array([x2_std, x1_std])\n",
    "input_mean=numpy.array([u2_mean, u1_mean])\n",
    "input_std=numpy.array([u2_std, u1_std])\n",
    "output_mean=numpy.array([y2_mean, y1_mean])\n",
    "output_std=numpy.array([y2_std, y1_std])\n",
    "\n",
    "model=[1]*(NUM_SUBMODELS) \n",
    "\n",
    "#### LOAD NEURAL NETWORK MODELS ####\n",
    "model[0]=load_model(\"lrnn_256_0.h5\", custom_objects={'MyLRNNCell': MyLRNNCell})\n",
    "    \n",
    "####################################################################\n",
    "##### SOLVING THE MPC PROGRAM TO FIND THE OPTIMIZED MPC INPUTS #####\n",
    "####################################################################\n",
    "##########  KEEP RUNNING MPC ###############\n",
    "\n",
    "dir_name = os.getcwd()\n",
    "test = os.listdir(dir_name)\n",
    "\n",
    "for item in test:\n",
    "    if item.endswith(\".txt\"):\n",
    "        os.remove(os.path.join(dir_name, item))\n",
    "\n",
    "nvar = NUM_MPC_INPUTS\n",
    "x_lower=[0]* nvar\n",
    "x_upper=[0]* nvar\n",
    "for i in range(int(NUM_MPC_INPUTS/2)):\n",
    "    x_lower[2*i]=-5e5\n",
    "    x_lower[2 * i+1] = -3.5\n",
    "    x_upper[2 * i] = 5e5\n",
    "    x_upper[2 * i + 1] = 3.5\n",
    "x_L = array(x_lower) #array([-5e5, -3.5])\n",
    "x_U = array(x_upper) #array([5e5, 3.5])\n",
    "\n",
    "### DEFINE THE UPPER BOUND AND LOWER BOUND OF THE CONSTRAINT ###\n",
    "ncon = NUM_MPC_CONSTRAINTS\n",
    "g_L = array([-2e19]*HORIZON)\n",
    "g_U = array([0]*HORIZON)\n",
    "\n",
    "print (\"g_L\", g_L, g_U)\n",
    "\n",
    "for main_iteration in range(NUM_MPC_ITERATION):\n",
    "    print (\"Num Iteratin: \", main_iteration)\n",
    "    rawdata=numpy.array([Ti, CAi])\n",
    "    realtime_data=rawdata\n",
    "\n",
    "    start = time.time()\n",
    "    nlp = pyipopt.create(nvar, x_L, x_U, ncon, g_L, g_U, nnzj, nnzh, eval_f, eval_grad_f, eval_g, eval_jac_g)\n",
    "    if main_iteration ==0 :\n",
    "        x0 = array([0.0]*int(NUM_MPC_INPUTS))\n",
    "    else:\n",
    "        x0=x\n",
    "        x0[0:-2]=x[2:]\n",
    "        x0[-2:]=x[-2:]#[0, 0]\n",
    "        x_record=x\n",
    "        \n",
    "    \"\"\"\n",
    "    print x0\n",
    "    print nvar, ncon, nnzj\n",
    "    print x_L,  x_U\n",
    "    print g_L, g_U\n",
    "    print eval_f(x0)\n",
    "    print eval_grad_f(x0)\n",
    "    print eval_g(x0)\n",
    "    a =  eval_jac_g(x0, True)\n",
    "    print \"a = \", a[1], a[0]\n",
    "    print eval_jac_g(x0, False)\n",
    "    print eval_h(x0, pi0, 1.0, False)\n",
    "    print eval_h(x0, pi0, 1.0, True)\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\" You CAd2 set Ipopt options by calling nlp.num_option, nlp.str_option\n",
    "    or nlp.int_option. For instance, to set the tolarance by calling\n",
    "\n",
    "        nlp.num_option('tol', 1e-8)\n",
    "\n",
    "    For a complete list of Ipopt options, refer to\n",
    "\n",
    "        http://www.coin-or.org/Ipopt/documentation/node59.html\n",
    "\n",
    "    Note that Ipopt distinguishs between Int, Num, and Str options, yet sometimes\n",
    "    does not explicitly tell you which option is which.  If you are not sure about\n",
    "    the option's type, just try it in PyIpopt.  If you try to set one type of\n",
    "    option using the wrong function, Pyipopt will remind you of it. \"\"\"\n",
    "    nlp.int_option('max_iter', 100)\n",
    "    nlp.num_option('tol', 1e-5)\n",
    "    nlp.int_option('print_level', 2)\n",
    "    print(\"Going to call solve\")\n",
    "    print(\"x0 = {}\".format(x0))\n",
    "    x, zl, zu, constraint_multipliers, obj, status = nlp.solve(x0)\n",
    "\n",
    "    nlp.close()\n",
    "    end = time.time()\n",
    "    \n",
    "    print(\"The elapsed time is\", end - start, \"s\")\n",
    "    time_record.append(end-start)\n",
    "\n",
    "    print(\"Solution of the primal variables, x\")\n",
    "    print_variable(\"x\", x)\n",
    "    print (\"status=\", status)\n",
    "    print(\"Objective value\")\n",
    "    print(\"f(x*) = {}\".format(obj))\n",
    "    print (\"Control action=:  \", x[1], x[0])\n",
    "\n",
    "    x1=CAi\n",
    "    x2=Ti\n",
    "\n",
    "    w1 =numpy.random.normal(0, w1_std, 1)\n",
    "    w2 =numpy.random.normal(0, w2_std, 1)\n",
    "    if w1>w1_std:\n",
    "        w1=w1_std\n",
    "    if w1<-w1_std:\n",
    "        w1=-w1_std\n",
    "    if w2>w2_std:\n",
    "        w2=w2_std\n",
    "    if w2>w2_std:\n",
    "        w2=w2_std\n",
    "\n",
    "    for kk in range (int(delta/hc)):\n",
    "        x1_new = x1 + hc * ((F / V) * (x[1] - x1) -\n",
    "                            k0 * ((numpy.exp(-E / (R * (x2 + Ts)))*(x1 + CAs) * (x1 + CAs))\n",
    "                                  - numpy.exp(-E / (R * Ts)) * CAs * CAs))\n",
    "\n",
    "        x2_new = x2 + hc * (((F / V) * (-x2) + (-Dh / (sigma * cp)) *\n",
    "                             (k0 * ((numpy.exp(-E / (R * (x2 + Ts))) * (x1 + CAs) * (x1 + CAs)) -\n",
    "                                      numpy.exp(-E / (R * Ts)) * CAs * CAs)) + (x[0] / (sigma * cp * V))))\n",
    "\n",
    "        x1 = x1_new\n",
    "        x2 = x2_new\n",
    "\n",
    "        if (kk%5==1):\n",
    "            x1_record.append(x1)\n",
    "            x2_record.append(x2)\n",
    "            u1_record.append(x[1])\n",
    "            u2_record.append(x[0])\n",
    "\n",
    "    CAi=x1\n",
    "    Ti=x2\n",
    "\n",
    "    print('Real model output x1 x2 in deviation form:   ', x1, x2)\n",
    "\n",
    "    if sum(time_record) > 720:\n",
    "        break\n",
    "\n",
    "print (\"x1_record: \",x1_record)\n",
    "print (\"x2_record: \",x2_record)\n",
    "\n",
    "print (\"u1_record: \",u1_record)\n",
    "print (\"u2_record: \",u2_record)\n",
    "\n",
    "print(\"time_record: \", time_record)\n",
    "print(\"total time elapsed: \", sum(time_record), 's')\n",
    "print(\"average time for each iteration:\", sum(time_record)/len(time_record), 's')\n",
    "\n",
    "numpy.savetxt(\"x1.txt\",   x1_record, fmt=\"%f\",  delimiter=\" \")\n",
    "numpy.savetxt(\"x2.txt\",   x2_record, fmt=\"%f\",  delimiter=\" \")\n",
    "\n",
    "numpy.savetxt(\"u1.txt\",   u1_record, fmt=\"%f\",  delimiter=\" \")\n",
    "numpy.savetxt(\"u2.txt\",   u2_record, fmt=\"%f\",  delimiter=\" \")\n",
    "numpy.savetxt(\"time_LRNN.txt\",   time_record, fmt=\"%f\",  delimiter=\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
