{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "889ce0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 08:27:30.102713: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-05 08:27:30.103900: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-05 08:27:30.128615: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-05 08:27:30.129504: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-05 08:27:30.729498: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_L [-2.e+19 -2.e+19] [0 0]\n",
      "Num Iteratin:  0\n",
      "[PyIPOPT] Ipopt will use Hessian approximation.\n",
      "\n",
      "[PyIPOPT] Problem created\n",
      "Going to call solve\n",
      "x0 = [0. 0. 0. 0.]\n",
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit https://github.com/coin-or/Ipopt\n",
      "******************************************************************************\n",
      "\n",
      "The elapsed time is 136.90255618095398 s\n",
      "Solution of the primal variables, x\n",
      "x[0] = 166498.38159398187\n",
      "x[1] = -3.500000034998327\n",
      "x[2] = 372679.48240853247\n",
      "x[3] = -3.500000034996234\n",
      "status= -1\n",
      "Objective value\n",
      "f(x*) = 711.2260221648161\n",
      "Control action=:   -3.500000034998327 166498.38159398187\n",
      "Real model output x1 x2 in deviation form:    1.166215154861889 -46.87397185925735\n",
      "Num Iteratin:  1\n",
      "[PyIPOPT] Ipopt will use Hessian approximation.\n",
      "\n",
      "[PyIPOPT] Problem created\n",
      "Going to call solve\n",
      "x0 = [ 3.72679482e+05 -3.50000003e+00  3.72679482e+05 -3.50000003e+00]\n",
      "The elapsed time is 56.115288496017456 s\n",
      "Solution of the primal variables, x\n",
      "x[0] = 370467.9979771688\n",
      "x[1] = -3.500000034999935\n",
      "x[2] = 371383.1223951974\n",
      "x[3] = -3.500000035006302\n",
      "status= 2\n",
      "Objective value\n",
      "f(x*) = 560.8743004154913\n",
      "Control action=:   -3.500000034999935 370467.9979771688\n",
      "Real model output x1 x2 in deviation form:    1.0807107865784862 -39.27525624934599\n",
      "Num Iteratin:  2\n",
      "[PyIPOPT] Ipopt will use Hessian approximation.\n",
      "\n",
      "[PyIPOPT] Problem created\n",
      "Going to call solve\n",
      "x0 = [ 3.71383122e+05 -3.50000004e+00  3.71383122e+05 -3.50000004e+00]\n",
      "The elapsed time is 95.95012068748474 s\n",
      "Solution of the primal variables, x\n",
      "x[0] = 498073.2813559066\n",
      "x[1] = -3.500000034999712\n",
      "x[2] = 112069.69876278912\n",
      "x[3] = -3.500000034999557\n",
      "status= -1\n",
      "Objective value\n",
      "f(x*) = 403.8934705571792\n",
      "Control action=:   -3.500000034999712 498073.2813559066\n",
      "Real model output x1 x2 in deviation form:    0.9883948280335936 -28.691516782072124\n",
      "Num Iteratin:  3\n",
      "[PyIPOPT] Ipopt will use Hessian approximation.\n",
      "\n",
      "[PyIPOPT] Problem created\n",
      "Going to call solve\n",
      "x0 = [ 1.12069699e+05 -3.50000003e+00  1.12069699e+05 -3.50000003e+00]\n",
      "The elapsed time is 103.2247052192688 s\n",
      "Solution of the primal variables, x\n",
      "x[0] = 302025.70436042786\n",
      "x[1] = -3.5000000350063067\n",
      "x[2] = -22969.732863899815\n",
      "x[3] = -2.88498302382227\n",
      "status= 2\n",
      "Objective value\n",
      "f(x*) = 284.5542141899698\n",
      "Control action=:   -3.5000000350063067 302025.70436042786\n",
      "Real model output x1 x2 in deviation form:    0.8877162658720357 -22.03122125012339\n",
      "Num Iteratin:  4\n",
      "[PyIPOPT] Ipopt will use Hessian approximation.\n",
      "\n",
      "[PyIPOPT] Problem created\n",
      "Going to call solve\n",
      "x0 = [-2.29697329e+04 -2.88498302e+00 -2.29697329e+04 -2.88498302e+00]\n",
      "The elapsed time is 78.27881026268005 s\n",
      "Solution of the primal variables, x\n",
      "x[0] = 253597.02941362784\n",
      "x[1] = -3.500000034999962\n",
      "x[2] = -56382.20488829656\n",
      "x[3] = 0.29644634987001256\n",
      "status= 2\n",
      "Objective value\n",
      "f(x*) = 200.53499746345656\n",
      "Control action=:   -3.500000034999962 253597.02941362784\n",
      "Real model output x1 x2 in deviation form:    0.7811578565437747 -16.154410210277078\n",
      "Num Iteratin:  5\n",
      "[PyIPOPT] Ipopt will use Hessian approximation.\n",
      "\n",
      "[PyIPOPT] Problem created\n",
      "Going to call solve\n",
      "x0 = [-5.63822049e+04  2.96446350e-01 -5.63822049e+04  2.96446350e-01]\n",
      "The elapsed time is 126.09077715873718 s\n",
      "Solution of the primal variables, x\n",
      "x[0] = 228772.48412558762\n",
      "x[1] = -3.4999998517599575\n",
      "x[2] = 237429.07673950333\n",
      "x[3] = -3.4999993876331983\n",
      "status= -1\n",
      "Objective value\n",
      "f(x*) = 119.76568004646595\n",
      "Control action=:   -3.4999998517599575 228772.48412558762\n",
      "Real model output x1 x2 in deviation form:    0.6692297127344915 -10.555197516683608\n",
      "Num Iteratin:  6\n",
      "[PyIPOPT] Ipopt will use Hessian approximation.\n",
      "\n",
      "[PyIPOPT] Problem created\n",
      "Going to call solve\n",
      "x0 = [ 2.37429077e+05 -3.49999939e+00  2.37429077e+05 -3.49999939e+00]\n",
      "The elapsed time is 114.93159890174866 s\n",
      "Solution of the primal variables, x\n",
      "x[0] = 213907.1760144498\n",
      "x[1] = -3.49999983698992\n",
      "x[2] = 246394.01756168882\n",
      "x[3] = -3.4999989511168916\n",
      "status= 0\n",
      "Objective value\n",
      "f(x*) = 71.72038581925841\n",
      "Control action=:   -3.49999983698992 213907.1760144498\n",
      "Real model output x1 x2 in deviation form:    0.5521030683411347 -5.015702293757503\n",
      "Num Iteratin:  7\n",
      "[PyIPOPT] Ipopt will use Hessian approximation.\n",
      "\n",
      "[PyIPOPT] Problem created\n",
      "Going to call solve\n",
      "x0 = [ 2.46394018e+05 -3.49999895e+00  2.46394018e+05 -3.49999895e+00]\n",
      "The elapsed time is 72.35860395431519 s\n",
      "Solution of the primal variables, x\n",
      "x[0] = 141596.36057859357\n",
      "x[1] = -3.5000000349957903\n",
      "x[2] = 101288.50294854354\n",
      "x[3] = -3.500000034982385\n",
      "status= 0\n",
      "Objective value\n",
      "f(x*) = 41.63809118038607\n",
      "Control action=:   -3.5000000349957903 141596.36057859357\n",
      "Real model output x1 x2 in deviation form:    0.4316968257066533 -0.8518870390922844\n",
      "x1_record:  [1.25, 1.246640293570168, 1.2382442859269491, 1.229852842127689, 1.2214658484806795, 1.2130831914531797, 1.2047047576773897, 1.1963304339566099, 1.1879601072715877, 1.1795936647870597, 1.1712309938584944, 1.162870452652845, 1.154484051705587, 1.146061345344306, 1.1376009361649295, 1.1291013963414442, 1.1205612668912097, 1.1119790569185337, 1.103353242835981, 1.094682267562909, 1.085964539700729, 1.0771971920548498, 1.0683557026577277, 1.0594291581050084, 1.0504138216568493, 1.041305832954964, 1.0321012035886898, 1.0227958124732182, 1.0133854010327474, 1.0038655681813164, 0.9942317650941241, 0.9844819949881766, 0.9746610969176838, 0.9647836449754396, 0.9548482399340718, 0.9448534584462907, 0.9347978526476065, 0.9246799497616075, 0.9144982517089132, 0.9042512347210225, 0.8939373489603983, 0.8835558145639533, 0.8731195452002305, 0.8626322918737146, 0.852093067181811, 0.8415008726812999, 0.8308546989248935, 0.8201535255138089, 0.809396321167591, 0.7985820438124897, 0.787709640689778, 0.7767785151770527, 0.7657960771731318, 0.754764327969579, 0.743682490564854, 0.7325497842729881, 0.7213654250167078, 0.7101286256437468, 0.6988385962675769, 0.6874945446338305, 0.6760956765137439, 0.664641508071269, 0.6531369074152625, 0.6415831148300738, 0.6299795158147651, 0.6183254989043709, 0.6066204562039912, 0.5948637839518668, 0.5830548831125466, 0.5711931600012731, 0.5592780269407266, 0.5473105701801579, 0.5353204162853334, 0.5233176185098296, 0.5113022891008107, 0.49927455121539704, 0.48723453918604936, 0.4751823987871023, 0.4631182875021524, 0.451042374791984, 0.438954842362699]\n",
      "x2_record:  [-50, -49.87504872861295, -49.56264781275772, -49.25021040970726, -48.937731518054726, -48.62520614266244, -48.31262929496343, -47.99999599327208, -47.687301263104295, -47.374540137507175, -47.06170765739878, -46.57216981245036, -45.81702921264784, -45.06092444626822, -44.3037838395688, -43.545534209554475, -42.78610082738924, -42.02540738072561, -41.26337593492552, -40.499926893147595, -39.73497895527561, -38.85793416808217, -37.812825974594816, -36.764994290586564, -35.71424931451608, -34.66039510010106, -33.60322933555778, -32.54254311348952, -31.478120691063477, -30.409739240115396, -29.337168586824024, -28.43000134371282, -27.77457206089339, -27.11674318480399, -26.45644401833016, -25.79360266617625, -25.128146015080794, -24.459999714159434, -23.789088155430733, -23.115334454585746, -22.438660432068076, -21.80094534923902, -21.223607370871605, -20.643875544075282, -20.061700352018875, -19.477031729129862, -18.889819062912068, -18.30001119656068, -17.70755643243605, -17.112402536461214, -16.51449674351208, -15.935296727841937, -15.38582095409055, -14.83389711451485, -14.27948651018517, -13.722550258790474, -13.16304930923095, -12.600944457365088, -12.036196362972325, -11.468765567994783, -10.89861251612413, -10.338580281843905, -9.795288537643488, -9.249474297882921, -8.70110715420716, -8.1501568489439, -7.596593301693758, -7.040386637363314, -6.481507215696223, -5.919925662358471, -5.355612901634584, -4.851214316138367, -4.439226933034408, -4.026148242148108, -3.611984985014013, -3.1967444434222116, -2.7804344526372855, -2.363063414674504, -1.94464031161849, -1.5251747189686575, -1.1046768189948046]\n",
      "u1_record:  [-3.500000034998327, -3.500000034998327, -3.500000034998327, -3.500000034998327, -3.500000034998327, -3.500000034998327, -3.500000034998327, -3.500000034998327, -3.500000034998327, -3.500000034998327, -3.500000034999935, -3.500000034999935, -3.500000034999935, -3.500000034999935, -3.500000034999935, -3.500000034999935, -3.500000034999935, -3.500000034999935, -3.500000034999935, -3.500000034999935, -3.500000034999712, -3.500000034999712, -3.500000034999712, -3.500000034999712, -3.500000034999712, -3.500000034999712, -3.500000034999712, -3.500000034999712, -3.500000034999712, -3.500000034999712, -3.5000000350063067, -3.5000000350063067, -3.5000000350063067, -3.5000000350063067, -3.5000000350063067, -3.5000000350063067, -3.5000000350063067, -3.5000000350063067, -3.5000000350063067, -3.5000000350063067, -3.500000034999962, -3.500000034999962, -3.500000034999962, -3.500000034999962, -3.500000034999962, -3.500000034999962, -3.500000034999962, -3.500000034999962, -3.500000034999962, -3.500000034999962, -3.4999998517599575, -3.4999998517599575, -3.4999998517599575, -3.4999998517599575, -3.4999998517599575, -3.4999998517599575, -3.4999998517599575, -3.4999998517599575, -3.4999998517599575, -3.4999998517599575, -3.49999983698992, -3.49999983698992, -3.49999983698992, -3.49999983698992, -3.49999983698992, -3.49999983698992, -3.49999983698992, -3.49999983698992, -3.49999983698992, -3.49999983698992, -3.5000000349957903, -3.5000000349957903, -3.5000000349957903, -3.5000000349957903, -3.5000000349957903, -3.5000000349957903, -3.5000000349957903, -3.5000000349957903, -3.5000000349957903, -3.5000000349957903]\n",
      "u2_record:  [166498.38159398187, 166498.38159398187, 166498.38159398187, 166498.38159398187, 166498.38159398187, 166498.38159398187, 166498.38159398187, 166498.38159398187, 166498.38159398187, 166498.38159398187, 370467.9979771688, 370467.9979771688, 370467.9979771688, 370467.9979771688, 370467.9979771688, 370467.9979771688, 370467.9979771688, 370467.9979771688, 370467.9979771688, 370467.9979771688, 498073.2813559066, 498073.2813559066, 498073.2813559066, 498073.2813559066, 498073.2813559066, 498073.2813559066, 498073.2813559066, 498073.2813559066, 498073.2813559066, 498073.2813559066, 302025.70436042786, 302025.70436042786, 302025.70436042786, 302025.70436042786, 302025.70436042786, 302025.70436042786, 302025.70436042786, 302025.70436042786, 302025.70436042786, 302025.70436042786, 253597.02941362784, 253597.02941362784, 253597.02941362784, 253597.02941362784, 253597.02941362784, 253597.02941362784, 253597.02941362784, 253597.02941362784, 253597.02941362784, 253597.02941362784, 228772.48412558762, 228772.48412558762, 228772.48412558762, 228772.48412558762, 228772.48412558762, 228772.48412558762, 228772.48412558762, 228772.48412558762, 228772.48412558762, 228772.48412558762, 213907.1760144498, 213907.1760144498, 213907.1760144498, 213907.1760144498, 213907.1760144498, 213907.1760144498, 213907.1760144498, 213907.1760144498, 213907.1760144498, 213907.1760144498, 141596.36057859357, 141596.36057859357, 141596.36057859357, 141596.36057859357, 141596.36057859357, 141596.36057859357, 141596.36057859357, 141596.36057859357, 141596.36057859357, 141596.36057859357]\n",
      "time_record:  [136.90255618095398, 56.115288496017456, 95.95012068748474, 103.2247052192688, 78.27881026268005, 126.09077715873718, 114.93159890174866, 72.35860395431519]\n",
      "total time elapsed:  783.852460861206 s\n",
      "average time for each iteration: 97.98155760765076 s\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import pandas\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from scipy.optimize import NonlinearConstraint, LinearConstraint\n",
    "from scipy.optimize import BFGS, minimize, Bounds, SR1\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, SimpleRNN\n",
    "import numpy\n",
    "from keras.models import model_from_json, load_model\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "import pyipopt\n",
    "from numpy import *\n",
    "\n",
    "#####Simulation time step\n",
    "delta=0.005\n",
    "hc=1e-4 #delta/100\n",
    "oper_time=0.01\n",
    "short_factor=int(0.005/delta)\n",
    "\n",
    "####Initial states\n",
    "CAi=1.25\n",
    "Ti=-50\n",
    "x1_nn=CAi\n",
    "x2_nn=Ti\n",
    "x1_record=[CAi]\n",
    "x2_record=[Ti]\n",
    "u1_record=[]\n",
    "u2_record=[]\n",
    "time_record=[]\n",
    "\n",
    "a=1060\n",
    "b=22\n",
    "d=0.52\n",
    "F=5\n",
    "V=1\n",
    "k0=8460000\n",
    "E=50000\n",
    "R=8.314\n",
    "T0=300\n",
    "Dh=-11500\n",
    "rho=1000\n",
    "sigma=1000\n",
    "Cp=0.231\n",
    "cp=0.231\n",
    "Qs=0\n",
    "CA0s=4\n",
    "x_record=[0,0]\n",
    "\n",
    "#steady-state\n",
    "CAs= 1.9537\n",
    "Ts=  401.8727\n",
    "\n",
    "w1_std=2.5\n",
    "w2_std=70\n",
    "state_ss=numpy.array([Ts, CAs])\n",
    "input_ss=numpy.array([Qs, CA0s])\n",
    "ROOT_FOLDER=os.getcwd()\n",
    "\n",
    "#### CONSTANTS ####\n",
    "NUM_MPC_ITERATION=50*short_factor   #10000000000\n",
    "OUTPUT_NO=0\n",
    "TOTAL_MODELS=12 # used to be 8\n",
    "NUM_SUBMODELS=1\n",
    "NUM_OUTPUTS=2\n",
    "NUM_INPUTS=4   #used to be 16\n",
    "HORIZON=2\n",
    "NUM_IN_SEQUENCE=10\n",
    "PREDICTION_STORE=0\n",
    "deviation=0\n",
    "NUM_MPC_INPUTS=2*HORIZON\n",
    "NUM_MPC_CONSTRAINTS=HORIZON\n",
    "realtime_data=None\n",
    "setpoint=[0, 0]\n",
    "\n",
    "def my_ens_prediction(num_horizon,my_rawdata,my_inputs):\n",
    "    xx = []\n",
    "    nn_inputs = []\n",
    "    ensemble_output = numpy.zeros((num_horizon,NUM_OUTPUTS,NUM_IN_SEQUENCE))\n",
    "    ensemble_output = ensemble_output.reshape(num_horizon,NUM_IN_SEQUENCE,NUM_OUTPUTS)\n",
    "    predict_output = []\n",
    "    x_test2 = my_rawdata[0:NUM_OUTPUTS].astype(float)\n",
    "    x_test2= (x_test2-state_mean)/state_std\n",
    "\n",
    "    predict_output_normal=[[0 for i in range(NUM_OUTPUTS)] for j in range(NUM_IN_SEQUENCE)]\n",
    "    for i_model in range(num_horizon):    \n",
    "        COUNT_CORRECT_MODEL=0\n",
    "        my_inputs_normalized = (my_inputs[2*i_model:2*(i_model+1)] - input_mean) / input_std\n",
    "        sum=[[0 for i in range(NUM_OUTPUTS)] for j in range(NUM_IN_SEQUENCE)]\n",
    "        xx = numpy.concatenate((x_test2,  my_inputs_normalized), axis=None).reshape((1, NUM_INPUTS))\n",
    "        xx = numpy.tile(xx, (NUM_IN_SEQUENCE, 1))\n",
    "        nn_inputs = xx.reshape(1, NUM_IN_SEQUENCE, NUM_INPUTS)\n",
    "        for j_submodel in range (NUM_SUBMODELS):\n",
    "            predict_output = numpy.array(model[j_submodel].predict(nn_inputs,verbose=0))\n",
    "            predict_output = predict_output.reshape(NUM_IN_SEQUENCE, NUM_OUTPUTS)\n",
    "            sum=sum+predict_output\n",
    "        # MODEL AVERAGING (ENSEMBLE LEARNING)\n",
    "        predict_output=sum/NUM_SUBMODELS\n",
    "        x_test2=predict_output[-1,0:2]\n",
    "\n",
    "        #########  if delta=0.005##########\n",
    "        x_test2 = predict_output[int(NUM_IN_SEQUENCE/short_factor-1), 0:2]\n",
    "        x_test2=x_test2 * output_std + output_mean\n",
    "        x_test2 = (x_test2 - state_mean) / state_std\n",
    "\n",
    "        # RESCALING BY THE CORRESPONDING STANDARD DEVIATION & THE MEAN OF THE OUTPUT STATISTICS OF THE EXITING SURFACE\n",
    "        predict_output_normal = predict_output * output_std + output_mean\n",
    "        ensemble_output[i_model,:,:]=predict_output_normal\n",
    "\n",
    "    return ensemble_output    \n",
    "\n",
    "#################################################\n",
    "################## MPC PROGRAM ##################\n",
    "#################################################\n",
    "### DEFINE THE UPPER BOUND AND LOWER BOUND OF THE MANIPULATED INPUTS ###\n",
    "\n",
    "def eval_f(x):\n",
    "    assert len(x) == int(NUM_MPC_INPUTS)\n",
    "    offset=0\n",
    "    global PREDICTION_STORE\n",
    "    #### CALCULATE OUTLET CONC ###########\n",
    "    df_ensemble_output = my_ens_prediction(num_horizon=int(NUM_MPC_INPUTS/2),my_rawdata=realtime_data,my_inputs=x)\n",
    "    #### account for all intermediate steps ####\n",
    "    for j in range (int(NUM_MPC_INPUTS/2)):\n",
    "        est_outlet_product = df_ensemble_output[j, :, 0:2]\n",
    "        for i in range (int(NUM_IN_SEQUENCE/short_factor)):  #NUM_IN_SEQUENCE/2\n",
    "             offset = offset + (setpoint[0] - (est_outlet_product[i, 0])) ** 2.0  + (setpoint[1] - (est_outlet_product[i, 1])) ** 2.0 * 1000\n",
    "        offset=offset+x[2*j] **2 *3e-10 + 1* x[2*j+1] **2\n",
    "\n",
    "    return offset/100\n",
    "\n",
    "def eval_grad_f(x):\n",
    "    assert len(x) == int(NUM_MPC_INPUTS)\n",
    "    step = 1e-1 # we just have a small step\n",
    "    objp=objm=0\n",
    "    grad_f = [0]*NUM_MPC_INPUTS\n",
    "    xpstep = [0]*NUM_MPC_INPUTS\n",
    "    xmstep = [0]*NUM_MPC_INPUTS\n",
    "    for i_mpc_input in range(NUM_MPC_INPUTS):\n",
    "        xpstep=x.copy()\n",
    "        xmstep=x.copy()\n",
    "        # for each variables, we need to evaluate the derivative of the function with respect to that variable, This is why we have the for loop\n",
    "        xpstep[i_mpc_input]  = xpstep[i_mpc_input]+step \n",
    "        xmstep[i_mpc_input] = xmstep[i_mpc_input]-step\n",
    "        # Evaluate the objective function at xpstep and xmstep\n",
    "        objp=eval_f(xpstep) # This function returns the value of the objective function evaluated with the variable x[i] is perturebed +step\n",
    "        objm=eval_f(xmstep) # This function returns the value of the objective function evaluated with the variable x[i] is perturebed -step\n",
    "        grad_f[i_mpc_input] = (objp - objm) / (2 * step) # This evaluates the gradient of the objetive function with repect to the optimization variable x[i]\n",
    "    return array(grad_f)\n",
    "\n",
    "def eval_g(x):\n",
    "    assert len(x) == int(NUM_MPC_INPUTS)\n",
    "    #### CALCULATE FLUID TEMPERATURE ALONG THE FIRST THREE SURFACES ###########\n",
    "    CAd2=realtime_data[1]\n",
    "    Td2=realtime_data[0]\n",
    "    g=array([-5.0]*NUM_MPC_CONSTRAINTS)\n",
    " \n",
    "    df_ensemble_output2 = my_ens_prediction(num_horizon=int(NUM_MPC_INPUTS / 2), my_rawdata=realtime_data, my_inputs=x)\n",
    "    for j in range(int(NUM_MPC_INPUTS / 2)):\n",
    "        est_outlet_product2 = df_ensemble_output2[j, int(NUM_IN_SEQUENCE/short_factor-1), 0:2]  #int(NUM_IN_SEQUENCE/2-1)\n",
    "        g[j]= d * (est_outlet_product2[0]) ** 2+ 2 * b * (est_outlet_product2[0])*(est_outlet_product2[1]) + \\\n",
    "              a*(est_outlet_product2[1]) ** 2 - a*CAd2**2 - 2*b*CAd2*Td2 - d*Td2**2\n",
    "\n",
    "    return  g\n",
    "\n",
    "nnzj = NUM_MPC_CONSTRAINTS*NUM_MPC_INPUTS\n",
    "\n",
    "def eval_jac_g(x, flag):\n",
    "    if flag:\n",
    "        list_x = []\n",
    "        list_y=[]\n",
    "        for i in range(int(NUM_MPC_INPUTS / 2)):\n",
    "            list_x = list_x + [i] * NUM_MPC_INPUTS\n",
    "            list_y = list_y +list(range(0, int(NUM_MPC_INPUTS)))\n",
    "        return (array(list_x),\n",
    "                array(list_y))\n",
    "    else:\n",
    "        assert len(x) == int(NUM_MPC_INPUTS)\n",
    "        step = 1e-1 # we just have a small step\n",
    "        gp=gm=numpy.zeros(NUM_MPC_CONSTRAINTS)\n",
    "        xpstep=xmstep=numpy.zeros(NUM_MPC_INPUTS)\n",
    "        jac_g = [[0]*int(NUM_MPC_INPUTS) for _ in range(NUM_MPC_CONSTRAINTS)]\n",
    "        for i_mpc_input in range(NUM_MPC_INPUTS):\n",
    "            xpstep=x.copy()\n",
    "            xmstep=x.copy()\n",
    "            # for each variables, we need to evaluate the derivative of the function with respect to that variable, This is why we have the for loop\n",
    "            xpstep[i_mpc_input] += step \n",
    "            xmstep[i_mpc_input] -= step\n",
    "            gp=eval_g(xpstep)\n",
    "            gm=eval_g(xmstep)\n",
    "            for num_constraint in range(NUM_MPC_CONSTRAINTS):\n",
    "                jac_g[num_constraint][i_mpc_input] = (gp[num_constraint] - gm[num_constraint]) / (2 * step)\n",
    "        return array(jac_g)\n",
    "\n",
    "def apply_new(x):\n",
    "    return True\n",
    "def print_variable(variable_name, value):\n",
    "    for i in range(len(value)):\n",
    "        print(\"{} {}\".format(variable_name + \"[\"+str(i)+\"] =\", value[i]))\n",
    "\n",
    "nnzh = NUM_MPC_INPUTS**2\n",
    "\n",
    "#####################################################################\n",
    "##### PRE-PROCESSING (THE FOLLOWING COMMANDS ARE EXECUTED ONCE) #####\n",
    "#####################################################################\n",
    "#### LOAD MEAN AND STD FILES###########\n",
    "#### READ MEANS & STD FROM THE FILE #####\n",
    "# dataframe_summary= pandas.read_csv(\"train.summary.csv\",   skiprows=1, header=None)\n",
    "# train_summary = dataframe_summary.values\n",
    "# train_summary=train_summary[0:,1:].astype(float)\n",
    "# print (train_summary)\n",
    "\n",
    "# x1_mean=train_summary[1,0]\n",
    "# x1_std=train_summary[1,1]\n",
    "# x2_mean=train_summary[0,0]\n",
    "# x2_std=train_summary[0,1]\n",
    "# u1_mean=train_summary[3,0]\n",
    "# u1_std=train_summary[3,1]\n",
    "# u2_mean=train_summary[2,0]\n",
    "# u2_std=train_summary[2,1]\n",
    "# y1_mean=train_summary[5,0]\n",
    "# y1_std=train_summary[5,1]\n",
    "# y2_mean=train_summary[4,0]\n",
    "# y2_std=train_summary[4,1]\n",
    "x1_mean=1.6712e-02 # CA\n",
    "x1_std=8.4936e-01 \n",
    "x2_mean=-6.1691e-01# T\n",
    "x2_std=3.8528e+01 \n",
    "u1_mean=1.1605e-02   # CA0\n",
    "u1_std=2.6116e+00 \n",
    "u2_mean=1.9277e+02    # Q\n",
    "u2_std=3.7388e+05\n",
    "y1_mean=0.01958    # CA\n",
    "y1_std=0.8453\n",
    "y2_mean=-0.7537  # T\n",
    "y2_std=38.7847\n",
    "state_mean=numpy.array([x2_mean, x1_mean])\n",
    "state_std=numpy.array([x2_std, x1_std])\n",
    "input_mean=numpy.array([u2_mean, u1_mean])\n",
    "input_std=numpy.array([u2_std, u1_std])\n",
    "output_mean=numpy.array([y2_mean, y1_mean])\n",
    "output_std=numpy.array([y2_std, y1_std])\n",
    "\n",
    "model=[1]*(NUM_SUBMODELS) \n",
    "\n",
    "#### LOAD NEURAL NETWORK MODELS ####\n",
    "model[0]=load_model(\"rnn_256_0.h5\")\n",
    "    \n",
    "####################################################################\n",
    "##### SOLVING THE MPC PROGRAM TO FIND THE OPTIMIZED MPC INPUTS #####\n",
    "####################################################################\n",
    "##########  KEEP RUNNING MPC ###############\n",
    "\n",
    "dir_name = os.getcwd()\n",
    "test = os.listdir(dir_name)\n",
    "\n",
    "for item in test:\n",
    "    if item.endswith(\".txt\"):\n",
    "        os.remove(os.path.join(dir_name, item))\n",
    "\n",
    "nvar = NUM_MPC_INPUTS\n",
    "x_lower=[0]* nvar\n",
    "x_upper=[0]* nvar\n",
    "for i in range(int(NUM_MPC_INPUTS/2)):\n",
    "    x_lower[2*i]=-5e5\n",
    "    x_lower[2 * i+1] = -3.5\n",
    "    x_upper[2 * i] = 5e5\n",
    "    x_upper[2 * i + 1] = 3.5\n",
    "x_L = array(x_lower) #array([-5e5, -3.5])\n",
    "x_U = array(x_upper) #array([5e5, 3.5])\n",
    "\n",
    "### DEFINE THE UPPER BOUND AND LOWER BOUND OF THE CONSTRAINT ###\n",
    "ncon = NUM_MPC_CONSTRAINTS\n",
    "g_L = array([-2e19]*HORIZON)\n",
    "g_U = array([0]*HORIZON)\n",
    "\n",
    "print (\"g_L\", g_L, g_U)\n",
    "\n",
    "for main_iteration in range(NUM_MPC_ITERATION):\n",
    "    print (\"Num Iteratin: \", main_iteration)\n",
    "    rawdata=numpy.array([Ti, CAi])\n",
    "    realtime_data=rawdata\n",
    "\n",
    "    start = time.time()\n",
    "    nlp = pyipopt.create(nvar, x_L, x_U, ncon, g_L, g_U, nnzj, nnzh, eval_f, eval_grad_f, eval_g, eval_jac_g)\n",
    "    if main_iteration ==0 :\n",
    "        x0 = array([0.0]*int(NUM_MPC_INPUTS))\n",
    "    else:\n",
    "        x0=x\n",
    "        x0[0:-2]=x[2:]\n",
    "        x0[-2:]=x[-2:]#[0, 0]\n",
    "        x_record=x\n",
    "        \n",
    "    \"\"\"\n",
    "    print x0\n",
    "    print nvar, ncon, nnzj\n",
    "    print x_L,  x_U\n",
    "    print g_L, g_U\n",
    "    print eval_f(x0)\n",
    "    print eval_grad_f(x0)\n",
    "    print eval_g(x0)\n",
    "    a =  eval_jac_g(x0, True)\n",
    "    print \"a = \", a[1], a[0]\n",
    "    print eval_jac_g(x0, False)\n",
    "    print eval_h(x0, pi0, 1.0, False)\n",
    "    print eval_h(x0, pi0, 1.0, True)\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\" You CAd2 set Ipopt options by calling nlp.num_option, nlp.str_option\n",
    "    or nlp.int_option. For instance, to set the tolarance by calling\n",
    "\n",
    "        nlp.num_option('tol', 1e-8)\n",
    "\n",
    "    For a complete list of Ipopt options, refer to\n",
    "\n",
    "        http://www.coin-or.org/Ipopt/documentation/node59.html\n",
    "\n",
    "    Note that Ipopt distinguishs between Int, Num, and Str options, yet sometimes\n",
    "    does not explicitly tell you which option is which.  If you are not sure about\n",
    "    the option's type, just try it in PyIpopt.  If you try to set one type of\n",
    "    option using the wrong function, Pyipopt will remind you of it. \"\"\"\n",
    "    nlp.int_option('max_iter', 100)\n",
    "    nlp.num_option('tol', 1e-5)\n",
    "    nlp.int_option('print_level', 2)\n",
    "    print(\"Going to call solve\")\n",
    "    print(\"x0 = {}\".format(x0))\n",
    "    x, zl, zu, constraint_multipliers, obj, status = nlp.solve(x0)\n",
    "    \n",
    "    nlp.close()\n",
    "    end = time.time()\n",
    "    \n",
    "    print(\"The elapsed time is\", end - start, \"s\")\n",
    "    time_record.append(end-start)\n",
    "\n",
    "    print(\"Solution of the primal variables, x\")\n",
    "    print_variable(\"x\", x)\n",
    "    print (\"status=\", status)\n",
    "    print(\"Objective value\")\n",
    "    print(\"f(x*) = {}\".format(obj))\n",
    "    print (\"Control action=:  \", x[1], x[0])\n",
    "\n",
    "    x1=CAi\n",
    "    x2=Ti\n",
    "\n",
    "    w1 =numpy.random.normal(0, w1_std, 1)\n",
    "    w2 =numpy.random.normal(0, w2_std, 1)\n",
    "    if w1>w1_std:\n",
    "        w1=w1_std\n",
    "    if w1<-w1_std:\n",
    "        w1=-w1_std\n",
    "    if w2>w2_std:\n",
    "        w2=w2_std\n",
    "    if w2>w2_std:\n",
    "        w2=w2_std\n",
    "\n",
    "    for kk in range (int(delta/hc)):\n",
    "        x1_new = x1 + hc * ((F / V) * (x[1] - x1) -\n",
    "                            k0 * ((numpy.exp(-E / (R * (x2 + Ts)))*(x1 + CAs) * (x1 + CAs))\n",
    "                                  - numpy.exp(-E / (R * Ts)) * CAs * CAs))\n",
    "\n",
    "        x2_new = x2 + hc * (((F / V) * (-x2) + (-Dh / (sigma * cp)) *\n",
    "                             (k0 * ((numpy.exp(-E / (R * (x2 + Ts))) * (x1 + CAs) * (x1 + CAs)) -\n",
    "                                      numpy.exp(-E / (R * Ts)) * CAs * CAs)) + (x[0] / (sigma * cp * V))))\n",
    "\n",
    "        x1 = x1_new\n",
    "        x2 = x2_new\n",
    "\n",
    "        if (kk%5==1):\n",
    "            x1_record.append(x1)\n",
    "            x2_record.append(x2)\n",
    "            u1_record.append(x[1])\n",
    "            u2_record.append(x[0])\n",
    "\n",
    "    CAi=x1\n",
    "    Ti=x2\n",
    "\n",
    "    print('Real model output x1 x2 in deviation form:   ', x1, x2)\n",
    "    \n",
    "    if sum(time_record) > 720:\n",
    "        break\n",
    "\n",
    "print (\"x1_record: \",x1_record)\n",
    "print (\"x2_record: \",x2_record)\n",
    "\n",
    "print (\"u1_record: \",u1_record)\n",
    "print (\"u2_record: \",u2_record)\n",
    "\n",
    "print(\"time_record: \", time_record)\n",
    "print(\"total time elapsed: \", sum(time_record), 's')\n",
    "print(\"average time for each iteration:\", sum(time_record)/len(time_record), 's')\n",
    "\n",
    "numpy.savetxt(\"x1.txt\",   x1_record, fmt=\"%f\",  delimiter=\" \")\n",
    "numpy.savetxt(\"x2.txt\",   x2_record, fmt=\"%f\",  delimiter=\" \")\n",
    "\n",
    "numpy.savetxt(\"u1.txt\",   u1_record, fmt=\"%f\",  delimiter=\" \")\n",
    "numpy.savetxt(\"u2.txt\",   u2_record, fmt=\"%f\",  delimiter=\" \")\n",
    "numpy.savetxt(\"time_RNN.txt\",   time_record, fmt=\"%f\",  delimiter=\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
