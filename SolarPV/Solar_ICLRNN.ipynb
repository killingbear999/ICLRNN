{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b32b68",
   "metadata": {
    "executionInfo": {
     "elapsed": 4491,
     "status": "ok",
     "timestamp": 1700023650790,
     "user": {
      "displayName": "Wang Zihao",
      "userId": "13688795653924779981"
     },
     "user_tz": -480
    },
    "id": "40b32b68"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, Input, Activation, Dropout, Add, LSTM, GRU, RNN, LayerNormalization, BatchNormalization, Conv1D, MaxPooling1D, Flatten, Layer\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam,SGD\n",
    "import tensorflow as tf\n",
    "from keras import Model, regularizers, activations\n",
    "from keras.constraints import Constraint\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5010c574",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_BETA_BJORCK = 0.5\n",
    "DEFAULT_EPS_SPECTRAL = 1e-3\n",
    "DEFAULT_EPS_BJORCK = 1e-3\n",
    "DEFAULT_MAXITER_BJORCK = 15\n",
    "DEFAULT_MAXITER_SPECTRAL = 10\n",
    "SWAP_MEMORY = True\n",
    "STOP_GRAD_SPECTRAL = True\n",
    "\n",
    "def reshaped_kernel_orthogonalization(\n",
    "    kernel,\n",
    "    u,\n",
    "    adjustment_coef,\n",
    "    eps_spectral=DEFAULT_EPS_SPECTRAL,\n",
    "    eps_bjorck=DEFAULT_EPS_BJORCK,\n",
    "    beta=DEFAULT_BETA_BJORCK,\n",
    "    maxiter_spectral=DEFAULT_MAXITER_SPECTRAL,\n",
    "    maxiter_bjorck=DEFAULT_MAXITER_BJORCK,\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform reshaped kernel orthogonalization (RKO) to the kernel given as input. It\n",
    "    apply the power method to find the largest singular value and apply the Bjorck\n",
    "    algorithm to the rescaled kernel. This greatly improve the stability and and\n",
    "    speed convergence of the bjorck algorithm.\n",
    "\n",
    "    Args:\n",
    "        kernel (tf.Tensor): the kernel to orthogonalize\n",
    "        u (tf.Tensor): the vector used to do the power iteration method\n",
    "        adjustment_coef (float): the adjustment coefficient as used in convolution\n",
    "        eps_spectral (float): stopping criterion in spectral algorithm\n",
    "        eps_bjorck (float): stopping criterion in bjorck algorithm\n",
    "        beta (float): the beta used in the bjorck algorithm\n",
    "        maxiter_spectral (int): maximum number of iterations for the power iteration\n",
    "        maxiter_bjorck (int): maximum number of iterations for bjorck algorithm\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: the orthogonalized kernel, the new u, and sigma which is the largest\n",
    "            singular value\n",
    "\n",
    "    Reference:\n",
    "        Serrurier, M., Mamalet, F., González-Sanz, A., Boissin, T., Loubes, J. M., & Del Barrio, E. (2021). \n",
    "        Achieving robustness in classification using optimal transport with hinge regularization. \n",
    "        In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 505-514).\n",
    "        \n",
    "    \"\"\"\n",
    "    W_shape = kernel.shape\n",
    "    # Flatten the Tensor\n",
    "    W_reshaped = tf.reshape(kernel, [-1, W_shape[-1]])\n",
    "    W_bar, u, sigma = spectral_normalization(\n",
    "        W_reshaped, u, eps=eps_spectral, maxiter=maxiter_spectral\n",
    "    )\n",
    "    if (eps_bjorck is not None) and (beta is not None):\n",
    "        W_bar = bjorck_normalization(\n",
    "            W_bar, eps=eps_bjorck, beta=beta, maxiter=maxiter_bjorck\n",
    "        )\n",
    "    W_bar = W_bar * adjustment_coef\n",
    "    W_bar = K.reshape(W_bar, kernel.shape)\n",
    "    return W_bar, u, sigma\n",
    "\n",
    "\n",
    "def _wwtw(w):\n",
    "    if w.shape[0] > w.shape[1]:\n",
    "        return w @ (tf.transpose(w) @ w)\n",
    "    else:\n",
    "        return (w @ tf.transpose(w)) @ w\n",
    "\n",
    "\n",
    "def bjorck_normalization(\n",
    "    w, eps=DEFAULT_EPS_BJORCK, beta=DEFAULT_BETA_BJORCK, maxiter=DEFAULT_MAXITER_BJORCK\n",
    "):\n",
    "    \"\"\"\n",
    "    apply Bjorck normalization on w.\n",
    "\n",
    "    Args:\n",
    "        w (tf.Tensor): weight to normalize, in order to work properly, we must have\n",
    "            max_eigenval(w) ~= 1\n",
    "        eps (float): epsilon stopping criterion: norm(wt - wt-1) must be less than eps\n",
    "        beta (float): beta used in each iteration, must be in the interval ]0, 0.5]\n",
    "        maxiter (int): maximum number of iterations for the algorithm\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: the orthonormal weights\n",
    "\n",
    "    Reference:\n",
    "        Serrurier, M., Mamalet, F., González-Sanz, A., Boissin, T., Loubes, J. M., & Del Barrio, E. (2021). \n",
    "        Achieving robustness in classification using optimal transport with hinge regularization. \n",
    "        In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 505-514).\n",
    "        \n",
    "    \"\"\"\n",
    "    # create a fake old_w that does'nt pass the loop condition\n",
    "    # it won't affect computation as the first action done in the loop overwrite it.\n",
    "    old_w = 10 * w\n",
    "    # define the loop condition\n",
    "\n",
    "    def cond(w, old_w):\n",
    "        return tf.linalg.norm(w - old_w) >= eps\n",
    "\n",
    "    # define the loop body\n",
    "    def body(w, old_w):\n",
    "        old_w = w\n",
    "        w = (1 + beta) * w - beta * _wwtw(w)\n",
    "        return w, old_w\n",
    "\n",
    "    # apply the loop\n",
    "    w, old_w = tf.while_loop(\n",
    "        cond,\n",
    "        body,\n",
    "        (w, old_w),\n",
    "        parallel_iterations=30,\n",
    "        maximum_iterations=maxiter,\n",
    "        swap_memory=SWAP_MEMORY,\n",
    "    )\n",
    "    return w\n",
    "\n",
    "\n",
    "def _power_iteration(\n",
    "    linear_operator,\n",
    "    adjoint_operator,\n",
    "    u,\n",
    "    eps=DEFAULT_EPS_SPECTRAL,\n",
    "    maxiter=DEFAULT_MAXITER_SPECTRAL,\n",
    "    axis=None,\n",
    "):\n",
    "    \"\"\"Internal function that performs the power iteration algorithm to estimate the\n",
    "    largest singular vector of a linear operator.\n",
    "\n",
    "    Args:\n",
    "        linear_operator (Callable): a callable object that maps a linear operation.\n",
    "        adjoint_operator (Callable): a callable object that maps the adjoint of the\n",
    "            linear operator.\n",
    "        u (tf.Tensor): initialization of the singular vector.\n",
    "        eps (float, optional): stopping criterion of the algorithm, when\n",
    "            norm(u[t] - u[t-1]) is less than eps. Defaults to DEFAULT_EPS_SPECTRAL.\n",
    "        maxiter (int, optional): maximum number of iterations for the algorithm.\n",
    "            Defaults to DEFAULT_MAXITER_SPECTRAL.\n",
    "        axis (int/list, optional): dimension along which to normalize. Can be set for\n",
    "            depthwise convolution for example. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: the maximum singular vector.\n",
    "    \n",
    "    Reference:\n",
    "        Serrurier, M., Mamalet, F., González-Sanz, A., Boissin, T., Loubes, J. M., & Del Barrio, E. (2021). \n",
    "        Achieving robustness in classification using optimal transport with hinge regularization. \n",
    "        In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 505-514).\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare while loop variables\n",
    "    u = tf.math.l2_normalize(u, axis=axis)\n",
    "    # create a fake old_w that doesn't pass the loop condition, it will be overwritten\n",
    "    old_u = u + 2 * eps\n",
    "\n",
    "    # Loop body\n",
    "    def body(u, old_u):\n",
    "        old_u = u\n",
    "        v = linear_operator(u)\n",
    "        u = adjoint_operator(v)\n",
    "\n",
    "        u = tf.math.l2_normalize(u, axis=axis)\n",
    "\n",
    "        return u, old_u\n",
    "\n",
    "    # Loop stopping condition\n",
    "    def cond(u, old_u):\n",
    "        return tf.linalg.norm(u - old_u) >= eps\n",
    "\n",
    "    # Run the while loop\n",
    "    u, _ = tf.while_loop(\n",
    "        cond,\n",
    "        body,\n",
    "        (u, old_u),\n",
    "        maximum_iterations=maxiter,\n",
    "        swap_memory=SWAP_MEMORY,\n",
    "    )\n",
    "\n",
    "    # Prevent gradient to back-propagate into the while loop\n",
    "    if STOP_GRAD_SPECTRAL:\n",
    "        u = tf.stop_gradient(u)\n",
    "\n",
    "    return u\n",
    "\n",
    "\n",
    "def spectral_normalization(\n",
    "    kernel, u, eps=DEFAULT_EPS_SPECTRAL, maxiter=DEFAULT_MAXITER_SPECTRAL\n",
    "):\n",
    "    \"\"\"\n",
    "    Normalize the kernel to have its maximum singular value equal to 1.\n",
    "\n",
    "    Args:\n",
    "        kernel (tf.Tensor): the kernel to normalize, assuming a 2D kernel.\n",
    "        u (tf.Tensor): initialization of the maximum singular vector.\n",
    "        eps (float, optional): stopping criterion of the algorithm, when\n",
    "            norm(u[t] - u[t-1]) is less than eps. Defaults to DEFAULT_EPS_SPECTRAL.\n",
    "        maxiter (int, optional): maximum number of iterations for the algorithm.\n",
    "            Defaults to DEFAULT_MAXITER_SPECTRAL.\n",
    "\n",
    "    Returns:\n",
    "        the normalized kernel, the maximum singular vector, and the maximum singular\n",
    "            value.\n",
    "\n",
    "    Reference:\n",
    "        Serrurier, M., Mamalet, F., González-Sanz, A., Boissin, T., Loubes, J. M., & Del Barrio, E. (2021). \n",
    "        Achieving robustness in classification using optimal transport with hinge regularization. \n",
    "        In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 505-514).\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    if u is None:\n",
    "        u = tf.random.uniform(\n",
    "            shape=(1, kernel.shape[-1]), minval=0.0, maxval=1.0, dtype=kernel.dtype\n",
    "        )\n",
    "\n",
    "    def linear_op(u):\n",
    "        return u @ tf.transpose(kernel)\n",
    "\n",
    "    def adjoint_op(v):\n",
    "        return v @ kernel\n",
    "\n",
    "    u = _power_iteration(linear_op, adjoint_op, u, eps, maxiter)\n",
    "\n",
    "    # Compute the largest singular value and the normalized kernel.\n",
    "    # We assume that in the worst case we converged to sigma + eps (as u and v are\n",
    "    # normalized after each iteration)\n",
    "    # In order to be sure that operator norm of normalized kernel is strictly less than\n",
    "    # one we use sigma + eps, which ensures stability of Björck algorithm even when\n",
    "    # beta=0.5\n",
    "    sigma = tf.reshape(tf.norm(linear_op(u)), (1, 1))\n",
    "    normalized_kernel = kernel / (sigma + eps)\n",
    "    return normalized_kernel, u, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edcfffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralConstraint(Constraint):\n",
    "    def __init__(\n",
    "        self,\n",
    "        k_coef_lip=1.0,\n",
    "        eps_spectral=DEFAULT_EPS_SPECTRAL,\n",
    "        eps_bjorck=DEFAULT_EPS_BJORCK,\n",
    "        beta_bjorck=DEFAULT_BETA_BJORCK,\n",
    "        u=None,\n",
    "    ) -> None:\n",
    "        \n",
    "        \"\"\"\n",
    "        Ensure that *all* singular values of the weight matrix equals to 1. Computation\n",
    "        based on Bjorck algorithm. The computation is done in two steps:\n",
    "\n",
    "        1. reduce the larget singular value to k_coef_lip, using iterate power method.\n",
    "        2. increase other singular values to k_coef_lip, using bjorck algorithm.\n",
    "\n",
    "        Args:\n",
    "            k_coef_lip (float): lipschitz coefficient of the weight matrix\n",
    "            eps_spectral (float): stopping criterion for the iterative power algorithm.\n",
    "            eps_bjorck (float): stopping criterion Bjorck algorithm.\n",
    "            beta_bjorck (float): beta parameter in bjorck algorithm.\n",
    "            u (tf.Tensor): vector used for iterated power method, can be set to None\n",
    "                (used for serialization/deserialization purposes).\n",
    "\n",
    "        Reference:\n",
    "            Serrurier, M., Mamalet, F., González-Sanz, A., Boissin, T., Loubes, J. M., & Del Barrio, E. (2021). \n",
    "            Achieving robustness in classification using optimal transport with hinge regularization. \n",
    "            In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 505-514).\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        self.eps_spectral = eps_spectral\n",
    "        self.eps_bjorck = eps_bjorck\n",
    "        self.beta_bjorck = beta_bjorck\n",
    "        self.k_coef_lip = k_coef_lip\n",
    "        if not (isinstance(u, tf.Tensor) or (u is None)):\n",
    "            u = tf.convert_to_tensor(u)\n",
    "        self.u = u\n",
    "        super(SpectralConstraint, self).__init__()\n",
    "\n",
    "    def __call__(self, w):\n",
    "        # make the largest singular value of W to be 1\n",
    "        wbar, _, _ = reshaped_kernel_orthogonalization(\n",
    "            w,\n",
    "            self.u,\n",
    "            self.k_coef_lip,\n",
    "            self.eps_spectral,\n",
    "            self.eps_bjorck,\n",
    "            self.beta_bjorck,\n",
    "        )\n",
    "\n",
    "        # clip to ensure non-negative weight\n",
    "        wbar = K.clip(wbar, 0, wbar)\n",
    "        return wbar\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            \"k_coef_lip\": self.k_coef_lip,\n",
    "            \"eps_spectral\": self.eps_spectral,\n",
    "            \"eps_bjorck\": self.eps_bjorck,\n",
    "            \"beta_bjorck\": self.beta_bjorck,\n",
    "            \"u\": None if self.u is None else self.u.numpy(),\n",
    "        }\n",
    "        base_config = super(SpectralConstraint, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ZA508QJqv8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "executionInfo": {
     "elapsed": 1355,
     "status": "error",
     "timestamp": 1700023674308,
     "user": {
      "displayName": "Wang Zihao",
      "userId": "13688795653924779981"
     },
     "user_tz": -480
    },
    "id": "38ZA508QJqv8",
    "outputId": "0ea8a487-50d4-48d7-fb80-a2272be53469"
   },
   "outputs": [],
   "source": [
    "# set the seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "X_train = np.load(\"data/X_train.npy\")\n",
    "X_test = np.load(\"data/X_test.npy\")\n",
    "y_train = np.load(\"data/y_train.npy\")\n",
    "y_test_normalized = np.load(\"data/y_test_normalized.npy\")\n",
    "\n",
    "input = Input(shape=(X_train.shape[1],X_train.shape[2]))\n",
    "x = SimpleRNN(64, activation='relu', return_sequences=True, kernel_constraint=SpectralConstraint(), recurrent_constraint=SpectralConstraint())(input) \n",
    "x = SimpleRNN(64, activation='relu', return_sequences=False, kernel_constraint=SpectralConstraint(), recurrent_constraint=SpectralConstraint())(x) \n",
    "x = LayerNormalization()(x)  \n",
    "x = Dense(2, activation='linear', kernel_constraint=tf.keras.constraints.NonNeg())(x)\n",
    "model = Model(input, x)\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=256, validation_split=0.25, verbose=2)\n",
    "training_loss = history.history['val_loss'][-1]\n",
    "print(training_loss)\n",
    "\n",
    "loss = model.evaluate(X_test, y_test_normalized, batch_size=256)\n",
    "test_loss = loss[0]\n",
    "print(test_loss)\n",
    "\n",
    "name = 'iclrnn_64_'\n",
    "name = name + '.h5'\n",
    "model.save(name)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aW5-RgMJSvgX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7607,
     "status": "ok",
     "timestamp": 1700023694468,
     "user": {
      "displayName": "Wang Zihao",
      "userId": "13688795653924779981"
     },
     "user_tz": -480
    },
    "id": "aW5-RgMJSvgX",
    "outputId": "74b5b069-23d2-4851-8da0-8ec552f0a195"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2_as_graph\n",
    "\n",
    "def get_flops(model):\n",
    "    concrete = tf.function(lambda inputs: model(inputs))\n",
    "    concrete_func = concrete.get_concrete_function(\n",
    "        [tf.TensorSpec([1, *inputs.shape[1:]]) for inputs in model.inputs])\n",
    "    frozen_func, graph_def = convert_variables_to_constants_v2_as_graph(concrete_func, lower_control_flow=False)\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.graph_util.import_graph_def(graph_def, name='')\n",
    "        run_meta = tf.compat.v1.RunMetadata()\n",
    "        opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "        flops = tf.compat.v1.profiler.profile(graph=graph, run_meta=run_meta, cmd=\"op\", options=opts)\n",
    "        return flops.total_float_ops\n",
    "\n",
    "print(\"The FLOPs is:{}\".format(get_flops(model)),flush=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UrrPBiGgK_2E",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12086,
     "status": "ok",
     "timestamp": 1700023708574,
     "user": {
      "displayName": "Wang Zihao",
      "userId": "13688795653924779981"
     },
     "user_tz": -480
    },
    "id": "UrrPBiGgK_2E",
    "outputId": "8d40c693-11bd-459e-969e-d655de8d8140"
   },
   "outputs": [],
   "source": [
    "X_train = np.load(\"data/X_train.npy\")\n",
    "X_test = np.load(\"data/X_test.npy\")\n",
    "y_train = np.load(\"data/y_train.npy\")\n",
    "y_test_normalized = np.load(\"data/y_test_normalized.npy\")\n",
    "y_test = np.load(\"data/y_test.npy\")\n",
    "\n",
    "scaler_X = pickle.load(open(\"data/scalar_X.sav\", 'rb'))\n",
    "scaler_y = pickle.load(open(\"data/scalar_y.sav\", 'rb'))\n",
    "model = tf.keras.models.load_model('iclrnn_256_0.h5', custom_objects={'SpectralConstraint': SpectralConstraint})\n",
    "\n",
    "y_predict = model.predict(X_test)\n",
    "print(y_predict.shape)\n",
    "\n",
    "y_predict = y_predict.reshape(-1,2)\n",
    "y_predict = scaler_y.inverse_transform(y_predict)\n",
    "y_predict = y_predict.reshape(-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rtB5bHP0LuD6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2035,
     "status": "ok",
     "timestamp": 1700023828845,
     "user": {
      "displayName": "Wang Zihao",
      "userId": "13688795653924779981"
     },
     "user_tz": -480
    },
    "id": "rtB5bHP0LuD6",
    "outputId": "f258a86a-bdf8-412c-ba78-83c82d5dad09"
   },
   "outputs": [],
   "source": [
    "# color code: \"#E69F00\", \"#56B4E9\", \"#009E73\", \"#0072B2\", \"#D55E00\", \"#CC79A7\", \"#F0E442\"\n",
    "plt.figure(figsize=(16, 5))\n",
    "plt.plot(y_predict[:,0], color=\"#E69F00\", label='Predicted')\n",
    "plt.plot(y_test[:,0], color=\"#56B4E9\", label='Test')\n",
    "plt.title(\"SI north\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16, 5))\n",
    "plt.plot(y_predict[:,1], color=\"#009E73\", label='Predicted')\n",
    "plt.plot(y_test[:,1], color=\"#0072B2\", label='Test')\n",
    "plt.title(\"SI south\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16, 5))\n",
    "plt.plot(y_predict[19700:20700,0], color=\"#E69F00\", label='Predicted')\n",
    "plt.plot(y_test[19700:20700,0], color=\"#56B4E9\", label='Test')\n",
    "plt.title(\"SI north\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16, 5))\n",
    "plt.plot(y_predict[19700:20700,1], color=\"#009E73\", label='Predicted')\n",
    "plt.plot(y_test[19700:20700,1], color=\"#0072B2\", label='Test')\n",
    "plt.title(\"SI south\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45219e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply to unseen data\n",
    "# 2023-12-28\n",
    "data_new = pd.read_csv('data/2023-12/[170] 2023-12-28.txt',sep='\t')\n",
    "\n",
    "SI_data = data_new[['Tm', 'AvgGmod05_N_1','AvgGmod05_S_1', 'AvgHamb_1', 'AvgTamb_1', 'AvgTmod05_N_1', 'AvgTmod05_S_1', 'AvgWindS_1', 'AvgWindD_1']]\n",
    "SI_data = SI_data.set_index('Tm')\n",
    "\n",
    "SI_north = SI_data['AvgGmod05_N_1'].to_numpy()\n",
    "SI_south = SI_data['AvgGmod05_S_1'].to_numpy()\n",
    "Ambient_humidity = SI_data['AvgHamb_1'].to_numpy()\n",
    "Ambient_temp = SI_data['AvgTamb_1'].to_numpy()\n",
    "Temp_north = SI_data['AvgTmod05_N_1'].to_numpy()\n",
    "Temp_south = SI_data['AvgTmod05_S_1'].to_numpy()\n",
    "Wind_speed = SI_data['AvgWindS_1'].to_numpy()\n",
    "Wind_direction = SI_data['AvgWindD_1'].to_numpy()\n",
    "\n",
    "def generate_data(data):\n",
    "  win_length = 15\n",
    "  count = 0\n",
    "  data_train = []\n",
    "  data_test = []\n",
    "  while count < len(data):\n",
    "    if count + win_length + 1 < len(data):\n",
    "      data_train.append(data[count:count+win_length])\n",
    "      data_test.append(data[count+win_length+1])\n",
    "      count = count + 1\n",
    "    else:\n",
    "      break\n",
    "  return np.array(data_train).reshape(-1, win_length, 1), np.array(data_test).reshape(-1, 1)\n",
    "\n",
    "SI_north_train, SI_north_test = generate_data(SI_north)\n",
    "SI_south_train, SI_south_test = generate_data(SI_south)\n",
    "Ambient_humidity_train, Ambient_humidity_test = generate_data(Ambient_humidity)\n",
    "Ambient_temp_train, Ambient_temp_test = generate_data(Ambient_temp)\n",
    "Temp_north_train, Temp_north_test = generate_data(Temp_north)\n",
    "Temp_south_train, Temp_south_test = generate_data(Temp_south)\n",
    "Wind_speed_train, Wind_speed_test = generate_data(Wind_speed)\n",
    "Wind_direction_train, Wind_direction_test = generate_data(Wind_direction)\n",
    "\n",
    "data_train = np.concatenate([SI_south_train, SI_north_train, Ambient_humidity_train, Ambient_temp_train, Temp_north_train, Temp_south_train, Wind_speed_train, Wind_direction_train], axis=2)\n",
    "data_test = np.concatenate([SI_south_test, SI_north_test], axis=1)\n",
    "\n",
    "win_length = 15\n",
    "X = scaler_X.transform(data_train.reshape(-1, 8)).reshape(-1, win_length, 8)\n",
    "y = scaler_y.transform(data_test.reshape(-1, 2)).reshape(-1, 2)\n",
    "\n",
    "y_predict = model.predict(X)\n",
    "\n",
    "y_predict = y_predict.reshape(-1,2)\n",
    "y_predict = scaler_y.inverse_transform(y_predict)\n",
    "y_predict = y_predict.reshape(-1,2)\n",
    "\n",
    "loss = model.evaluate(X, y, batch_size=256)\n",
    "print('loss: ', loss)\n",
    "\n",
    "# color code: \"#E69F00\", \"#56B4E9\", \"#009E73\", \"#0072B2\", \"#D55E00\", \"#CC79A7\", \"#F0E442\"\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.rc('font', size=20)\n",
    "plt.plot(y_predict[:,0], color=\"#E69F00\", label='Predicted')\n",
    "plt.plot(data_test[:,0], color=\"#56B4E9\", label='Test')\n",
    "# plt.title(\"SI north\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Magnitude\")\n",
    "plt.margins(x=0)\n",
    "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.savefig('si_north_iclrnn_256_testing.pdf')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_predict[:,1], color=\"#0072B2\", label='Predicted')\n",
    "plt.plot(data_test[:,1], color=\"#D55E00\", label='Test')\n",
    "# plt.title(\"SI south\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Magnitude\")\n",
    "plt.margins(x=0)\n",
    "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.savefig('si_south_iclrnn_256_testing.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ac6016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply to unseen data\n",
    "# 2024-01-01\n",
    "data_new = pd.read_csv('data/2024-01/[170] 2024-01-01.txt',sep='\t')\n",
    "\n",
    "SI_data = data_new[['Tm', 'AvgGmod05_N_1','AvgGmod05_S_1', 'AvgHamb_1', 'AvgTamb_1', 'AvgTmod05_N_1', 'AvgTmod05_S_1', 'AvgWindS_1', 'AvgWindD_1']]\n",
    "SI_data = SI_data.set_index('Tm')\n",
    "\n",
    "SI_north = SI_data['AvgGmod05_N_1'].to_numpy()\n",
    "SI_south = SI_data['AvgGmod05_S_1'].to_numpy()\n",
    "Ambient_humidity = SI_data['AvgHamb_1'].to_numpy()\n",
    "Ambient_temp = SI_data['AvgTamb_1'].to_numpy()\n",
    "Temp_north = SI_data['AvgTmod05_N_1'].to_numpy()\n",
    "Temp_south = SI_data['AvgTmod05_S_1'].to_numpy()\n",
    "Wind_speed = SI_data['AvgWindS_1'].to_numpy()\n",
    "Wind_direction = SI_data['AvgWindD_1'].to_numpy()\n",
    "\n",
    "def generate_data(data):\n",
    "  win_length = 15\n",
    "  count = 0\n",
    "  data_train = []\n",
    "  data_test = []\n",
    "  while count < len(data):\n",
    "    if count + win_length + 1 < len(data):\n",
    "      data_train.append(data[count:count+win_length])\n",
    "      data_test.append(data[count+win_length+1])\n",
    "      count = count + 1\n",
    "    else:\n",
    "      break\n",
    "  return np.array(data_train).reshape(-1, win_length, 1), np.array(data_test).reshape(-1, 1)\n",
    "\n",
    "SI_north_train, SI_north_test = generate_data(SI_north)\n",
    "SI_south_train, SI_south_test = generate_data(SI_south)\n",
    "Ambient_humidity_train, Ambient_humidity_test = generate_data(Ambient_humidity)\n",
    "Ambient_temp_train, Ambient_temp_test = generate_data(Ambient_temp)\n",
    "Temp_north_train, Temp_north_test = generate_data(Temp_north)\n",
    "Temp_south_train, Temp_south_test = generate_data(Temp_south)\n",
    "Wind_speed_train, Wind_speed_test = generate_data(Wind_speed)\n",
    "Wind_direction_train, Wind_direction_test = generate_data(Wind_direction)\n",
    "\n",
    "data_train = np.concatenate([SI_south_train, SI_north_train, Ambient_humidity_train, Ambient_temp_train, Temp_north_train, Temp_south_train, Wind_speed_train, Wind_direction_train], axis=2)\n",
    "data_test = np.concatenate([SI_south_test, SI_north_test], axis=1)\n",
    "\n",
    "win_length = 15\n",
    "X = scaler_X.transform(data_train.reshape(-1, 8)).reshape(-1, win_length, 8)\n",
    "y = scaler_y.transform(data_test.reshape(-1, 2)).reshape(-1, 2)\n",
    "\n",
    "y_predict = model.predict(X)\n",
    "\n",
    "y_predict = y_predict.reshape(-1,2)\n",
    "y_predict = scaler_y.inverse_transform(y_predict)\n",
    "y_predict = y_predict.reshape(-1,2)\n",
    "\n",
    "loss = model.evaluate(X, y, batch_size=256)\n",
    "print('loss: ', loss)\n",
    "\n",
    "# color code: \"#E69F00\", \"#56B4E9\", \"#009E73\", \"#0072B2\", \"#D55E00\", \"#CC79A7\", \"#F0E442\"\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.rc('font', size=20)\n",
    "plt.plot(y_predict[:,0], color=\"#E69F00\", label='Predicted')\n",
    "plt.plot(data_test[:,0], color=\"#56B4E9\", label='Test')\n",
    "# plt.title(\"SI north\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Magnitude\")\n",
    "plt.margins(x=0)\n",
    "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.savefig('si_north_iclrnn_256_unseen.pdf')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_predict[:,1], color=\"#0072B2\", label='Predicted')\n",
    "plt.plot(data_test[:,1], color=\"#D55E00\", label='Test')\n",
    "# plt.title(\"SI south\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Magnitude\")\n",
    "plt.margins(x=0)\n",
    "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.savefig('si_south_iclrnn_256_unseen.pdf')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
