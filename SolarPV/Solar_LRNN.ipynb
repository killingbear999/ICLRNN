{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b32b68",
   "metadata": {
    "executionInfo": {
     "elapsed": 4491,
     "status": "ok",
     "timestamp": 1700023650790,
     "user": {
      "displayName": "Wang Zihao",
      "userId": "13688795653924779981"
     },
     "user_tz": -480
    },
    "id": "40b32b68"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, Input, Activation, Dropout, Add, LSTM, GRU, RNN, LayerNormalization, BatchNormalization, Conv1D, MaxPooling1D, Flatten, Layer\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam,SGD\n",
    "import tensorflow as tf\n",
    "from keras import Model, regularizers, activations\n",
    "from keras.constraints import Constraint\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a290c542",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLRNNCell(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, units, eps=0.01, gamma=0.01, beta=0.8, alpha=1, **kwargs):\n",
    "        self.units = units\n",
    "        self.state_size = units\n",
    "        self.I = tf.eye(units)\n",
    "        self.eps = eps\n",
    "        self.gamma = gamma\n",
    "        self.beta = beta\n",
    "        self.alpha = alpha\n",
    "        super(MyLRNNCell, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.C = self.add_weight(shape=(self.units, self.units),\n",
    "                                      initializer='random_normal',\n",
    "                                      name='C',\n",
    "                                      trainable=True)\n",
    "        self.B = self.add_weight(shape=(self.units, self.units),\n",
    "                                                initializer='random_normal',\n",
    "                                                name='B',\n",
    "                                                trainable=True)\n",
    "        self.U = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                                initializer='random_normal',\n",
    "                                                name='U',\n",
    "                                                trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.units,),\n",
    "                                    initializer='zeros',\n",
    "                                    name='b',\n",
    "                                    trainable=True)\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, states):\n",
    "        prev_h = states[0]\n",
    "\n",
    "        A = self.beta * (self.B - tf.transpose(self.B)) + (1 - self.beta) * (self.B + tf.transpose(self.B)) - self.gamma * self.I\n",
    "        W = self.beta * (self.C - tf.transpose(self.C)) + (1 - self.beta) * (self.C + tf.transpose(self.C)) - self.gamma * self.I\n",
    "\n",
    "        h = prev_h + self.eps * self.alpha * K.dot(prev_h, A) + self.eps * tf.nn.tanh(K.dot(prev_h, W) + K.dot(inputs, self.U) + self.b)\n",
    "        return h, [h]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(MyLRNNCell, self).get_config()\n",
    "        config.update({\"units\": self.units, \"eps\":self.eps, \"gamma\":self.gamma, \"beta\":self.beta, \"alpha\":self.alpha})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ZA508QJqv8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "executionInfo": {
     "elapsed": 1355,
     "status": "error",
     "timestamp": 1700023674308,
     "user": {
      "displayName": "Wang Zihao",
      "userId": "13688795653924779981"
     },
     "user_tz": -480
    },
    "id": "38ZA508QJqv8",
    "outputId": "0ea8a487-50d4-48d7-fb80-a2272be53469"
   },
   "outputs": [],
   "source": [
    "# set the seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "X_train = np.load(\"data/X_train.npy\")\n",
    "X_test = np.load(\"data/X_test.npy\")\n",
    "y_train = np.load(\"data/y_train.npy\")\n",
    "y_test_normalized = np.load(\"data/y_test_normalized.npy\")\n",
    "\n",
    "model = Sequential()\n",
    "model.add(RNN(MyLRNNCell(units=64),return_sequences=True))\n",
    "model.add(RNN(MyLRNNCell(units=64),return_sequences=False))\n",
    "model.add(Dense(2, activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=256, validation_split=0.25, verbose=2)\n",
    "training_loss = history.history['val_loss'][-1]\n",
    "print(training_loss)\n",
    "\n",
    "loss = model.evaluate(X_test, y_test_normalized, batch_size=256)\n",
    "test_loss = loss[0]\n",
    "print(test_loss)\n",
    "\n",
    "name = 'lrnn_64_'\n",
    "name = name + '.h5'\n",
    "model.save(name)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aW5-RgMJSvgX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7607,
     "status": "ok",
     "timestamp": 1700023694468,
     "user": {
      "displayName": "Wang Zihao",
      "userId": "13688795653924779981"
     },
     "user_tz": -480
    },
    "id": "aW5-RgMJSvgX",
    "outputId": "74b5b069-23d2-4851-8da0-8ec552f0a195"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2_as_graph\n",
    "\n",
    "def get_flops(model):\n",
    "    concrete = tf.function(lambda inputs: model(inputs))\n",
    "    concrete_func = concrete.get_concrete_function(\n",
    "        [tf.TensorSpec([1, *inputs.shape[1:]]) for inputs in model.inputs])\n",
    "    frozen_func, graph_def = convert_variables_to_constants_v2_as_graph(concrete_func, lower_control_flow=False)\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.graph_util.import_graph_def(graph_def, name='')\n",
    "        run_meta = tf.compat.v1.RunMetadata()\n",
    "        opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "        flops = tf.compat.v1.profiler.profile(graph=graph, run_meta=run_meta, cmd=\"op\", options=opts)\n",
    "        return flops.total_float_ops\n",
    "\n",
    "print(\"The FLOPs is:{}\".format(get_flops(model)),flush=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UrrPBiGgK_2E",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12086,
     "status": "ok",
     "timestamp": 1700023708574,
     "user": {
      "displayName": "Wang Zihao",
      "userId": "13688795653924779981"
     },
     "user_tz": -480
    },
    "id": "UrrPBiGgK_2E",
    "outputId": "8d40c693-11bd-459e-969e-d655de8d8140"
   },
   "outputs": [],
   "source": [
    "X_train = np.load(\"data/X_train.npy\")\n",
    "X_test = np.load(\"data/X_test.npy\")\n",
    "y_train = np.load(\"data/y_train.npy\")\n",
    "y_test_normalized = np.load(\"data/y_test_normalized.npy\")\n",
    "y_test = np.load(\"data/y_test.npy\")\n",
    "\n",
    "scaler_X = pickle.load(open(\"data/scalar_X.sav\", 'rb'))\n",
    "scaler_y = pickle.load(open(\"data/scalar_y.sav\", 'rb'))\n",
    "model = tf.keras.models.load_model('lrnn_256_0.h5', custom_objects={'MyLRNNCell': MyLRNNCell})\n",
    "\n",
    "y_predict = model.predict(X_test)\n",
    "print(y_predict.shape)\n",
    "\n",
    "y_predict = y_predict.reshape(-1,2)\n",
    "y_predict = scaler_y.inverse_transform(y_predict)\n",
    "y_predict = y_predict.reshape(-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rtB5bHP0LuD6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2035,
     "status": "ok",
     "timestamp": 1700023828845,
     "user": {
      "displayName": "Wang Zihao",
      "userId": "13688795653924779981"
     },
     "user_tz": -480
    },
    "id": "rtB5bHP0LuD6",
    "outputId": "f258a86a-bdf8-412c-ba78-83c82d5dad09"
   },
   "outputs": [],
   "source": [
    "# color code: \"#E69F00\", \"#56B4E9\", \"#009E73\", \"#0072B2\", \"#D55E00\", \"#CC79A7\", \"#F0E442\"\n",
    "plt.figure(figsize=(16, 5))\n",
    "plt.plot(y_predict[:,0], color=\"#E69F00\", label='Predicted')\n",
    "plt.plot(y_test[:,0], color=\"#56B4E9\", label='Test')\n",
    "plt.title(\"SI north\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16, 5))\n",
    "plt.plot(y_predict[:,1], color=\"#009E73\", label='Predicted')\n",
    "plt.plot(y_test[:,1], color=\"#0072B2\", label='Test')\n",
    "plt.title(\"SI south\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16, 5))\n",
    "plt.plot(y_predict[19700:20700,0], color=\"#E69F00\", label='Predicted')\n",
    "plt.plot(y_test[19700:20700,0], color=\"#56B4E9\", label='Test')\n",
    "plt.title(\"SI north\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16, 5))\n",
    "plt.plot(y_predict[19700:20700,1], color=\"#009E73\", label='Predicted')\n",
    "plt.plot(y_test[19700:20700,1], color=\"#0072B2\", label='Test')\n",
    "plt.title(\"SI south\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a024079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply to unseen data\n",
    "# 2023-12-28\n",
    "data_new = pd.read_csv('data/2023-12/[170] 2023-12-28.txt',sep='\t')\n",
    "\n",
    "SI_data = data_new[['Tm', 'AvgGmod05_N_1','AvgGmod05_S_1', 'AvgHamb_1', 'AvgTamb_1', 'AvgTmod05_N_1', 'AvgTmod05_S_1', 'AvgWindS_1', 'AvgWindD_1']]\n",
    "SI_data = SI_data.set_index('Tm')\n",
    "\n",
    "SI_north = SI_data['AvgGmod05_N_1'].to_numpy()\n",
    "SI_south = SI_data['AvgGmod05_S_1'].to_numpy()\n",
    "Ambient_humidity = SI_data['AvgHamb_1'].to_numpy()\n",
    "Ambient_temp = SI_data['AvgTamb_1'].to_numpy()\n",
    "Temp_north = SI_data['AvgTmod05_N_1'].to_numpy()\n",
    "Temp_south = SI_data['AvgTmod05_S_1'].to_numpy()\n",
    "Wind_speed = SI_data['AvgWindS_1'].to_numpy()\n",
    "Wind_direction = SI_data['AvgWindD_1'].to_numpy()\n",
    "\n",
    "def generate_data(data):\n",
    "  win_length = 15\n",
    "  count = 0\n",
    "  data_train = []\n",
    "  data_test = []\n",
    "  while count < len(data):\n",
    "    if count + win_length + 1 < len(data):\n",
    "      data_train.append(data[count:count+win_length])\n",
    "      data_test.append(data[count+win_length+1])\n",
    "      count = count + 1\n",
    "    else:\n",
    "      break\n",
    "  return np.array(data_train).reshape(-1, win_length, 1), np.array(data_test).reshape(-1, 1)\n",
    "\n",
    "SI_north_train, SI_north_test = generate_data(SI_north)\n",
    "SI_south_train, SI_south_test = generate_data(SI_south)\n",
    "Ambient_humidity_train, Ambient_humidity_test = generate_data(Ambient_humidity)\n",
    "Ambient_temp_train, Ambient_temp_test = generate_data(Ambient_temp)\n",
    "Temp_north_train, Temp_north_test = generate_data(Temp_north)\n",
    "Temp_south_train, Temp_south_test = generate_data(Temp_south)\n",
    "Wind_speed_train, Wind_speed_test = generate_data(Wind_speed)\n",
    "Wind_direction_train, Wind_direction_test = generate_data(Wind_direction)\n",
    "\n",
    "data_train = np.concatenate([SI_south_train, SI_north_train, Ambient_humidity_train, Ambient_temp_train, Temp_north_train, Temp_south_train, Wind_speed_train, Wind_direction_train], axis=2)\n",
    "data_test = np.concatenate([SI_south_test, SI_north_test], axis=1)\n",
    "\n",
    "win_length = 15\n",
    "X = scaler_X.transform(data_train.reshape(-1, 8)).reshape(-1, win_length, 8)\n",
    "y = scaler_y.transform(data_test.reshape(-1, 2)).reshape(-1, 2)\n",
    "\n",
    "y_predict = model.predict(X)\n",
    "\n",
    "y_predict = y_predict.reshape(-1,2)\n",
    "y_predict = scaler_y.inverse_transform(y_predict)\n",
    "y_predict = y_predict.reshape(-1,2)\n",
    "\n",
    "loss = model.evaluate(X, y, batch_size=256)\n",
    "print('loss: ', loss)\n",
    "\n",
    "# color code: \"#E69F00\", \"#56B4E9\", \"#009E73\", \"#0072B2\", \"#D55E00\", \"#CC79A7\", \"#F0E442\"\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.rc('font', size=20)\n",
    "plt.plot(y_predict[:,0], color=\"#E69F00\", label='Predicted')\n",
    "plt.plot(data_test[:,0], color=\"#56B4E9\", label='Test')\n",
    "# plt.title(\"SI north\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Magnitude\")\n",
    "plt.margins(x=0)\n",
    "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.savefig('si_north_lrnn_256_testing.pdf')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_predict[:,1], color=\"#0072B2\", label='Predicted')\n",
    "plt.plot(data_test[:,1], color=\"#D55E00\", label='Test')\n",
    "# plt.title(\"SI south\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Magnitude\")\n",
    "plt.margins(x=0)\n",
    "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.savefig('si_south_lrnn_256_testing.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9bac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply to unseen data\n",
    "# 2024-01-01\n",
    "data_new = pd.read_csv('data/2024-01/[170] 2024-01-01.txt',sep='\t')\n",
    "\n",
    "SI_data = data_new[['Tm', 'AvgGmod05_N_1','AvgGmod05_S_1', 'AvgHamb_1', 'AvgTamb_1', 'AvgTmod05_N_1', 'AvgTmod05_S_1', 'AvgWindS_1', 'AvgWindD_1']]\n",
    "SI_data = SI_data.set_index('Tm')\n",
    "\n",
    "SI_north = SI_data['AvgGmod05_N_1'].to_numpy()\n",
    "SI_south = SI_data['AvgGmod05_S_1'].to_numpy()\n",
    "Ambient_humidity = SI_data['AvgHamb_1'].to_numpy()\n",
    "Ambient_temp = SI_data['AvgTamb_1'].to_numpy()\n",
    "Temp_north = SI_data['AvgTmod05_N_1'].to_numpy()\n",
    "Temp_south = SI_data['AvgTmod05_S_1'].to_numpy()\n",
    "Wind_speed = SI_data['AvgWindS_1'].to_numpy()\n",
    "Wind_direction = SI_data['AvgWindD_1'].to_numpy()\n",
    "\n",
    "def generate_data(data):\n",
    "  win_length = 15\n",
    "  count = 0\n",
    "  data_train = []\n",
    "  data_test = []\n",
    "  while count < len(data):\n",
    "    if count + win_length + 1 < len(data):\n",
    "      data_train.append(data[count:count+win_length])\n",
    "      data_test.append(data[count+win_length+1])\n",
    "      count = count + 1\n",
    "    else:\n",
    "      break\n",
    "  return np.array(data_train).reshape(-1, win_length, 1), np.array(data_test).reshape(-1, 1)\n",
    "\n",
    "SI_north_train, SI_north_test = generate_data(SI_north)\n",
    "SI_south_train, SI_south_test = generate_data(SI_south)\n",
    "Ambient_humidity_train, Ambient_humidity_test = generate_data(Ambient_humidity)\n",
    "Ambient_temp_train, Ambient_temp_test = generate_data(Ambient_temp)\n",
    "Temp_north_train, Temp_north_test = generate_data(Temp_north)\n",
    "Temp_south_train, Temp_south_test = generate_data(Temp_south)\n",
    "Wind_speed_train, Wind_speed_test = generate_data(Wind_speed)\n",
    "Wind_direction_train, Wind_direction_test = generate_data(Wind_direction)\n",
    "\n",
    "data_train = np.concatenate([SI_south_train, SI_north_train, Ambient_humidity_train, Ambient_temp_train, Temp_north_train, Temp_south_train, Wind_speed_train, Wind_direction_train], axis=2)\n",
    "data_test = np.concatenate([SI_south_test, SI_north_test], axis=1)\n",
    "\n",
    "win_length = 15\n",
    "X = scaler_X.transform(data_train.reshape(-1, 8)).reshape(-1, win_length, 8)\n",
    "y = scaler_y.transform(data_test.reshape(-1, 2)).reshape(-1, 2)\n",
    "\n",
    "y_predict = model.predict(X)\n",
    "\n",
    "y_predict = y_predict.reshape(-1,2)\n",
    "y_predict = scaler_y.inverse_transform(y_predict)\n",
    "y_predict = y_predict.reshape(-1,2)\n",
    "\n",
    "loss = model.evaluate(X, y, batch_size=256)\n",
    "print('loss: ', loss)\n",
    "\n",
    "# color code: \"#E69F00\", \"#56B4E9\", \"#009E73\", \"#0072B2\", \"#D55E00\", \"#CC79A7\", \"#F0E442\"\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.rc('font', size=20)\n",
    "plt.plot(y_predict[:,0], color=\"#E69F00\", label='Predicted')\n",
    "plt.plot(data_test[:,0], color=\"#56B4E9\", label='Test')\n",
    "# plt.title(\"SI north\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Magnitude\")\n",
    "plt.margins(x=0)\n",
    "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.savefig('si_north_lrnn_256_unseen.pdf')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_predict[:,1], color=\"#0072B2\", label='Predicted')\n",
    "plt.plot(data_test[:,1], color=\"#D55E00\", label='Test')\n",
    "# plt.title(\"SI south\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Magnitude\")\n",
    "plt.margins(x=0)\n",
    "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.savefig('si_south_lrnn_256_unseen.pdf')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
