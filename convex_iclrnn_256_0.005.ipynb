{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a98dacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 08:10:47.350959: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-05 08:10:47.352215: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-05 08:10:47.376390: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-05 08:10:47.377559: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-05 08:10:47.899528: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import pandas\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from scipy.optimize import NonlinearConstraint, LinearConstraint\n",
    "from scipy.optimize import BFGS, minimize, Bounds, SR1\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, SimpleRNN\n",
    "from keras import backend as K\n",
    "import numpy\n",
    "from keras.models import model_from_json, load_model\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "import pyipopt\n",
    "from numpy import *\n",
    "from keras.constraints import Constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36b6cdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_BETA_BJORCK = 0.5\n",
    "DEFAULT_EPS_SPECTRAL = 1e-3\n",
    "DEFAULT_EPS_BJORCK = 1e-3\n",
    "DEFAULT_MAXITER_BJORCK = 15\n",
    "DEFAULT_MAXITER_SPECTRAL = 10\n",
    "SWAP_MEMORY = True\n",
    "STOP_GRAD_SPECTRAL = True\n",
    "\n",
    "def reshaped_kernel_orthogonalization(\n",
    "    kernel,\n",
    "    u,\n",
    "    adjustment_coef,\n",
    "    eps_spectral=DEFAULT_EPS_SPECTRAL,\n",
    "    eps_bjorck=DEFAULT_EPS_BJORCK,\n",
    "    beta=DEFAULT_BETA_BJORCK,\n",
    "    maxiter_spectral=DEFAULT_MAXITER_SPECTRAL,\n",
    "    maxiter_bjorck=DEFAULT_MAXITER_BJORCK,\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform reshaped kernel orthogonalization (RKO) to the kernel given as input. It\n",
    "    apply the power method to find the largest singular value and apply the Bjorck\n",
    "    algorithm to the rescaled kernel. This greatly improve the stability and and\n",
    "    speed convergence of the bjorck algorithm.\n",
    "\n",
    "    Args:\n",
    "        kernel (tf.Tensor): the kernel to orthogonalize\n",
    "        u (tf.Tensor): the vector used to do the power iteration method\n",
    "        adjustment_coef (float): the adjustment coefficient as used in convolution\n",
    "        eps_spectral (float): stopping criterion in spectral algorithm\n",
    "        eps_bjorck (float): stopping criterion in bjorck algorithm\n",
    "        beta (float): the beta used in the bjorck algorithm\n",
    "        maxiter_spectral (int): maximum number of iterations for the power iteration\n",
    "        maxiter_bjorck (int): maximum number of iterations for bjorck algorithm\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: the orthogonalized kernel, the new u, and sigma which is the largest\n",
    "            singular value\n",
    "\n",
    "    \"\"\"\n",
    "    W_shape = kernel.shape\n",
    "    # Flatten the Tensor\n",
    "    W_reshaped = tf.reshape(kernel, [-1, W_shape[-1]])\n",
    "    W_bar, u, sigma = spectral_normalization(\n",
    "        W_reshaped, u, eps=eps_spectral, maxiter=maxiter_spectral\n",
    "    )\n",
    "    if (eps_bjorck is not None) and (beta is not None):\n",
    "        W_bar = bjorck_normalization(\n",
    "            W_bar, eps=eps_bjorck, beta=beta, maxiter=maxiter_bjorck\n",
    "        )\n",
    "    W_bar = W_bar * adjustment_coef\n",
    "    W_bar = K.reshape(W_bar, kernel.shape)\n",
    "    return W_bar, u, sigma\n",
    "\n",
    "\n",
    "def _wwtw(w):\n",
    "    if w.shape[0] > w.shape[1]:\n",
    "        return w @ (tf.transpose(w) @ w)\n",
    "    else:\n",
    "        return (w @ tf.transpose(w)) @ w\n",
    "\n",
    "\n",
    "def bjorck_normalization(\n",
    "    w, eps=DEFAULT_EPS_BJORCK, beta=DEFAULT_BETA_BJORCK, maxiter=DEFAULT_MAXITER_BJORCK\n",
    "):\n",
    "    \"\"\"\n",
    "    apply Bjorck normalization on w.\n",
    "\n",
    "    Args:\n",
    "        w (tf.Tensor): weight to normalize, in order to work properly, we must have\n",
    "            max_eigenval(w) ~= 1\n",
    "        eps (float): epsilon stopping criterion: norm(wt - wt-1) must be less than eps\n",
    "        beta (float): beta used in each iteration, must be in the interval ]0, 0.5]\n",
    "        maxiter (int): maximum number of iterations for the algorithm\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: the orthonormal weights\n",
    "\n",
    "    \"\"\"\n",
    "    # create a fake old_w that does'nt pass the loop condition\n",
    "    # it won't affect computation as the first action done in the loop overwrite it.\n",
    "    old_w = 10 * w\n",
    "    # define the loop condition\n",
    "\n",
    "    def cond(w, old_w):\n",
    "        return tf.linalg.norm(w - old_w) >= eps\n",
    "\n",
    "    # define the loop body\n",
    "    def body(w, old_w):\n",
    "        old_w = w\n",
    "        w = (1 + beta) * w - beta * _wwtw(w)\n",
    "        return w, old_w\n",
    "\n",
    "    # apply the loop\n",
    "    w, old_w = tf.while_loop(\n",
    "        cond,\n",
    "        body,\n",
    "        (w, old_w),\n",
    "        parallel_iterations=30,\n",
    "        maximum_iterations=maxiter,\n",
    "        swap_memory=SWAP_MEMORY,\n",
    "    )\n",
    "    return w\n",
    "\n",
    "\n",
    "def _power_iteration(\n",
    "    linear_operator,\n",
    "    adjoint_operator,\n",
    "    u,\n",
    "    eps=DEFAULT_EPS_SPECTRAL,\n",
    "    maxiter=DEFAULT_MAXITER_SPECTRAL,\n",
    "    axis=None,\n",
    "):\n",
    "    \"\"\"Internal function that performs the power iteration algorithm to estimate the\n",
    "    largest singular vector of a linear operator.\n",
    "\n",
    "    Args:\n",
    "        linear_operator (Callable): a callable object that maps a linear operation.\n",
    "        adjoint_operator (Callable): a callable object that maps the adjoint of the\n",
    "            linear operator.\n",
    "        u (tf.Tensor): initialization of the singular vector.\n",
    "        eps (float, optional): stopping criterion of the algorithm, when\n",
    "            norm(u[t] - u[t-1]) is less than eps. Defaults to DEFAULT_EPS_SPECTRAL.\n",
    "        maxiter (int, optional): maximum number of iterations for the algorithm.\n",
    "            Defaults to DEFAULT_MAXITER_SPECTRAL.\n",
    "        axis (int/list, optional): dimension along which to normalize. Can be set for\n",
    "            depthwise convolution for example. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: the maximum singular vector.\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare while loop variables\n",
    "    u = tf.math.l2_normalize(u, axis=axis)\n",
    "    # create a fake old_w that doesn't pass the loop condition, it will be overwritten\n",
    "    old_u = u + 2 * eps\n",
    "\n",
    "    # Loop body\n",
    "    def body(u, old_u):\n",
    "        old_u = u\n",
    "        v = linear_operator(u)\n",
    "        u = adjoint_operator(v)\n",
    "\n",
    "        u = tf.math.l2_normalize(u, axis=axis)\n",
    "\n",
    "        return u, old_u\n",
    "\n",
    "    # Loop stopping condition\n",
    "    def cond(u, old_u):\n",
    "        return tf.linalg.norm(u - old_u) >= eps\n",
    "\n",
    "    # Run the while loop\n",
    "    u, _ = tf.while_loop(\n",
    "        cond,\n",
    "        body,\n",
    "        (u, old_u),\n",
    "        maximum_iterations=maxiter,\n",
    "        swap_memory=SWAP_MEMORY,\n",
    "    )\n",
    "\n",
    "    # Prevent gradient to back-propagate into the while loop\n",
    "    if STOP_GRAD_SPECTRAL:\n",
    "        u = tf.stop_gradient(u)\n",
    "\n",
    "    return u\n",
    "\n",
    "\n",
    "def spectral_normalization(\n",
    "    kernel, u, eps=DEFAULT_EPS_SPECTRAL, maxiter=DEFAULT_MAXITER_SPECTRAL\n",
    "):\n",
    "    \"\"\"\n",
    "    Normalize the kernel to have its maximum singular value equal to 1.\n",
    "\n",
    "    Args:\n",
    "        kernel (tf.Tensor): the kernel to normalize, assuming a 2D kernel.\n",
    "        u (tf.Tensor): initialization of the maximum singular vector.\n",
    "        eps (float, optional): stopping criterion of the algorithm, when\n",
    "            norm(u[t] - u[t-1]) is less than eps. Defaults to DEFAULT_EPS_SPECTRAL.\n",
    "        maxiter (int, optional): maximum number of iterations for the algorithm.\n",
    "            Defaults to DEFAULT_MAXITER_SPECTRAL.\n",
    "\n",
    "    Returns:\n",
    "        the normalized kernel, the maximum singular vector, and the maximum singular\n",
    "            value.\n",
    "    \"\"\"\n",
    "\n",
    "    if u is None:\n",
    "        u = tf.random.uniform(\n",
    "            shape=(1, kernel.shape[-1]), minval=0.0, maxval=1.0, dtype=kernel.dtype\n",
    "        )\n",
    "\n",
    "    def linear_op(u):\n",
    "        return u @ tf.transpose(kernel)\n",
    "\n",
    "    def adjoint_op(v):\n",
    "        return v @ kernel\n",
    "\n",
    "    u = _power_iteration(linear_op, adjoint_op, u, eps, maxiter)\n",
    "\n",
    "    # Compute the largest singular value and the normalized kernel.\n",
    "    # We assume that in the worst case we converged to sigma + eps (as u and v are\n",
    "    # normalized after each iteration)\n",
    "    # In order to be sure that operator norm of normalized kernel is strictly less than\n",
    "    # one we use sigma + eps, which ensures stability of Björck algorithm even when\n",
    "    # beta=0.5\n",
    "    sigma = tf.reshape(tf.norm(linear_op(u)), (1, 1))\n",
    "    normalized_kernel = kernel / (sigma + eps)\n",
    "    return normalized_kernel, u, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8856ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralConstraint(Constraint):\n",
    "    def __init__(\n",
    "        self,\n",
    "        k_coef_lip=1.0,\n",
    "        eps_spectral=DEFAULT_EPS_SPECTRAL,\n",
    "        eps_bjorck=DEFAULT_EPS_BJORCK,\n",
    "        beta_bjorck=DEFAULT_BETA_BJORCK,\n",
    "        u=None,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Ensure that *all* singular values of the weight matrix equals to 1. Computation\n",
    "        based on Bjorck algorithm. The computation is done in two steps:\n",
    "\n",
    "        1. reduce the larget singular value to k_coef_lip, using iterate power method.\n",
    "        2. increase other singular values to k_coef_lip, using bjorck algorithm.\n",
    "\n",
    "        Args:\n",
    "            k_coef_lip (float): lipschitz coefficient of the weight matrix\n",
    "            eps_spectral (float): stopping criterion for the iterative power algorithm.\n",
    "            eps_bjorck (float): stopping criterion Bjorck algorithm.\n",
    "            beta_bjorck (float): beta parameter in bjorck algorithm.\n",
    "            u (tf.Tensor): vector used for iterated power method, can be set to None\n",
    "                (used for serialization/deserialization purposes).\n",
    "        \"\"\"\n",
    "        self.eps_spectral = eps_spectral\n",
    "        self.eps_bjorck = eps_bjorck\n",
    "        self.beta_bjorck = beta_bjorck\n",
    "        self.k_coef_lip = k_coef_lip\n",
    "        if not (isinstance(u, tf.Tensor) or (u is None)):\n",
    "            u = tf.convert_to_tensor(u)\n",
    "        self.u = u\n",
    "        super(SpectralConstraint, self).__init__()\n",
    "\n",
    "    def __call__(self, w):\n",
    "        # make the largest singular value of W to be 1\n",
    "        wbar, _, _ = reshaped_kernel_orthogonalization(\n",
    "            w,\n",
    "            self.u,\n",
    "            self.k_coef_lip,\n",
    "            self.eps_spectral,\n",
    "            self.eps_bjorck,\n",
    "            self.beta_bjorck,\n",
    "        )\n",
    "\n",
    "        # clip to ensure non-negative weight\n",
    "        wbar = K.clip(wbar, 0, wbar)\n",
    "        return wbar\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            \"k_coef_lip\": self.k_coef_lip,\n",
    "            \"eps_spectral\": self.eps_spectral,\n",
    "            \"eps_bjorck\": self.eps_bjorck,\n",
    "            \"beta_bjorck\": self.beta_bjorck,\n",
    "            \"u\": None if self.u is None else self.u.numpy(),\n",
    "        }\n",
    "        base_config = super(SpectralConstraint, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "889ce0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_L [-2.e+19 -2.e+19] [0 0]\n",
      "Num Iteratin:  0\n",
      "[PyIPOPT] Ipopt will use Hessian approximation.\n",
      "\n",
      "[PyIPOPT] Problem created\n",
      "Going to call solve\n",
      "x0 = [0. 0. 0. 0.]\n",
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit https://github.com/coin-or/Ipopt\n",
      "******************************************************************************\n",
      "\n",
      "The elapsed time is 84.56871700286865 s\n",
      "Solution of the primal variables, x\n",
      "x[0] = 500000.00009996403\n",
      "x[1] = -3.5000000349984273\n",
      "x[2] = 500000.0000998778\n",
      "x[3] = -3.500000034995047\n",
      "status= 0\n",
      "Objective value\n",
      "f(x*) = 660.1772873733008\n",
      "Control action=:   -3.5000000349984273 500000.00009996403\n",
      "Real model output x1 x2 in deviation form:    1.1629372648194882 -39.579862274802466\n",
      "Num Iteratin:  1\n",
      "[PyIPOPT] Ipopt will use Hessian approximation.\n",
      "\n",
      "[PyIPOPT] Problem created\n",
      "Going to call solve\n",
      "x0 = [ 5.00000000e+05 -3.50000003e+00  5.00000000e+05 -3.50000003e+00]\n",
      "The elapsed time is 96.67857074737549 s\n",
      "Solution of the primal variables, x\n",
      "x[0] = 455111.7913537201\n",
      "x[1] = -3.4999912042733037\n",
      "x[2] = 462919.1318595703\n",
      "x[3] = -3.457941642676642\n",
      "status= -1\n",
      "Objective value\n",
      "f(x*) = 467.4607086760096\n",
      "Control action=:   -3.4999912042733037 455111.7913537201\n",
      "Real model output x1 x2 in deviation form:    1.068005191264363 -29.878046003469528\n",
      "Num Iteratin:  2\n",
      "[PyIPOPT] Ipopt will use Hessian approximation.\n",
      "\n",
      "[PyIPOPT] Problem created\n",
      "Going to call solve\n",
      "x0 = [ 4.62919132e+05 -3.45794164e+00  4.62919132e+05 -3.45794164e+00]\n",
      "The elapsed time is 113.94091176986694 s\n",
      "Solution of the primal variables, x\n",
      "x[0] = 419276.810587219\n",
      "x[1] = -3.5000000349999576\n",
      "x[2] = 495441.8293627063\n",
      "x[3] = -3.500000034999959\n",
      "status= -1\n",
      "Objective value\n",
      "f(x*) = 312.44201020938243\n",
      "Control action=:   -3.5000000349999576 419276.810587219\n",
      "Real model output x1 x2 in deviation form:    0.9628777063302121 -20.557781932355816\n",
      "Num Iteratin:  3\n",
      "[PyIPOPT] Ipopt will use Hessian approximation.\n",
      "\n",
      "[PyIPOPT] Problem created\n",
      "Going to call solve\n",
      "x0 = [ 4.95441829e+05 -3.50000003e+00  4.95441829e+05 -3.50000003e+00]\n",
      "The elapsed time is 23.2172269821167 s\n",
      "Solution of the primal variables, x\n",
      "x[0] = 436453.9178527179\n",
      "x[1] = -3.500000034999983\n",
      "x[2] = 428089.50220854086\n",
      "x[3] = -3.5000000349999656\n",
      "status= 2\n",
      "Objective value\n",
      "f(x*) = 191.9310476370928\n",
      "Control action=:   -3.500000034999983 436453.9178527179\n",
      "Real model output x1 x2 in deviation form:    0.8437413806612123 -10.273752031431858\n",
      "Num Iteratin:  4\n",
      "[PyIPOPT] Ipopt will use Hessian approximation.\n",
      "\n",
      "[PyIPOPT] Problem created\n",
      "Going to call solve\n",
      "x0 = [ 4.28089502e+05 -3.50000003e+00  4.28089502e+05 -3.50000003e+00]\n",
      "The elapsed time is 22.989404678344727 s\n",
      "Solution of the primal variables, x\n",
      "x[0] = 427513.27209911164\n",
      "x[1] = -3.500000034999985\n",
      "x[2] = 427779.4400613999\n",
      "x[3] = -3.500000034999971\n",
      "status= 2\n",
      "Objective value\n",
      "f(x*) = 108.83163685972276\n",
      "Control action=:   -3.500000034999985 427513.27209911164\n",
      "Real model output x1 x2 in deviation form:    0.7048600978071231 0.6945807157614252\n",
      "Num Iteratin:  5\n",
      "[PyIPOPT] Ipopt will use Hessian approximation.\n",
      "\n",
      "[PyIPOPT] Problem created\n",
      "Going to call solve\n",
      "x0 = [ 4.27779440e+05 -3.50000003e+00  4.27779440e+05 -3.50000003e+00]\n",
      "The elapsed time is 111.4093611240387 s\n",
      "Solution of the primal variables, x\n",
      "x[0] = 19509.8984918235\n",
      "x[1] = -3.500000034997006\n",
      "x[2] = 471116.2630453821\n",
      "x[3] = -3.5000000349903027\n",
      "status= -1\n",
      "Objective value\n",
      "f(x*) = 67.46837751588289\n",
      "Control action=:   -3.500000034997006 19509.8984918235\n",
      "Real model output x1 x2 in deviation form:    0.5563055622949484 3.32043630372506\n",
      "Num Iteratin:  6\n",
      "[PyIPOPT] Ipopt will use Hessian approximation.\n",
      "\n",
      "[PyIPOPT] Problem created\n",
      "Going to call solve\n",
      "x0 = [ 4.71116263e+05 -3.50000003e+00  4.71116263e+05 -3.50000003e+00]\n",
      "The elapsed time is 46.454817056655884 s\n",
      "Solution of the primal variables, x\n",
      "x[0] = 360829.9126103676\n",
      "x[1] = -3.50000003499994\n",
      "x[2] = 367996.5502119089\n",
      "x[3] = -3.5000000349999394\n",
      "status= 2\n",
      "Objective value\n",
      "f(x*) = 56.46508240039706\n",
      "Control action=:   -3.50000003499994 360829.9126103676\n",
      "Real model output x1 x2 in deviation form:    0.400015676505297 13.747276244906814\n",
      "Num Iteratin:  7\n",
      "[PyIPOPT] Ipopt will use Hessian approximation.\n",
      "\n",
      "[PyIPOPT] Problem created\n",
      "Going to call solve\n",
      "x0 = [ 3.67996550e+05 -3.50000003e+00  3.67996550e+05 -3.50000003e+00]\n",
      "The elapsed time is 86.67709851264954 s\n",
      "Solution of the primal variables, x\n",
      "x[0] = -499999.9287727662\n",
      "x[1] = -3.5000000349931644\n",
      "x[2] = 6939.179209330798\n",
      "x[3] = -3.500000034973758\n",
      "status= 0\n",
      "Objective value\n",
      "f(x*) = 24.530901360538\n",
      "Control action=:   -3.5000000349931644 -499999.9287727662\n",
      "Real model output x1 x2 in deviation form:    0.25588627164647204 5.097128321489967\n",
      "Num Iteratin:  8\n",
      "[PyIPOPT] Ipopt will use Hessian approximation.\n",
      "\n",
      "[PyIPOPT] Problem created\n",
      "Going to call solve\n",
      "x0 = [ 6.93917921e+03 -3.50000003e+00  6.93917921e+03 -3.50000003e+00]\n",
      "The elapsed time is 17.83463478088379 s\n",
      "Solution of the primal variables, x\n",
      "x[0] = 6939.319236790986\n",
      "x[1] = -3.5000000349866998\n",
      "x[2] = 6939.0776735541795\n",
      "x[3] = -3.5000000349252014\n",
      "status= 0\n",
      "Objective value\n",
      "f(x*) = 7.539583473200777\n",
      "Control action=:   -3.5000000349866998 6939.319236790986\n",
      "Real model output x1 x2 in deviation form:    0.13803230876308414 6.369087491076813\n",
      "Num Iteratin:  9\n",
      "[PyIPOPT] Ipopt will use Hessian approximation.\n",
      "\n",
      "[PyIPOPT] Problem created\n",
      "Going to call solve\n",
      "x0 = [ 6.93907767e+03 -3.50000003e+00  6.93907767e+03 -3.50000003e+00]\n",
      "The elapsed time is 120.40841126441956 s\n",
      "Solution of the primal variables, x\n",
      "x[0] = -245653.643803043\n",
      "x[1] = -3.500000034943112\n",
      "x[2] = 97976.30400731668\n",
      "x[3] = -1.4523723913308348\n",
      "status= -1\n",
      "Objective value\n",
      "f(x*) = 2.37976456572763\n",
      "Control action=:   -3.500000034943112 -245653.643803043\n",
      "Real model output x1 x2 in deviation form:    0.03450070540912 1.6405759866399043\n",
      "x1_record:  [1.25, 1.2466379817421445, 1.238194999386366, 1.2296955813977193, 1.2211368480013252, 1.2125158232239048, 1.2038294315480915, 1.1950744944194462, 1.1862477265987645, 1.1773457323519485, 1.1683650014694091, 1.1593023690816833, 1.1501625010028729, 1.1409449770890903, 1.1316466276500254, 1.1222641863323402, 1.1127942868159055, 1.1032334593765671, 1.0935781273106358, 1.0838246032162908, 1.073969085127129, 1.064008142645242, 1.0539469202599796, 1.0437849611124923, 1.0335187625978859, 1.0231447215161653, 1.012659130829039, 1.0020581763156882, 0.9913379331273349, 0.9804943622409593, 0.9695233068131407, 0.9584201737192025, 0.9471747667912954, 0.9357802368698948, 0.9242314333693488, 0.912523046583769, 0.900649602555866, 0.8886054578458207, 0.8763847942120122, 0.8639816132180922, 0.8513897307839576, 0.8386029878829699, 0.8256187921583743, 0.8124319629789926, 0.7990358545518601, 0.7854236236622012, 0.7715882251141909, 0.7575224073737538, 0.7432187084724304, 0.7286694522400776, 0.7138667449439703, 0.6988152447578582, 0.6837390908956761, 0.6687149134931386, 0.6537434365584696, 0.638825385146656, 0.6239614849090613, 0.6091524616353171, 0.5943990407880192, 0.579701947030778, 0.5650619037502005, 0.550469282735622, 0.535736973643023, 0.5207985323444773, 0.5056491188869288, 0.4902838388581486, 0.4746977491079863, 0.45888586432264145, 0.44284316453343253, 0.42656460364716525, 0.4100451190908902, 0.39331119096441736, 0.37692279288961533, 0.3610548294142527, 0.3456920875896572, 0.33081937638654735, 0.3164215669322629, 0.3024836294191484, 0.28899066675835705, 0.2759279450744681, 0.26328092115342416, 0.25102274816781195, 0.23891796973974416, 0.2268905697694319, 0.2149407761521509, 0.2030688019174237, 0.19127484513277612, 0.17955908882155844, 0.16792170089483577, 0.15636283409732574, 0.14488262596733506, 0.13348702511542912, 0.12227976628747421, 0.11129181649335157, 0.10051883986027874, 0.08995651714924857, 0.07960055035510363, 0.06944666701438838, 0.0594906242272487, 0.049728212400386745, 0.04015525871870885]\n",
      "x2_record:  [-50, -49.58625983405652, -48.55109784245681, -47.51466184928403, -46.4768046540477, -45.437374276737614, -44.39621379123969, -43.35316115141896, -42.308049009500635, -41.2607045263647, -40.21094917335387, -39.197475717923034, -38.239769869728214, -37.279453509235054, -36.31636570246825, -35.35034071105481, -34.38120782773152, -33.408791205207706, -32.43290967814409, -31.453376578008594, -30.469999540571244, -29.51362334771439, -28.599874752328347, -27.682142254752648, -26.760248907630128, -25.83401276205413, -24.903246706094603, -23.967758298294456, -23.027349596127667, -22.081816979436876, -21.130950968898706, -20.159652135542228, -19.160041235282772, -18.154104800727445, -17.141583674339326, -16.122210783862158, -15.095710886855672, -14.061800310254368, -13.020186685538242, -11.970568680236802, -10.912635726640232, -9.853817394667564, -8.797817548409531, -7.732752867207986, -6.65828994500985, -5.574085553784304, -4.479786416531812, -3.375028990351267, -2.259439262504106, -1.1326325628488787, 0.005786603491924613, 0.802427484948944, 1.0710973818716556, 1.338383188442416, 1.6042458552631933, 1.8686462883310937, 2.131545371441481, 2.3929039889755237, 2.6526830490460287, 2.9108435069741483, 3.1673463890682734, 3.7181093532377574, 4.718873526307293, 5.729232016498472, 6.749427441376398, 7.779705125512486, 8.820312815670636, 9.871500353527077, 10.933519301867513, 12.006622519925456, 13.091063683242222, 13.440405261865989, 12.657468428030331, 11.852615541041907, 11.026593982894296, 10.180150069262542, 9.314027046288812, 8.428963253089988, 7.5256904462899525, 6.604932281827547, 5.667402948439231, 5.153227889670633, 5.291600235960684, 5.427279864143824, 5.560252533040947, 5.690504748775034, 5.818023769544436, 5.942797609696011, 6.064815043097879, 6.1840656058129335, 6.30053959807543, 6.195297499147571, 5.754807755822371, 5.305893602651755, 4.84876466707416, 4.3836297639933335, 3.910696666731453, 3.4301718925302, 2.942260502287679, 2.4471659141822792, 1.9450897308032618]\n",
      "u1_record:  [-3.5000000349984273, -3.5000000349984273, -3.5000000349984273, -3.5000000349984273, -3.5000000349984273, -3.5000000349984273, -3.5000000349984273, -3.5000000349984273, -3.5000000349984273, -3.5000000349984273, -3.4999912042733037, -3.4999912042733037, -3.4999912042733037, -3.4999912042733037, -3.4999912042733037, -3.4999912042733037, -3.4999912042733037, -3.4999912042733037, -3.4999912042733037, -3.4999912042733037, -3.5000000349999576, -3.5000000349999576, -3.5000000349999576, -3.5000000349999576, -3.5000000349999576, -3.5000000349999576, -3.5000000349999576, -3.5000000349999576, -3.5000000349999576, -3.5000000349999576, -3.500000034999983, -3.500000034999983, -3.500000034999983, -3.500000034999983, -3.500000034999983, -3.500000034999983, -3.500000034999983, -3.500000034999983, -3.500000034999983, -3.500000034999983, -3.500000034999985, -3.500000034999985, -3.500000034999985, -3.500000034999985, -3.500000034999985, -3.500000034999985, -3.500000034999985, -3.500000034999985, -3.500000034999985, -3.500000034999985, -3.500000034997006, -3.500000034997006, -3.500000034997006, -3.500000034997006, -3.500000034997006, -3.500000034997006, -3.500000034997006, -3.500000034997006, -3.500000034997006, -3.500000034997006, -3.50000003499994, -3.50000003499994, -3.50000003499994, -3.50000003499994, -3.50000003499994, -3.50000003499994, -3.50000003499994, -3.50000003499994, -3.50000003499994, -3.50000003499994, -3.5000000349931644, -3.5000000349931644, -3.5000000349931644, -3.5000000349931644, -3.5000000349931644, -3.5000000349931644, -3.5000000349931644, -3.5000000349931644, -3.5000000349931644, -3.5000000349931644, -3.5000000349866998, -3.5000000349866998, -3.5000000349866998, -3.5000000349866998, -3.5000000349866998, -3.5000000349866998, -3.5000000349866998, -3.5000000349866998, -3.5000000349866998, -3.5000000349866998, -3.500000034943112, -3.500000034943112, -3.500000034943112, -3.500000034943112, -3.500000034943112, -3.500000034943112, -3.500000034943112, -3.500000034943112, -3.500000034943112, -3.500000034943112]\n",
      "u2_record:  [500000.00009996403, 500000.00009996403, 500000.00009996403, 500000.00009996403, 500000.00009996403, 500000.00009996403, 500000.00009996403, 500000.00009996403, 500000.00009996403, 500000.00009996403, 455111.7913537201, 455111.7913537201, 455111.7913537201, 455111.7913537201, 455111.7913537201, 455111.7913537201, 455111.7913537201, 455111.7913537201, 455111.7913537201, 455111.7913537201, 419276.810587219, 419276.810587219, 419276.810587219, 419276.810587219, 419276.810587219, 419276.810587219, 419276.810587219, 419276.810587219, 419276.810587219, 419276.810587219, 436453.9178527179, 436453.9178527179, 436453.9178527179, 436453.9178527179, 436453.9178527179, 436453.9178527179, 436453.9178527179, 436453.9178527179, 436453.9178527179, 436453.9178527179, 427513.27209911164, 427513.27209911164, 427513.27209911164, 427513.27209911164, 427513.27209911164, 427513.27209911164, 427513.27209911164, 427513.27209911164, 427513.27209911164, 427513.27209911164, 19509.8984918235, 19509.8984918235, 19509.8984918235, 19509.8984918235, 19509.8984918235, 19509.8984918235, 19509.8984918235, 19509.8984918235, 19509.8984918235, 19509.8984918235, 360829.9126103676, 360829.9126103676, 360829.9126103676, 360829.9126103676, 360829.9126103676, 360829.9126103676, 360829.9126103676, 360829.9126103676, 360829.9126103676, 360829.9126103676, -499999.9287727662, -499999.9287727662, -499999.9287727662, -499999.9287727662, -499999.9287727662, -499999.9287727662, -499999.9287727662, -499999.9287727662, -499999.9287727662, -499999.9287727662, 6939.319236790986, 6939.319236790986, 6939.319236790986, 6939.319236790986, 6939.319236790986, 6939.319236790986, 6939.319236790986, 6939.319236790986, 6939.319236790986, 6939.319236790986, -245653.643803043, -245653.643803043, -245653.643803043, -245653.643803043, -245653.643803043, -245653.643803043, -245653.643803043, -245653.643803043, -245653.643803043, -245653.643803043]\n",
      "time_record:  [84.56871700286865, 96.67857074737549, 113.94091176986694, 23.2172269821167, 22.989404678344727, 111.4093611240387, 46.454817056655884, 86.67709851264954, 17.83463478088379, 120.40841126441956]\n",
      "total time elapsed:  724.17915391922 s\n",
      "average time for each iteration: 72.417915391922 s\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import pandas\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from scipy.optimize import NonlinearConstraint, LinearConstraint\n",
    "from scipy.optimize import BFGS, minimize, Bounds, SR1\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, SimpleRNN\n",
    "import numpy\n",
    "from keras.models import model_from_json, load_model\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "import pyipopt\n",
    "from numpy import *\n",
    "#####Simulation time step\n",
    "delta=0.005\n",
    "hc=1e-4 #delta/100\n",
    "oper_time=0.01\n",
    "\n",
    "short_factor=int(0.005/delta)\n",
    "####Initial states\n",
    "CAi=1.25\n",
    "Ti=-50\n",
    "x1_nn=CAi\n",
    "x2_nn=Ti\n",
    "x1_record=[CAi]\n",
    "x2_record=[Ti]\n",
    "u1_record=[]\n",
    "u2_record=[]\n",
    "time_record=[]\n",
    "\n",
    "\n",
    "a=1060\n",
    "b=22\n",
    "d=0.52\n",
    "\n",
    "F=5\n",
    "V=1\n",
    "k0=8460000\n",
    "E=50000\n",
    "R=8.314\n",
    "T0=300\n",
    "Dh=-11500\n",
    "rho=1000\n",
    "sigma=1000\n",
    "Cp=0.231\n",
    "cp=0.231\n",
    "Qs=0\n",
    "CA0s=4\n",
    "x_record=[0,0]\n",
    "#steady-state\n",
    "CAs= 1.9537\n",
    "Ts=  401.8727\n",
    "\n",
    "w1_std=2.5\n",
    "w2_std=70\n",
    "state_ss=numpy.array([Ts, CAs])\n",
    "input_ss=numpy.array([Qs, CA0s])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ROOT_FOLDER=os.getcwd()\n",
    "#### CONSTANTS ####\n",
    "NUM_MPC_ITERATION=50*short_factor   #10000000000\n",
    "\n",
    "OUTPUT_NO=0\n",
    "TOTAL_MODELS=12 # used to be 8\n",
    "NUM_SUBMODELS=1\n",
    "NUM_OUTPUTS=2\n",
    "NUM_INPUTS=4   #used to be 16\n",
    "HORIZON=2\n",
    "#NUM_CONSTRAINT_MODELS=3\n",
    "NUM_IN_SEQUENCE=10\n",
    "PREDICTION_STORE=0\n",
    "#NUM_PREDICTION_STEPS=1\n",
    "deviation=0\n",
    "NUM_MPC_INPUTS=2*HORIZON\n",
    "NUM_MPC_CONSTRAINTS=HORIZON\n",
    "realtime_data=None\n",
    "setpoint=[0, 0]\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "def my_ens_prediction(num_horizon,my_rawdata,my_inputs):\n",
    "    xx = []\n",
    "    nn_inputs = []\n",
    "    ensemble_output = numpy.zeros((num_horizon,NUM_OUTPUTS,NUM_IN_SEQUENCE))\n",
    "    #numpy.array([0]*(num_horizon*NUM_OUTPUTS*NUM_IN_SEQUENCE))#[[[0 for i in range(NUM_IN_SEQUENCE)] for j in range(NUM_OUTPUTS)] for j in range(NUM_IN_SEQUENCE)]\n",
    "    ensemble_output = ensemble_output.reshape(num_horizon,NUM_IN_SEQUENCE,NUM_OUTPUTS)\n",
    "    predict_output = []\n",
    "    x_test2 = my_rawdata[0:NUM_OUTPUTS].astype(float)\n",
    "    x_test2= (x_test2-state_mean)/state_std\n",
    "\n",
    "    predict_output_normal=[[0 for i in range(NUM_OUTPUTS)] for j in range(NUM_IN_SEQUENCE)]\n",
    "    for i_model in range(num_horizon):    \n",
    "        # i_model=0\n",
    "        # my_inputs=[640]*4    \n",
    "        COUNT_CORRECT_MODEL=0\n",
    "        my_inputs_normalized = (my_inputs[2*i_model:2*(i_model+1)] - input_mean) / input_std\n",
    "        sum=[[0 for i in range(NUM_OUTPUTS)] for j in range(NUM_IN_SEQUENCE)]\n",
    "        xx = numpy.concatenate((x_test2,  my_inputs_normalized), axis=None).reshape((1, NUM_INPUTS))\n",
    "        xx = numpy.tile(xx, (NUM_IN_SEQUENCE, 1))\n",
    "        #if i_model != 0:\n",
    "        #    xx[:,NUM_OUTPUTS:2*NUM_OUTPUTS]=predict_output_normal\n",
    "        nn_inputs = xx.reshape(1, NUM_IN_SEQUENCE, NUM_INPUTS)\n",
    "        for j_submodel in range (NUM_SUBMODELS):\n",
    "            # j_submodel=0\n",
    "            predict_output = numpy.array(model[j_submodel].predict(nn_inputs,verbose=0))\n",
    "            predict_output = predict_output.reshape(NUM_IN_SEQUENCE, NUM_OUTPUTS)\n",
    "            # print (\"submodel id:\", j_submodel)\n",
    "            # print (\"submodel:\", predict_output)\n",
    "            #if not math.isnan(predict_output[0,0]):\n",
    "            sum=sum+predict_output\n",
    "            #COUNT_CORRECT_MODEL=COUNT_CORRECT_MODEL+1\n",
    "        # MODEL AVERAGING (ENSEMBLE LEARNING)\n",
    "        predict_output=sum/NUM_SUBMODELS\n",
    "        #print (predict_output.shape)\n",
    "        x_test2=predict_output[-1,0:2]\n",
    "\n",
    "        #########  if delta=0.005##########\n",
    "        #x_test2=predict_output[int(NUM_IN_SEQUENCE/2-1),0:2]\n",
    "        x_test2 = predict_output[int(NUM_IN_SEQUENCE/short_factor-1), 0:2]\n",
    "        x_test2=x_test2 * output_std + output_mean\n",
    "        x_test2 = (x_test2 - state_mean) / state_std\n",
    "\n",
    "\n",
    "        # RESCALING BY THE CORRESPONDING STANDARD DEVIATION & THE MEAN OF THE OUTPUT STATISTICS OF THE EXITING SURFACE\n",
    "        predict_output_normal = predict_output * output_std + output_mean\n",
    "        #predict_output_normal=predict_output_normal*[y2_std, y1_std]+[y2_mean, y1_mean]\n",
    "        #print(\"predict_output_normal=\",predict_output_normal)\n",
    "        #print(\"ensemble_output=\",ensemble_output.shape)\n",
    "        ensemble_output[i_model,:,:]=predict_output_normal\n",
    "\n",
    "    return ensemble_output    \n",
    "\n",
    "\n",
    "\n",
    "#################################################\n",
    "################## MPC PROGRAM ##################\n",
    "#################################################\n",
    "### DEFINE THE UPPER BOUND AND LOWER BOUND OF THE MANIPULATED INPUTS ###\n",
    "\n",
    "def eval_f(x):\n",
    "    assert len(x) == int(NUM_MPC_INPUTS)\n",
    "    offset=0\n",
    "    global PREDICTION_STORE\n",
    "    #### CALCULATE OUTLET CONC ###########\n",
    "    df_ensemble_output = my_ens_prediction(num_horizon=int(NUM_MPC_INPUTS/2),my_rawdata=realtime_data,my_inputs=x)\n",
    "    # LAST SUBENSEMBLE, LAST TIME STEP, FIRST VARIABLE\n",
    "    # factor=realtime_data[1] **2 *500 /(realtime_data[0] **2 *50)\n",
    "    # factor2=realtime_data[1] **2 *500 /(3.5 **2 *100)\n",
    "    #### account for all intermediate steps ####\n",
    "    for j in range (int(NUM_MPC_INPUTS/2)):\n",
    "        est_outlet_product = df_ensemble_output[j, :, 0:2]\n",
    "        for i in range (int(NUM_IN_SEQUENCE/short_factor)):  #NUM_IN_SEQUENCE/2\n",
    "             #print (\"just show:\", est_outlet_product[i,:])\n",
    "            #offset = offset+ (setpoint[0]-(est_outlet_product[i,0]-Ts)) ** 2.0 *2 +(setpoint[1]-(est_outlet_product[i,1]-CAs)) ** 2.0 *500 +\\\n",
    "             #    x[2*j] **2 *5e-6 + 0.6* x[2*j+1] **2\n",
    "             #offset = offset+(setpoint[0]-(est_outlet_product[i,0]-Ts)) ** 2.0 *factor +(setpoint[1]-(est_outlet_product[i,1]-CAs)) ** 2.0 *500 +\\\n",
    "             #     0#x[2*j] **2 *1e-10 + 1* x[2*j+1] **2\n",
    "\n",
    "             offset = offset + (setpoint[0] - (est_outlet_product[i, 0])) ** 2  + (setpoint[1] - (est_outlet_product[i, 1])) ** 2 * 1000\n",
    "        offset=offset+x[2*j] **2 *3e-10 + 1* x[2*j+1] ** 2\n",
    "        #offset=offset+(x[1]-x_record[1])**2 *factor2/10+(x[0]-x_record[0])**2 *factor2/1e11\n",
    "\n",
    "\n",
    "\n",
    "    #print (\"im here\")\n",
    "    #####  only account for the last point #####\n",
    "    # for j in range(int(NUM_MPC_INPUTS / 2)):\n",
    "    #     est_outlet_product = df_ensemble_output[j, -1, 0:2]\n",
    "    #     #for i in range(NUM_IN_SEQUENCE):\n",
    "    #     offset = offset+ (setpoint[0] - (est_outlet_product[0] - Ts)) ** 2.0 + (\n",
    "    #                 setpoint[1] - (est_outlet_product[1] - CAs)) ** 2.0 * 500 + \\\n",
    "    #              0#x[2*j] ** 2 * 1e-11 + 0.05 * x[2*j+1] ** 2\n",
    "\n",
    "    # useless for now\n",
    "    #PREDICTION_STORE=numpy.asscalar(est_outlet_product)\n",
    "    #print(\"Prediction store:\", PREDICTION_STORE)\n",
    "    #print (\"obj func:  \", numpy.asarray(offset))\n",
    "    return offset/100\n",
    "\n",
    "def eval_grad_f(x):\n",
    "    assert len(x) == int(NUM_MPC_INPUTS)\n",
    "    step = 1e-1 # we just have a small step\n",
    "    objp=objm=0\n",
    "    grad_f = [0]*NUM_MPC_INPUTS\n",
    "    xpstep = [0]*NUM_MPC_INPUTS\n",
    "    xmstep = [0]*NUM_MPC_INPUTS\n",
    "    for i_mpc_input in range(NUM_MPC_INPUTS):\n",
    "        xpstep=x.copy()\n",
    "        xmstep=x.copy()\n",
    "        # for each variables, we need to evaluate the derivative of the function with respect to that variable, This is why we have the for loop\n",
    "        xpstep[i_mpc_input]  = xpstep[i_mpc_input]+step \n",
    "        xmstep[i_mpc_input] = xmstep[i_mpc_input]-step\n",
    "        #print (\"step: \", step)\n",
    "        #print (\"xp:  \",xpstep)\n",
    "        #print (\"xm:  \",xmstep)\n",
    "        #print (\"i_mpc_input:  \",i_mpc_input)\n",
    "        # Evaluate the objective function at xpstep and xmstep\n",
    "        objp=eval_f(xpstep) # This function returns the value of the objective function evaluated with the variable x[i] is perturebed +step\n",
    "        objm=eval_f(xmstep) # This function returns the value of the objective function evaluated with the variable x[i] is perturebed -step\n",
    "        #print (\"obj \", objp, \"   objm   \", objm)\n",
    "        grad_f[i_mpc_input] = (objp - objm) / (2 * step) # This evaluates the gradient of the objetive function with repect to the optimization variable x[i]\n",
    "    #print(\"Gradient: \", grad_f)\n",
    "    return array(grad_f)\n",
    "\n",
    "def eval_g(x):\n",
    "    assert len(x) == int(NUM_MPC_INPUTS)\n",
    "    #### CALCULATE FLUID TEMPERATURE ALONG THE FIRST THREE SURFACES ###########\n",
    "    #df_ensemble_output = my_ens_prediction(num_horizon=NUM_CONSTRAINT_MODELS,my_rawdata=realtime_data,my_inputs=x)\n",
    "    CAd2=realtime_data[1]\n",
    "    Td2=realtime_data[0]\n",
    "    ##pred_states=df_ensemble_output[-1, -1, 0:2]\n",
    "    #CAd2=df_ensemble_output[-1, -1, 1]\n",
    "    #Td2\n",
    "    g=array([-5.0]*NUM_MPC_CONSTRAINTS)\n",
    "    #print (\"gggg\", g)\n",
    "\n",
    "    # if ((a*CAd2**2+d*Td2**2+2*b*CAd2*Td2-2)> 0):\n",
    "        # LfV = (2 * a * CAd2 + 2 * b * Td2) * ((F / V) * (-CAd2) - k0 * ((numpy.exp(-E / (R * (Td2 + Ts))) * (CAd2 + CAs) ** 2)-\n",
    "        #                                                                 numpy.exp(-E / (R * Ts)) *(CAs)**2)) + \\\n",
    "        #       (2 * d * Td2 + 2 * b * CAd2) * (((F / V) * (-Td2) + (-Dh / (sigma * cp)) *\n",
    "        #                                        (k0 * ((numpy.exp(-E / (R * (Td2 + Ts))) *(CAd2 + CAs) ** 2) - numpy.exp(-E / (R * Ts)) * CAs ** 2))))\n",
    "\n",
    "        # LgV = (2 * d * Td2 + 2 * b * CAd2) / (V * sigma * cp)\n",
    "\n",
    "        # h2x = -(LfV + sqrt((LfV ** 2) + LgV ** 4)) / (LgV)\n",
    "\n",
    "\n",
    "        # if (h2x > 5e5):\n",
    "        #     h2x=5e5\n",
    "\n",
    "        # if (h2x < -5e5):\n",
    "        #     h2x=-5e5\n",
    "\n",
    "        # dot_Vt = (2 * a * CAd2 + 2 * b * Td2) * ((F / V) * (0 - CAd2) -\n",
    "        #                                          k0 * ((numpy.exp(-E / (R * (Td2 + Ts))) * (\n",
    "        #                     CAd2 + CAs) ** 2) - numpy.exp(\n",
    "        #             -E / (R * Ts)) * (CAs ** 2))) + \\\n",
    "        #          (2 * d * Td2 + 2 * b * CAd2) * (((F / V) * (-Td2) + (-Dh / (sigma * cp)) * (\n",
    "        #         k0 * ((numpy.exp(-E / (R * (Td2 + Ts))) * (CAd2 + CAs) ** 2) -\n",
    "        #               numpy.exp(-E / (R * Ts)) * CAs ** 2)) + (h2x / (sigma * cp * V))))\n",
    "        # #print(\"theoretic dot v=:  \", dot_Vt)\n",
    "\n",
    "        # dot_V=(2*a * CAd2 + 2*b * Td2)*((F / V)*(x[1] - CAd2) -\n",
    "        #        k0*((numpy.exp(-E / (R*(Td2 + Ts)))* (CAd2 + CAs) ** 2) - numpy.exp(-E / (R*Ts))*(CAs ** 2))) + \\\n",
    "        #     (2*d*Td2 + 2*b * CAd2)*(((F / V)*(-Td2) + (-Dh / (sigma*cp))*(k0*((numpy.exp(-E / (R*(Td2 + Ts)))* (CAd2 + CAs)** 2) -\n",
    "        #       numpy.exp(-E / (R*Ts))* CAs ** 2)) + (x[0] / (sigma*cp*V))))\n",
    "        #print (\"dot V- TRUE\", dot_V)\n",
    "\n",
    "#         df_ensemble_output3 = my_ens_prediction(num_horizon=1,my_rawdata=realtime_data, my_inputs=x)\n",
    "#         est_outlet = df_ensemble_output3[-1, -1, 0:2]\n",
    "#     #         dot_V1=(2*a * CAd2 + 2*b * Td2)*((est_outlet[0][1])-CAd2)/(0.01)+\\\n",
    "#     #                 (2*d*Td2 + 2*b * CAd2)*((est_outlet[0][0])-Td2)/(0.01)\n",
    "#     #         #print (\"dot V\", dot_V1)\n",
    "\n",
    "#     #         vv=a*CAd2**2+d*Td2**2+2*b*CAd2*Td2\n",
    "#     #         g[0]=dot_V1+15*abs(vv/100)\n",
    "#         g[0] = a*(est_outlet[1])**2 + d*(est_outlet[0])**2 + 2*b*(est_outlet[1])*(est_outlet[0]) - \\\n",
    "#                 a*CAd2**2 - 2*b*CAd2*Td2 - d*Td2**2\n",
    "\n",
    "    df_ensemble_output2 = my_ens_prediction(num_horizon=int(NUM_MPC_INPUTS / 2), my_rawdata=realtime_data, my_inputs=x)\n",
    "    for j in range(int(NUM_MPC_INPUTS / 2)):\n",
    "        est_outlet_product2 = df_ensemble_output2[j, int(NUM_IN_SEQUENCE/short_factor-1), 0:2]  #int(NUM_IN_SEQUENCE/2-1)\n",
    "        g[j]= d * (est_outlet_product2[0]) ** 2+ 2 * b * (est_outlet_product2[0])*(est_outlet_product2[1]) + \\\n",
    "              a*(est_outlet_product2[1]) ** 2 - a*CAd2**2 - 2*b*CAd2*Td2 - d*Td2**2\n",
    "\n",
    "        #g[0]=dot_V-dot_Vt#+1#e-2 \n",
    "\n",
    "#     else:\n",
    "#         df_ensemble_output2 = my_ens_prediction(num_horizon=int(NUM_MPC_INPUTS / 2), my_rawdata=realtime_data,\n",
    "#                                                my_inputs=x)\n",
    "#         # LAST SUBENSEMBLE, LAST TIME STEP, FIRST VARIABLE\n",
    "\n",
    "#         #### NORMALIZE SETPOINT ####\n",
    "#         # for j in range (int(NUM_MPC_INPUTS/2)):\n",
    "#         #     est_outlet_product = df_ensemble_output[j, :, 0:2]\n",
    "#         #     for i in range (NUM_IN_SEQUENCE):\n",
    "#         #         offset = (setpoint[0]-(est_outlet_product[i,0]-Ts)) ** 2.0 +(setpoint[1]-(est_outlet_product[i,1]-CAs)) ** 2.0 *500 +\\\n",
    "#         #              x[0] **2 *1e-11 + 0.05* x[1] **2\n",
    "\n",
    "#         #####  only account for the last point #####\n",
    "#         for j in range(int(NUM_MPC_INPUTS / 2)):\n",
    "#             est_outlet_product2 = df_ensemble_output2[j, int(NUM_IN_SEQUENCE/short_factor-1), 0:2]  #int(NUM_IN_SEQUENCE/2-1)\n",
    "#             # for i in range(NUM_IN_SEQUENCE):\n",
    "#             g[j]= d * (est_outlet_product2[0]) ** 2+ 2 * b * (est_outlet_product2[0])*(est_outlet_product2[1]) + \\\n",
    "#                   a*(est_outlet_product2[1]) ** 2 -2\n",
    "\n",
    "\n",
    "#     df_fluid_temp=df_fluid_temp.reshape(NUM_CONSTRAINT_MODELS*NUM_IN_SEQUENCE)\n",
    "#     print (\"constraints satisfaction:  \",dot_V)\n",
    "    return  g\n",
    "\n",
    "nnzj = NUM_MPC_CONSTRAINTS*NUM_MPC_INPUTS\n",
    "\n",
    "\n",
    "def eval_jac_g(x, flag):\n",
    "    #print (\"in eval_jac_g_0\")\n",
    "    if flag:\n",
    "        list_x = []\n",
    "        list_y=[]\n",
    "        for i in range(int(NUM_MPC_INPUTS / 2)):\n",
    "            list_x = list_x + [i] * NUM_MPC_INPUTS\n",
    "            list_y = list_y +list(range(0, int(NUM_MPC_INPUTS)))\n",
    "        #list_x=[0]*int(NUM_MPC_INPUTS)+[1]*int(NUM_MPC_INPUTS)\n",
    "        #list_y=list(range(0, int(NUM_MPC_INPUTS)))+list(range(0, int(NUM_MPC_INPUTS)))\n",
    "        #print (\"list_x:\", list_x)\n",
    "        #print(\"list_y:\", list_y)\n",
    "        return (array(list_x),\n",
    "                array(list_y))\n",
    "\n",
    "        #return (array([0, 0]),\n",
    "        #        array([0, 1]))\n",
    "        #print (\"in eval_jac_g_1\")\n",
    "    else:\n",
    "        assert len(x) == int(NUM_MPC_INPUTS)\n",
    "        step = 1e-1 # we just have a small step\n",
    "        gp=gm=numpy.zeros(NUM_MPC_CONSTRAINTS)\n",
    "        xpstep=xmstep=numpy.zeros(NUM_MPC_INPUTS)\n",
    "        jac_g = [[0]*int(NUM_MPC_INPUTS) for _ in range(NUM_MPC_CONSTRAINTS)]\n",
    "        #print (\"shape:\", jac_g)\n",
    "        for i_mpc_input in range(NUM_MPC_INPUTS):\n",
    "            xpstep=x.copy()\n",
    "            xmstep=x.copy()\n",
    "            # for each variables, we need to evaluate the derivative of the function with respect to that variable, This is why we have the for loop\n",
    "            xpstep[i_mpc_input] += step \n",
    "            xmstep[i_mpc_input] -= step\n",
    "            gp=eval_g(xpstep)\n",
    "            gm=eval_g(xmstep)\n",
    "            for num_constraint in range(NUM_MPC_CONSTRAINTS):\n",
    "                jac_g[num_constraint][i_mpc_input] = (gp[num_constraint] - gm[num_constraint]) / (2 * step)\n",
    "            #print (\"in eval_jac_g_2:\")\n",
    "        return array(jac_g)\n",
    "\n",
    "def apply_new(x):\n",
    "    return True\n",
    "def print_variable(variable_name, value):\n",
    "    for i in range(len(value)):\n",
    "        print(\"{} {}\".format(variable_name + \"[\"+str(i)+\"] =\", value[i]))\n",
    "\n",
    "\n",
    "nnzh = NUM_MPC_INPUTS**2\n",
    "# def eval_h(x, lagrange, obj_factor, flag, user_data = None):\n",
    "#     if flag:\n",
    "#         hrow = [0, 1, 1, 2, 2, 2, 3, 3, 3, 3]\n",
    "#         hcol = [0, 0, 1, 0, 1, 2, 0, 1, 2, 3]\n",
    "#         return (array(hcol), array(hrow))\n",
    "#     else:\n",
    "#         values = zeros((10), float_)\n",
    "#         values[0] = obj_factor * (2*x[3])\n",
    "#         values[1] = obj_factor * (x[3])\n",
    "#         values[2] = 0\n",
    "#         values[3] = obj_factor * (x[3])\n",
    "#         values[4] = 0\n",
    "#         values[5] = 0\n",
    "#         values[6] = obj_factor * (2*x[0] + x[1] + x[2])\n",
    "#         values[7] = obj_factor * (x[0])\n",
    "#         values[8] = obj_factor * (x[0])\n",
    "#         values[9] = 0\n",
    "#         values[1] += lagrange[0] * (x[2] * x[3])\n",
    "\n",
    "#         values[3] += lagrange[0] * (x[1] * x[3])\n",
    "#         values[4] += lagrange[0] * (x[0] * x[3])\n",
    "\n",
    "#         values[6] += lagrange[0] * (x[1] * x[2])\n",
    "#         values[7] += lagrange[0] * (x[0] * x[2])\n",
    "#         values[8] += lagrange[0] * (x[0] * x[1])\n",
    "#         values[0] += lagrange[1] * 2\n",
    "#         values[2] += lagrange[1] * 2\n",
    "#         values[5] += lagrange[1] * 2\n",
    "#         values[9] += lagrange[1] * 2\n",
    "#         return values\n",
    "\n",
    "#####################################################################\n",
    "##### PRE-PROCESSING (THE FOLLOWING COMMANDS ARE EXECUTED ONCE) #####\n",
    "#####################################################################\n",
    "#### LOAD MEAN AND STD FILES###########\n",
    "#### READ MEANS & STD FROM THE FILE #####\n",
    "# dataframe_summary= pandas.read_csv(\"train.summary.csv\",   skiprows=1, header=None)\n",
    "# train_summary = dataframe_summary.values\n",
    "# train_summary=train_summary[0:,1:].astype(float)\n",
    "# print (train_summary)\n",
    "\n",
    "# x1_mean=train_summary[1,0]\n",
    "# x1_std=train_summary[1,1]\n",
    "# x2_mean=train_summary[0,0]\n",
    "# x2_std=train_summary[0,1]\n",
    "# u1_mean=train_summary[3,0]\n",
    "# u1_std=train_summary[3,1]\n",
    "# u2_mean=train_summary[2,0]\n",
    "# u2_std=train_summary[2,1]\n",
    "# y1_mean=train_summary[5,0]\n",
    "# y1_std=train_summary[5,1]\n",
    "# y2_mean=train_summary[4,0]\n",
    "# y2_std=train_summary[4,1]\n",
    "x1_mean=1.6712e-02 # CA\n",
    "x1_std=8.4936e-01 \n",
    "x2_mean=-6.1691e-01# T\n",
    "x2_std=3.8528e+01 \n",
    "u1_mean=1.1605e-02   # CA0\n",
    "u1_std=2.6116e+00 \n",
    "u2_mean=1.9277e+02    # Q\n",
    "u2_std=3.7388e+05\n",
    "y1_mean=0.01958    # CA\n",
    "y1_std=0.8453\n",
    "y2_mean=-0.7537  # T\n",
    "y2_std=38.7847\n",
    "state_mean=numpy.array([x2_mean, x1_mean])\n",
    "state_std=numpy.array([x2_std, x1_std])\n",
    "input_mean=numpy.array([u2_mean, u1_mean])\n",
    "input_std=numpy.array([u2_std, u1_std])\n",
    "output_mean=numpy.array([y2_mean, y1_mean])\n",
    "output_std=numpy.array([y2_std, y1_std])\n",
    "\n",
    "\n",
    "model=[1]*(NUM_SUBMODELS) \n",
    "#print(model)\n",
    "#### LOAD NEURAL NETWORK MODELS ####\n",
    "\n",
    "# for j_submodel in range (TOTAL_MODELS):\n",
    "#     #print (\"NOW IT IS :\", j_submodel)\n",
    "#     model_path = Path(\"MODEL/model\" + str(j_submodel + 1)+ \".h5\")\n",
    "#     #filename=Path(\"model\" + str(j_submodel + 1))\n",
    "#     #print(model_path)\n",
    "#     #if (os.path.isfile(model_path)==True)\n",
    "#     if (model_path.exists()):\n",
    "#         model[0] = load_model(model_path)\n",
    "#         print (\"NOW IT IS :\", j_submodel+1)\n",
    "#         OUTPUT_NO=j_submodel+1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model[0]=load_model(\"iclrnn_original_256_0.h5\", custom_objects={'SpectralConstraint': SpectralConstraint})\n",
    "    \n",
    "####################################################################\n",
    "##### SOLVING THE MPC PROGRAM TO FIND THE OPTIMIZED MPC INPUTS #####\n",
    "####################################################################\n",
    "##########  KEEP RUNNING MPC ###############\n",
    "\n",
    "dir_name = os.getcwd()\n",
    "test = os.listdir(dir_name)\n",
    "\n",
    "for item in test:\n",
    "    if item.endswith(\".txt\"):\n",
    "        os.remove(os.path.join(dir_name, item))\n",
    "\n",
    "\n",
    "nvar = NUM_MPC_INPUTS\n",
    "x_lower=[0]* nvar\n",
    "x_upper=[0]* nvar\n",
    "for i in range(int(NUM_MPC_INPUTS/2)):\n",
    "    x_lower[2*i]=-5e5\n",
    "    x_lower[2 * i+1] = -3.5\n",
    "    x_upper[2 * i] = 5e5\n",
    "    x_upper[2 * i + 1] = 3.5\n",
    "x_L = array(x_lower) #array([-5e5, -3.5])\n",
    "x_U = array(x_upper) #array([5e5, 3.5])\n",
    "\n",
    "### DEFINE THE UPPER BOUND AND LOWER BOUND OF THE CONSTRAINT ###\n",
    "ncon = NUM_MPC_CONSTRAINTS\n",
    "g_L = array([-2e19]*HORIZON)\n",
    "g_U = array([0]*HORIZON)\n",
    "\n",
    "print (\"g_L\", g_L, g_U)\n",
    "\n",
    "\n",
    "for main_iteration in range(NUM_MPC_ITERATION):\n",
    "    print (\"Num Iteratin: \", main_iteration)\n",
    "    #check_file = Path(\"indicator.out\")\n",
    "    #while not os.path.exists(check_file):\n",
    "    #    time.sleep(1)\n",
    "    #os.remove(check_file)  \n",
    "\n",
    "    #if main_iteration >0:\n",
    "     #   deviation=deviation-PREDICTION_STORE\n",
    "     #   setpoint = SETPOINT_TRUE-deviation\n",
    "    #else:\n",
    "    #    setpoint = SETPOINT_TRUE \n",
    "    #print (\"setpoint: \", setpoint)\n",
    "    #print (\"deviation: \", deviation)\n",
    "    #print (\"PREDICTION_STORE: \",PREDICTION_STORE)\n",
    "    \n",
    "\n",
    "    rawdata=numpy.array([Ti, CAi])\n",
    "\n",
    "    #### NORMALIZE RAW DATA ####\n",
    "    #rawdata=(rawdata-state_mean)/state_std\n",
    "    # print (\"normalized data:  \", rawdata)\n",
    "    realtime_data=rawdata\n",
    "\n",
    "    start = time.time()\n",
    "    nlp = pyipopt.create(nvar, x_L, x_U, ncon, g_L, g_U, nnzj, nnzh, eval_f, eval_grad_f, eval_g, eval_jac_g)\n",
    "    #x0 = array([3.33, 3.8, 3.8, 6])\n",
    "    if main_iteration ==0 :\n",
    "        x0 = array([0.0]*int(NUM_MPC_INPUTS))\n",
    "        #x0= array ([-5e5, 3.5, -5e5, 3.5])\n",
    "    else:\n",
    "        x0=x\n",
    "        x0[0:-2]=x[2:]\n",
    "        x0[-2:]=x[-2:]#[0, 0]\n",
    "        x_record=x\n",
    "        #x0 = array([0.0] * int(NUM_MPC_INPUTS))\n",
    "        #x0=array(x[:-2], 0, 0)\n",
    "    \"\"\"\n",
    "    print x0\n",
    "    print nvar, ncon, nnzj\n",
    "    print x_L,  x_U\n",
    "    print g_L, g_U\n",
    "    print eval_f(x0)\n",
    "    print eval_grad_f(x0)\n",
    "    print eval_g(x0)\n",
    "    a =  eval_jac_g(x0, True)\n",
    "    print \"a = \", a[1], a[0]\n",
    "    print eval_jac_g(x0, False)\n",
    "    print eval_h(x0, pi0, 1.0, False)\n",
    "    print eval_h(x0, pi0, 1.0, True)\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\" You CAd2 set Ipopt options by calling nlp.num_option, nlp.str_option\n",
    "    or nlp.int_option. For instance, to set the tolarance by calling\n",
    "\n",
    "        nlp.num_option('tol', 1e-8)\n",
    "\n",
    "    For a complete list of Ipopt options, refer to\n",
    "\n",
    "        http://www.coin-or.org/Ipopt/documentation/node59.html\n",
    "\n",
    "    Note that Ipopt distinguishs between Int, Num, and Str options, yet sometimes\n",
    "    does not explicitly tell you which option is which.  If you are not sure about\n",
    "    the option's type, just try it in PyIpopt.  If you try to set one type of\n",
    "    option using the wrong function, Pyipopt will remind you of it. \"\"\"\n",
    "    nlp.int_option('max_iter', 100)\n",
    "    nlp.num_option('tol', 1e-5)\n",
    "    nlp.int_option('print_level', 2)\n",
    "    print(\"Going to call solve\")\n",
    "    print(\"x0 = {}\".format(x0))\n",
    "    x, zl, zu, constraint_multipliers, obj, status = nlp.solve(x0)\n",
    "\n",
    "\n",
    "\n",
    "    # import pdb; pdb.set_trace()\n",
    "    nlp.close()\n",
    "    end = time.time()\n",
    "    \n",
    "    print(\"The elapsed time is\", end - start, \"s\")\n",
    "    time_record.append(end-start)\n",
    "\n",
    "    print(\"Solution of the primal variables, x\")\n",
    "    print_variable(\"x\", x)\n",
    "    print (\"status=\", status)\n",
    "    # print(\"Solution of the bound multipliers, z_L and z_U\")\n",
    "    # print_variable(\"z_L\", zl)\n",
    "    # print_variable(\"z_U\", zu)\n",
    "\n",
    "    # print(\"Solution of the constraint multipliers, lambda\")\n",
    "    # print_variable(\"lambda\", constraint_multipliers)\n",
    "\n",
    "    print(\"Objective value\")\n",
    "    print(\"f(x*) = {}\".format(obj))\n",
    "    print (\"Control action=:  \", x[1], x[0])\n",
    "    #REAL_CONTROL_ACTION=x*\n",
    "    #print (\"REAL DATA:\", REAL_CONTROL_ACTION)\n",
    "    #numpy.savetxt(\"input_to_fluent.out\",   REAL_CONTROL_ACTION, fmt=\"%f\",  delimiter=\" \")\n",
    "    x1=CAi\n",
    "    x2=Ti\n",
    "\n",
    "    w1 =numpy.random.normal(0, w1_std, 1)\n",
    "    w2 =numpy.random.normal(0, w2_std, 1)\n",
    "    if w1>w1_std:\n",
    "        w1=w1_std\n",
    "    if w1<-w1_std:\n",
    "        w1=-w1_std\n",
    "    if w2>w2_std:\n",
    "        w2=w2_std\n",
    "    if w2>w2_std:\n",
    "        w2=w2_std\n",
    "    #print (numpy.asscalar(w1))\n",
    "    #print (numpy.asscalar(w2))\n",
    "    for kk in range (int(delta/hc)):\n",
    "        #print (\"Anh needs to print x1 and x2: \", x1, x2)\n",
    "        #x1_new = x1 + hc * ((F / V) * (u1  - x1) - k0 * (numpy.exp(-E / (R * x2))*x1 * x1))\n",
    "        #x2_new = x2 + hc * ((F / V) * (T0-x2) + (-Dh / (sigma * cp)) * k0 * (numpy.exp(-E / (R * x2)) * x1* x1)\n",
    "        #        + (u2 / (sigma * cp * V)))\n",
    "\n",
    "\n",
    "        x1_new = x1 + hc * ((F / V) * (x[1] - x1) -\n",
    "                            k0 * ((numpy.exp(-E / (R * (x2 + Ts)))*(x1 + CAs) * (x1 + CAs))\n",
    "                                  - numpy.exp(-E / (R * Ts)) * CAs * CAs))\n",
    "\n",
    "        x2_new = x2 + hc * (((F / V) * (-x2) + (-Dh / (sigma * cp)) *\n",
    "                             (k0 * ((numpy.exp(-E / (R * (x2 + Ts))) * (x1 + CAs) * (x1 + CAs)) -\n",
    "                                      numpy.exp(-E / (R * Ts)) * CAs * CAs)) + (x[0] / (sigma * cp * V))))\n",
    "\n",
    "\n",
    "\n",
    "        x1 = x1_new\n",
    "        x2 = x2_new\n",
    "\n",
    "        if (kk%5==1):\n",
    "            x1_record.append(x1)\n",
    "            x2_record.append(x2)\n",
    "            u1_record.append(x[1])\n",
    "            u2_record.append(x[0])\n",
    "\n",
    "    CAi=x1\n",
    "    Ti=x2\n",
    "\n",
    "        #print (\"First principle intermediate steps x1, x2:  \", x1, x2)\n",
    "        #print(\"First principle intermediate derivatives x1, x2:  \", x1_derivate, x2_derivate)\n",
    "\n",
    "    #x1=x1-CAs\n",
    "    #x2=x2-Ts\n",
    "    print('Real model output x1 x2 in deviation form:   ', x1, x2)\n",
    "    #x1=(x1 -y1_mean)/y1_std\n",
    "    #x2 = (x2 - y2_mean) / y2_std\n",
    "    # x1_record.append(x1)\n",
    "    # x2_record.append(x2)\n",
    "    # u1_record.append(x[1])\n",
    "    # u2_record.append(x[0])\n",
    "    \n",
    "    if sum(time_record) > 720:\n",
    "        break\n",
    "\n",
    "print (\"x1_record: \",x1_record)\n",
    "print (\"x2_record: \",x2_record)\n",
    "\n",
    "print (\"u1_record: \",u1_record)\n",
    "print (\"u2_record: \",u2_record)\n",
    "\n",
    "print(\"time_record: \", time_record)\n",
    "print(\"total time elapsed: \", sum(time_record), 's')\n",
    "print(\"average time for each iteration:\", sum(time_record)/len(time_record), 's')\n",
    "\n",
    "\n",
    "# filename1=Path(\"OUTPUT/model\" + str(OUTPUT_NO)+\"-x1.txt\")\n",
    "# filename2=Path(\"OUTPUT/model\" + str(OUTPUT_NO)+\"-x2.txt\")\n",
    "# filename3=Path(\"OUTPUT/model\" + str(OUTPUT_NO)+\"-u1.txt\")\n",
    "# filename4=Path(\"OUTPUT/model\" + str(OUTPUT_NO)+\"-u2.txt\")\n",
    "\n",
    "#\n",
    "numpy.savetxt(\"x1.txt\",   x1_record, fmt=\"%f\",  delimiter=\" \")\n",
    "numpy.savetxt(\"x2.txt\",   x2_record, fmt=\"%f\",  delimiter=\" \")\n",
    "\n",
    "\n",
    "numpy.savetxt(\"u1.txt\",   u1_record, fmt=\"%f\",  delimiter=\" \")\n",
    "numpy.savetxt(\"u2.txt\",   u2_record, fmt=\"%f\",  delimiter=\" \")\n",
    "numpy.savetxt(\"time_LSTM.txt\",   time_record, fmt=\"%f\",  delimiter=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9245765d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
